{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [12.84269999996468, 12.219300000651856], "ttft_ms": [1.5120999996725004, 1.3760000001639128], "tokens_processed": [8, 8], "throughput_tok_s": [622.9219712382911, 654.7019878039846], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2493.910799999867, 259.220700001606, 1.633899999433197], "resource_metrics": {"samples": 20, "duration_s": 2.7798445224761963, "gpu_memory_mean_mb": 497.71953125, "gpu_memory_peak_mb": 562.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.05, "gpu_power_mean_watts": 29.145699999999998, "gpu_power_peak_watts": 29.493, "gpu_temperature_mean_c": 46.05, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1049.1943359375, "cpu_memory_peak_mb": 1420.29296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765651999.426966}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [13.469400000758469, 12.311500000578235], "ttft_ms": [1.905600000100094, 1.4203999999153893], "tokens_processed": [8, 8], "throughput_tok_s": [593.9388539615362, 649.7989684136185], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.3778999984642724, 1.7440000010537915, 1.476199999160599], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 562.01953125, "gpu_memory_peak_mb": 562.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 28.967, "gpu_power_peak_watts": 28.967, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1422.2734375, "cpu_memory_peak_mb": 1422.2734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765651999.5599115}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [12.393599999995786, 12.998899999729474], "ttft_ms": [1.3991000014357269, 1.3293000010889955], "tokens_processed": [8, 8], "throughput_tok_s": [645.4944487479603, 615.4366908097218], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.061600000364706, 1.5432999989570817, 1.460699999370263], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 562.01953125, "gpu_memory_peak_mb": 562.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 28.967, "gpu_power_peak_watts": 28.967, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1422.34375, "cpu_memory_peak_mb": 1422.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765651999.6860802}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [19.593899998653797, 12.827599999582162], "ttft_ms": [2.3139000004448462, 1.6821999997773673], "tokens_processed": [8, 8], "throughput_tok_s": [408.29033528545324, 623.6552434017733], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7265999997325707, 2.411900000879541, 2.495700000508805], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 562.01953125, "gpu_memory_peak_mb": 562.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.24, "gpu_power_peak_watts": 29.24, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1422.3515625, "cpu_memory_peak_mb": 1422.3515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765651999.809966}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [13.716299999941839, 13.278899999932037], "ttft_ms": [1.5628000001015607, 1.5001000010670396], "tokens_processed": [8, 8], "throughput_tok_s": [583.2476688344468, 602.4595410795281], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.705499999137828, 1.9383999988349387, 2.1194000000832602], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 562.01953125, "gpu_memory_peak_mb": 562.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.24, "gpu_power_peak_watts": 29.24, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1422.36328125, "cpu_memory_peak_mb": 1422.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765651999.9334748}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [87.47480000056385, 89.02889999990293], "ttft_ms": [11.22639999994135, 11.545399998794892], "tokens_processed": [8, 8], "throughput_tok_s": [91.45491044218944, 89.85846169062768], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1012.4329999998736, 11.000899999999092, 9.586799998942297], "resource_metrics": {"samples": 12, "duration_s": 1.19227933883667, "gpu_memory_mean_mb": 563.8528645833334, "gpu_memory_peak_mb": 564.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.16666666666666666, "gpu_power_mean_watts": 29.362916666666667, "gpu_power_peak_watts": 29.467, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1431.0439453125, "cpu_memory_peak_mb": 1464.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652001.2344542}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [64.46929999947315, 65.85379999887664], "ttft_ms": [8.352499999091378, 7.785100000546663], "tokens_processed": [8, 8], "throughput_tok_s": [124.09007077888819, 121.48122052389486], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.185499999963213, 8.854400000927853, 10.051200000816607], "resource_metrics": {"samples": 2, "duration_s": 0.11726880073547363, "gpu_memory_mean_mb": 564.01953125, "gpu_memory_peak_mb": 564.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 29.368, "gpu_power_peak_watts": 29.368, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1464.63671875, "cpu_memory_peak_mb": 1464.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652001.4623141}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [66.08769999911601, 65.65509999927599], "ttft_ms": [8.207700000639306, 7.767900000544614], "tokens_processed": [8, 8], "throughput_tok_s": [121.05126975378184, 121.84887388928232], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.072000001149718, 8.008299999346491, 8.06910000028438], "resource_metrics": {"samples": 2, "duration_s": 0.10950922966003418, "gpu_memory_mean_mb": 564.01953125, "gpu_memory_peak_mb": 564.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 29.368, "gpu_power_peak_watts": 29.368, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1464.732421875, "cpu_memory_peak_mb": 1464.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652001.6795926}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [66.9292000002315, 68.42669999969075], "ttft_ms": [8.483800000249175, 8.009299999685027], "tokens_processed": [8, 8], "throughput_tok_s": [119.52929364122578, 116.91342706920186], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.975099999588565, 8.711199998288066, 8.067599999776576], "resource_metrics": {"samples": 2, "duration_s": 0.1127479076385498, "gpu_memory_mean_mb": 564.01953125, "gpu_memory_peak_mb": 564.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.268, "gpu_power_peak_watts": 30.268, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1464.76953125, "cpu_memory_peak_mb": 1464.7734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652001.9004295}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [72.35509999918577, 69.52520000049844], "ttft_ms": [8.987600000182283, 8.426500000496162], "tokens_processed": [8, 8], "throughput_tok_s": [110.56580669628023, 115.06619182602346], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.231300000072224, 9.195999999064952, 8.932100001402432], "resource_metrics": {"samples": 2, "duration_s": 0.10793828964233398, "gpu_memory_mean_mb": 564.01953125, "gpu_memory_peak_mb": 564.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.268, "gpu_power_peak_watts": 30.268, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1464.78515625, "cpu_memory_peak_mb": 1464.78515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652002.1181796}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [103.35449999911361, 84.63269999992917], "ttft_ms": [10.423900001114816, 12.241500000527594], "tokens_processed": [8, 8], "throughput_tok_s": [77.40349960638974, 94.52611106589646], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1034.6540999998979, 8.527100000719656, 8.571000000301865], "resource_metrics": {"samples": 12, "duration_s": 1.190138816833496, "gpu_memory_mean_mb": 565.8528645833334, "gpu_memory_peak_mb": 566.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.6666666666666665, "gpu_power_mean_watts": 30.257666666666665, "gpu_power_peak_watts": 30.96, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1467.5091145833333, "cpu_memory_peak_mb": 1473.234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652003.4163158}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [71.20509999913338, 70.83220000095025], "ttft_ms": [9.362700000565383, 8.862200000294251], "tokens_processed": [8, 8], "throughput_tok_s": [112.35150291337791, 112.94298355680998], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.281300001224736, 10.175399998843204, 9.931099999448634], "resource_metrics": {"samples": 2, "duration_s": 0.11697602272033691, "gpu_memory_mean_mb": 566.01953125, "gpu_memory_peak_mb": 566.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.147, "gpu_power_peak_watts": 29.147, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1473.23046875, "cpu_memory_peak_mb": 1473.23046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652003.6406827}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [71.96870000007038, 70.39900000017951], "ttft_ms": [8.545200000298792, 9.579699999449076], "tokens_processed": [8, 8], "throughput_tok_s": [111.15943458742726, 113.63797781189507], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.756400000696885, 10.484200000064448, 9.711200000310782], "resource_metrics": {"samples": 2, "duration_s": 0.1104888916015625, "gpu_memory_mean_mb": 566.01953125, "gpu_memory_peak_mb": 566.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.597499999999997, "gpu_power_peak_watts": 30.048, "gpu_temperature_mean_c": 47.5, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1473.3046875, "cpu_memory_peak_mb": 1473.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652003.8595803}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [70.4105000004347, 61.94779999896127], "ttft_ms": [9.199999998600106, 4.171599999608588], "tokens_processed": [8, 8], "throughput_tok_s": [113.61941755775929, 129.14098644559036], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.74069999938365, 8.684999998877174, 8.860699999786448], "resource_metrics": {"samples": 2, "duration_s": 0.10797572135925293, "gpu_memory_mean_mb": 566.01953125, "gpu_memory_peak_mb": 566.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.048, "gpu_power_peak_watts": 30.048, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1473.33984375, "cpu_memory_peak_mb": 1473.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652004.0770278}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [92.05780000047525, 67.90669999827514], "ttft_ms": [8.783200000834768, 9.311499999967054], "tokens_processed": [8, 8], "throughput_tok_s": [86.90192465992779, 117.80869929186963], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.068499999557389, 8.565700001781806, 8.503099999870756], "resource_metrics": {"samples": 2, "duration_s": 0.1101381778717041, "gpu_memory_mean_mb": 566.01953125, "gpu_memory_peak_mb": 566.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.5, "gpu_power_mean_watts": 30.4455, "gpu_power_peak_watts": 30.843, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1473.33984375, "cpu_memory_peak_mb": 1473.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652004.2964485}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [90.09719999994559, 84.93240000098012], "ttft_ms": [9.4941999996081, 11.078300000008312], "tokens_processed": [8, 8], "throughput_tok_s": [88.79299245708891, 94.1925578449176], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [924.211399998967, 10.642900000675581, 9.613600001102895], "resource_metrics": {"samples": 11, "duration_s": 1.0959768295288086, "gpu_memory_mean_mb": 573.2922585227273, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.6363636363636362, "gpu_power_mean_watts": 28.74590909090909, "gpu_power_peak_watts": 30.843, "gpu_temperature_mean_c": 47.72727272727273, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1475.4495738636363, "cpu_memory_peak_mb": 1480.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652005.5020587}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [75.84880000104022, 75.24009999906411], "ttft_ms": [9.30060000064259, 9.274599999116617], "tokens_processed": [8, 8], "throughput_tok_s": [105.47299363853199, 106.32628080105567], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.070400001495727, 9.746099998665159, 9.372399999847403], "resource_metrics": {"samples": 2, "duration_s": 0.11884784698486328, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 25.403, "gpu_power_peak_watts": 25.403, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1480.41015625, "cpu_memory_peak_mb": 1480.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652005.7309666}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [80.24479999949108, 83.22770000086166], "ttft_ms": [10.066400000141584, 10.130000000572181], "tokens_processed": [8, 8], "throughput_tok_s": [99.69493350411163, 96.12184404852202], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.125200001013582, 9.899900000164052, 9.439600000405335], "resource_metrics": {"samples": 2, "duration_s": 0.12141966819763184, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.433, "gpu_power_peak_watts": 19.433, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1480.41796875, "cpu_memory_peak_mb": 1480.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652005.9626439}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [91.03630000026897, 87.05539999937173], "ttft_ms": [10.470100000020466, 10.674099999960163], "tokens_processed": [8, 8], "throughput_tok_s": [87.87703366653042, 91.89550562122206], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [20.77830000052927, 11.374900001101196, 10.359800000514952], "resource_metrics": {"samples": 3, "duration_s": 0.2098078727722168, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.433, "gpu_power_peak_watts": 19.433, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1480.4296875, "cpu_memory_peak_mb": 1480.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652006.2845254}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [79.74470000044676, 79.22549999966577], "ttft_ms": [10.108000000400352, 9.572400000251946], "tokens_processed": [8, 8], "throughput_tok_s": [100.32014666749241, 100.97758928670378], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.130200000086916, 9.854100000666222, 10.139799998796661], "resource_metrics": {"samples": 2, "duration_s": 0.11112213134765625, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 13.749, "gpu_power_peak_watts": 13.749, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1480.44140625, "cpu_memory_peak_mb": 1480.44140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652006.5089812}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [173.96299999927578, 147.0062999997026], "ttft_ms": [19.080799998846487, 20.10549999977229], "tokens_processed": [32, 32], "throughput_tok_s": [183.9471611787174, 217.67774578412445], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1006.31550000071, 21.522400000321795, 18.3206000001519], "resource_metrics": {"samples": 14, "duration_s": 1.3743607997894287, "gpu_memory_mean_mb": 596.4481026785714, "gpu_memory_peak_mb": 608.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.5, "gpu_power_mean_watts": 10.136214285714287, "gpu_power_peak_watts": 13.749, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1486.097935267857, "cpu_memory_peak_mb": 1506.92578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652007.9916682}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [112.08880000049248, 110.60320000069623], "ttft_ms": [12.37810000020545, 12.635800001589814], "tokens_processed": [32, 32], "throughput_tok_s": [285.48793456491103, 289.32255124443566], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.147199999366421, 13.366000001042266, 12.49420000021928], "resource_metrics": {"samples": 3, "duration_s": 0.21870708465576172, "gpu_memory_mean_mb": 608.01953125, "gpu_memory_peak_mb": 608.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.666666666666666, "gpu_power_mean_watts": 4.466, "gpu_power_peak_watts": 5.668, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1506.9765625, "cpu_memory_peak_mb": 1506.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652008.319345}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [109.80120000021998, 108.1715999989683], "ttft_ms": [12.447200000679004, 12.057199999617296], "tokens_processed": [32, 32], "throughput_tok_s": [291.4357948723319, 295.8262612395971], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.232700001026387, 13.88039999983448, 12.748999999530497], "resource_metrics": {"samples": 3, "duration_s": 0.21961307525634766, "gpu_memory_mean_mb": 608.01953125, "gpu_memory_peak_mb": 608.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 44.0, "gpu_power_mean_watts": 5.668, "gpu_power_peak_watts": 5.668, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1506.9765625, "cpu_memory_peak_mb": 1506.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652008.6494334}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [112.07779999858758, 109.47529999975814], "ttft_ms": [13.936499999545049, 12.26920000044629], "tokens_processed": [32, 32], "throughput_tok_s": [285.51595409977057, 292.30337802290285], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.876100000648876, 13.738100000409759, 14.548699999068049], "resource_metrics": {"samples": 3, "duration_s": 0.21326327323913574, "gpu_memory_mean_mb": 608.01953125, "gpu_memory_peak_mb": 608.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 44.0, "gpu_power_mean_watts": 8.607333333333333, "gpu_power_peak_watts": 10.077, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1506.98046875, "cpu_memory_peak_mb": 1506.98046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652008.9760413}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [109.90510000010545, 112.1975999994902], "ttft_ms": [12.240899999596877, 12.28590000027907], "tokens_processed": [32, 32], "throughput_tok_s": [291.1602828255404, 285.21109186065837], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [21.115800000188756, 12.918999998873915, 12.311799999224604], "resource_metrics": {"samples": 3, "duration_s": 0.21428370475769043, "gpu_memory_mean_mb": 608.01953125, "gpu_memory_peak_mb": 608.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 43.666666666666664, "gpu_power_mean_watts": 10.972333333333333, "gpu_power_peak_watts": 12.763, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1506.984375, "cpu_memory_peak_mb": 1506.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652009.302684}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [142.093800001021, 127.07289999889326], "ttft_ms": [16.023600001062732, 19.331100000272272], "tokens_processed": [32, 32], "throughput_tok_s": [225.20335158726184, 251.82395302443481], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [948.9236999997956, 16.715400000975933, 14.951699999073753], "resource_metrics": {"samples": 12, "duration_s": 1.2035913467407227, "gpu_memory_mean_mb": 620.8528645833334, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 28.666666666666668, "gpu_power_mean_watts": 11.681666666666667, "gpu_power_peak_watts": 12.763, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1518.5400390625, "cpu_memory_peak_mb": 1556.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652010.61733}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [119.81290000039735, 123.43449999934819], "ttft_ms": [14.389799998753006, 14.164899999741465], "tokens_processed": [32, 32], "throughput_tok_s": [267.083093722745, 259.2468070123748], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.900900000313413, 14.215699999112985, 14.072900001337985], "resource_metrics": {"samples": 3, "duration_s": 0.20888423919677734, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 10.800000000000002, "gpu_power_peak_watts": 10.989, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1556.92578125, "cpu_memory_peak_mb": 1556.92578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652010.935946}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [121.98650000027556, 122.15749999995751], "ttft_ms": [14.072899999518995, 14.63049999983923], "tokens_processed": [32, 32], "throughput_tok_s": [262.32410963449, 261.95689990390383], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.04909999857773, 14.858700000331737, 14.178400000673719], "resource_metrics": {"samples": 3, "duration_s": 0.21924757957458496, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 10.988999999999999, "gpu_power_peak_watts": 10.989, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1556.9296875, "cpu_memory_peak_mb": 1556.9296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652011.265028}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [120.2885000002425, 120.64040000041132], "ttft_ms": [14.144700000542798, 14.157900001009693], "tokens_processed": [32, 32], "throughput_tok_s": [266.0270931962365, 265.25110990920865], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [21.28209999864339, 15.268300001480384, 14.327099999718484], "resource_metrics": {"samples": 3, "duration_s": 0.2184281349182129, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 47.0, "gpu_power_mean_watts": 12.996, "gpu_power_peak_watts": 12.996, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1556.9296875, "cpu_memory_peak_mb": 1556.9296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652011.5952911}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [121.85729999873729, 124.85039999955916], "ttft_ms": [14.233399999284302, 15.213200000289362], "tokens_processed": [32, 32], "throughput_tok_s": [262.6022404922117, 256.30674791681076], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.279400000712485, 14.408600000024308, 14.361600000484032], "resource_metrics": {"samples": 3, "duration_s": 0.2164468765258789, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 47.0, "gpu_power_mean_watts": 13.358666666666666, "gpu_power_peak_watts": 13.54, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1556.94140625, "cpu_memory_peak_mb": 1556.94140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1264.3428999999742, "compile_ms": 921.5308000002551, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652011.9206333}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [4.836699999941629, 3.587600000173552], "ttft_ms": [0.5430000001069857, 0.5883999983780086], "tokens_processed": [8, 8], "throughput_tok_s": [1654.0203031191818, 2229.9029991116613], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0540000004984904, 0.41899999996530823, 0.490100001115934], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 47.0, "gpu_power_mean_watts": 13.54, "gpu_power_peak_watts": 13.54, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1563.88671875, "cpu_memory_peak_mb": 1563.88671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652012.0427883}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.1614999988960335, 2.876000000469503], "ttft_ms": [0.41290000081062317, 0.3276999996160157], "tokens_processed": [8, 8], "throughput_tok_s": [2530.444410182991, 2781.6411678351915], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6241000010049902, 0.3211999992345227, 0.31180000041786116], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 47.0, "gpu_power_mean_watts": 13.54, "gpu_power_peak_watts": 13.54, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1563.94921875, "cpu_memory_peak_mb": 1563.94921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652012.1687145}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.0303000003186753, 2.5705999996716855], "ttft_ms": [0.43290000030538067, 0.34050000067509245], "tokens_processed": [8, 8], "throughput_tok_s": [2640.0026397250094, 3112.1139037663393], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6382000010489719, 0.37179999890213367, 0.37619999966409523], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.447, "gpu_power_peak_watts": 15.447, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1564.0390625, "cpu_memory_peak_mb": 1564.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652012.294042}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.346899999087327, 3.1834000001254026], "ttft_ms": [0.392699999792967, 0.36980000004405156], "tokens_processed": [8, 8], "throughput_tok_s": [2390.2715952617455, 2513.0363761025505], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.5937999994785059, 0.35819999902741984, 0.37770000017189886], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.447, "gpu_power_peak_watts": 15.447, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1564.0703125, "cpu_memory_peak_mb": 1564.0703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652012.4198053}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [2.971700001580757, 2.3218000005726935], "ttft_ms": [0.38780000068072695, 0.28960000054212287], "tokens_processed": [8, 8], "throughput_tok_s": [2692.0617813859085, 3445.6025488959967], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.5624000004900154, 0.37650000012945384, 0.36109999928157777], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.447, "gpu_power_peak_watts": 15.447, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1564.078125, "cpu_memory_peak_mb": 1564.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652012.5459352}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.596699998524855, 4.781400000865688], "ttft_ms": [0.39139999898907263, 0.41280000004917383], "tokens_processed": [8, 8], "throughput_tok_s": [2224.2611291687126, 1673.1501230918925], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7699999987380579, 0.4138999993301695, 0.38889999996172264], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.447, "gpu_power_peak_watts": 15.447, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1565.23046875, "cpu_memory_peak_mb": 1565.23046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652012.6720645}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.510900000037509, 3.3920000005309703], "ttft_ms": [0.4048999999213265, 0.3997999992861878], "tokens_processed": [8, 8], "throughput_tok_s": [2278.6180181476348, 2358.490565668547], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6914000005053822, 0.42670000038924627, 0.4017999999632593], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 20.131, "gpu_power_peak_watts": 20.131, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1565.25390625, "cpu_memory_peak_mb": 1565.25390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652012.7964058}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.497399999105255, 3.4885999994003214], "ttft_ms": [0.4023000001325272, 0.5266999996820232], "tokens_processed": [8, 8], "throughput_tok_s": [2287.413507761952, 2293.1835124047393], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6473000012192642, 0.4063000014866702, 0.4270000008546049], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 20.131, "gpu_power_peak_watts": 20.131, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1565.2578125, "cpu_memory_peak_mb": 1565.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652012.9197407}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.472899999906076, 3.4570999996503815], "ttft_ms": [0.39029999970807694, 0.41140000030281954], "tokens_processed": [8, 8], "throughput_tok_s": [2303.55034703457, 2314.078273931632], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6420999998226762, 0.40780000017548446, 0.4119000004720874], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 20.131, "gpu_power_peak_watts": 20.131, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1565.2578125, "cpu_memory_peak_mb": 1565.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652013.0465329}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.48160000066855, 2.064000000245869], "ttft_ms": [0.44010000056005083, 0.261799999861978], "tokens_processed": [8, 8], "throughput_tok_s": [2297.7941172058277, 3875.968991786346], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6453000005421927, 0.42859999848587904, 0.4384000003483379], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 20.131, "gpu_power_peak_watts": 20.131, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1565.3125, "cpu_memory_peak_mb": 1565.3125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652013.1773577}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [5.001800000172807, 3.3610000009502983], "ttft_ms": [0.4718000000139, 0.4461999997147359], "tokens_processed": [8, 8], "throughput_tok_s": [1599.4242072301188, 2380.2439743344416], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7948999993677717, 0.5863000005774666, 0.565100001040264], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.897, "gpu_power_peak_watts": 19.897, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1576.5, "cpu_memory_peak_mb": 1576.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652013.2973475}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [4.1258000001107575, 3.7974000006215647], "ttft_ms": [0.4747000002680579, 0.4707000007329043], "tokens_processed": [8, 8], "throughput_tok_s": [1939.0178873879586, 2106.70458700441], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7317999989027157, 0.46290000136650633, 0.46939999992900994], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.897, "gpu_power_peak_watts": 19.897, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1576.5078125, "cpu_memory_peak_mb": 1576.5078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652013.4227135}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.7353000006987713, 3.6317000012786593], "ttft_ms": [0.4234000007272698, 0.42919999941659626], "tokens_processed": [8, 8], "throughput_tok_s": [2141.7289102624745, 2202.825122444953], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7516999994550133, 0.4804999989573844, 0.45390000013867393], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.897, "gpu_power_peak_watts": 19.897, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1576.5078125, "cpu_memory_peak_mb": 1576.5078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652013.546331}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.7658999990526354, 4.571299999952316], "ttft_ms": [0.4692999991675606, 0.5464000005304115], "tokens_processed": [8, 8], "throughput_tok_s": [2124.3261908209224, 1750.0492201525713], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7334999991144286, 0.4851000012422446, 0.4647999994631391], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.897, "gpu_power_peak_watts": 19.897, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1576.5078125, "cpu_memory_peak_mb": 1576.5078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652013.6723053}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.3759000016289065, 4.143199999816716], "ttft_ms": [0.47199999971780926, 0.5160000000614673], "tokens_processed": [8, 8], "throughput_tok_s": [2369.7384389762487, 1930.8746863182803], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7869000000937376, 0.49650000073597766, 0.4690000005211914], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.897, "gpu_power_peak_watts": 19.897, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1576.53125, "cpu_memory_peak_mb": 1576.53125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652013.798377}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [4.782800000612042, 4.191300000456977], "ttft_ms": [0.5318000003171619, 0.49390000094717834], "tokens_processed": [8, 8], "throughput_tok_s": [1672.6603660985745, 1908.7156727334625], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1044000002584653, 0.5414000006567221, 0.562299999728566], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.897, "gpu_power_peak_watts": 19.897, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1579.6796875, "cpu_memory_peak_mb": 1579.6796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652013.9244714}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [4.153299998506554, 2.9762000012851786], "ttft_ms": [0.42050000047311187, 0.3586999991966877], "tokens_processed": [8, 8], "throughput_tok_s": [1926.179183511098, 2687.9913972668005], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7439999990310753, 0.5154000009497395, 0.5654000015056226], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.897, "gpu_power_peak_watts": 19.897, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1579.68359375, "cpu_memory_peak_mb": 1579.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652014.0506384}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.897599999618251, 3.325399999084766], "ttft_ms": [0.5010000004403992, 0.411899998653098], "tokens_processed": [8, 8], "throughput_tok_s": [2052.545156194468, 2405.725627654358], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7944000008137664, 0.5464000005304115, 0.5292000005283626], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.897, "gpu_power_peak_watts": 19.897, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1579.703125, "cpu_memory_peak_mb": 1579.703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652014.176806}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.7268999985826667, 3.6015999994560843], "ttft_ms": [0.5849999997735722, 0.46690000090165995], "tokens_processed": [8, 8], "throughput_tok_s": [2146.556119842868, 2221.235006999157], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7953999993333127, 0.5332999990059761, 0.5249999994703103], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.704, "gpu_power_peak_watts": 17.704, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1579.703125, "cpu_memory_peak_mb": 1579.703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652014.3020902}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [4.942399998981273, 4.391200000100071], "ttft_ms": [0.622200001089368, 0.5737999999837484], "tokens_processed": [8, 8], "throughput_tok_s": [1618.646811599417, 1821.825469078541], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8207000009861076, 0.5483999993884936, 0.6094000000302913], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.704, "gpu_power_peak_watts": 17.704, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1579.765625, "cpu_memory_peak_mb": 1579.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652014.4278655}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [7.1095000002969755, 4.78810000095109], "ttft_ms": [0.6153000013000565, 0.5811000009998679], "tokens_processed": [32, 32], "throughput_tok_s": [4501.019762101879, 6683.235520069264], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0765999997820472, 0.7303000002139015, 0.6626999984291615], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.704, "gpu_power_peak_watts": 17.704, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1603.4375, "cpu_memory_peak_mb": 1603.4375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652014.5519977}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [6.227400001080241, 5.842300000949763], "ttft_ms": [0.7298999989870936, 0.7177000006777234], "tokens_processed": [32, 32], "throughput_tok_s": [5138.581108399829, 5477.294900090353], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1549000009836163, 0.8107000012387289, 0.7519999999203719], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.704, "gpu_power_peak_watts": 17.704, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1603.4375, "cpu_memory_peak_mb": 1603.4375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652014.6772516}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [8.080300000074203, 11.173900000358117], "ttft_ms": [0.8225999990827404, 0.9903999998641666], "tokens_processed": [32, 32], "throughput_tok_s": [3960.2490006195485, 2863.816572456745], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2888000001112232, 0.9322999994765269, 0.8376000005227979], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.704, "gpu_power_peak_watts": 17.704, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1603.4453125, "cpu_memory_peak_mb": 1603.4453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652014.8012712}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [6.502500000351574, 5.882199999177828], "ttft_ms": [0.857999999425374, 0.724600000467035], "tokens_processed": [32, 32], "throughput_tok_s": [4921.184159672409, 5440.14144443792], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2148999994678888, 0.8099999995465623, 0.765799999498995], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.704, "gpu_power_peak_watts": 17.704, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1603.5, "cpu_memory_peak_mb": 1603.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652014.9260776}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [6.762900000467198, 6.04380000004312], "ttft_ms": [0.7347000009758631, 0.758099999075057], "tokens_processed": [32, 32], "throughput_tok_s": [4731.697939905863, 5294.68215357419], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2900000001536682, 0.8476000002701767, 0.8328000003530178], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.704, "gpu_power_peak_watts": 17.704, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1603.5, "cpu_memory_peak_mb": 1603.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652015.0497508}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [12.585200000103214, 8.362599999600207], "ttft_ms": [1.0724000003392575, 1.2181000001874054], "tokens_processed": [32, 32], "throughput_tok_s": [2542.669166937161, 3826.561117538784], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.395900000919937, 0.9850999995251186, 0.9066999991773628], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.704, "gpu_power_peak_watts": 17.704, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1632.484375, "cpu_memory_peak_mb": 1632.484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652015.1749196}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [8.282600001621176, 9.979599999496713], "ttft_ms": [0.8336999999301042, 1.283200001125806], "tokens_processed": [32, 32], "throughput_tok_s": [3863.521115801385, 3206.5413445041695], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6813999991427409, 1.0196999992331257, 0.9558000001561595], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 4.336, "gpu_power_peak_watts": 4.336, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1632.48828125, "cpu_memory_peak_mb": 1632.48828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652015.3029594}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [8.007599999473314, 9.27860000047076], "ttft_ms": [0.7712999995419523, 0.9484000001975801], "tokens_processed": [32, 32], "throughput_tok_s": [3996.2036068365983, 3448.796154417309], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3251999989734031, 0.9200000004057074, 0.8094000004348345], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 4.336, "gpu_power_peak_watts": 4.336, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1632.55859375, "cpu_memory_peak_mb": 1632.55859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652015.4264247}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [6.7466000000422355, 6.238600000870065], "ttft_ms": [0.809899998785113, 0.7179000003816327], "tokens_processed": [32, 32], "throughput_tok_s": [4743.129872795137, 5129.355944528761], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.515300000392017, 0.9144999985437607, 0.866999998834217], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 4.336, "gpu_power_peak_watts": 4.336, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1632.55859375, "cpu_memory_peak_mb": 1632.55859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652015.552421}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [8.522800000719144, 8.494399999108282], "ttft_ms": [0.8663999997224892, 1.0645000002114102], "tokens_processed": [32, 32], "throughput_tok_s": [3754.634626801037, 3767.187794707015], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.600900000994443, 0.9550000013405224, 0.8981000009953277], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 654.01953125, "gpu_memory_peak_mb": 654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 4.336, "gpu_power_peak_watts": 4.336, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1632.55859375, "cpu_memory_peak_mb": 1632.55859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.58059999915713, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652015.6790001}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [38.557800000489806, 33.69100000054459], "ttft_ms": [4.7048999986145645, 4.192799999145791], "tokens_processed": [8, 8], "throughput_tok_s": [207.48071725820392, 237.4521385494846], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [101.49150000142981, 4.619100000127219, 4.5862000006309245], "resource_metrics": {"samples": 2, "duration_s": 0.11881566047668457, "gpu_memory_mean_mb": 666.01953125, "gpu_memory_peak_mb": 668.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 4.336, "gpu_power_peak_watts": 4.336, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1715.203125, "cpu_memory_peak_mb": 1773.25390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652015.905285}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.378900000068825, 36.544900000080816], "ttft_ms": [4.5862000006309245, 4.601499998898362], "tokens_processed": [8, 8], "throughput_tok_s": [226.12348037910837, 218.9087943866944], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.782099998919875, 6.025599999702536, 4.612200000337907], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 668.01953125, "gpu_memory_peak_mb": 668.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 4.336, "gpu_power_peak_watts": 4.336, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1776.47265625, "cpu_memory_peak_mb": 1776.47265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652016.022721}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [34.1511000005994, 31.849099999817554], "ttft_ms": [4.32590000127675, 3.902300000845571], "tokens_processed": [8, 8], "throughput_tok_s": [234.25306944313914, 251.18449187091088], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.837199998291908, 4.369899999801419, 4.7379000006912975], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 668.01953125, "gpu_memory_peak_mb": 668.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 4.336, "gpu_power_peak_watts": 4.336, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1776.515625, "cpu_memory_peak_mb": 1776.515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652016.1476283}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.200000000259024, 34.449799999492825], "ttft_ms": [6.245299999136478, 4.256000000168569], "tokens_processed": [8, 8], "throughput_tok_s": [227.27272727105486, 232.2219577506336], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.603699999686796, 5.499900000359048, 4.92619999931776], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 668.01953125, "gpu_memory_peak_mb": 668.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 4.336, "gpu_power_peak_watts": 4.336, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1776.53515625, "cpu_memory_peak_mb": 1776.53515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652016.2702975}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.867799999919953, 30.24349999941478], "ttft_ms": [3.9758999992045574, 3.968499999245978], "tokens_processed": [8, 8], "throughput_tok_s": [267.8469790216032, 264.5196488552847], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.739399999380112, 5.222800000410643, 4.96969999949215], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 668.01953125, "gpu_memory_peak_mb": 668.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 2.378, "gpu_power_peak_watts": 2.378, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1776.53515625, "cpu_memory_peak_mb": 1776.53515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652016.3921914}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [33.099800000854884, 27.820799999972223], "ttft_ms": [4.002499999842257, 4.141499999605003], "tokens_processed": [8, 8], "throughput_tok_s": [241.69330327655697, 287.55463538100946], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.874200000311248, 4.7481000001425855, 4.086900000402238], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 668.01953125, "gpu_memory_peak_mb": 668.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 2.378, "gpu_power_peak_watts": 2.378, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1777.11328125, "cpu_memory_peak_mb": 1777.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652016.5165331}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.755100000926177, 23.250100000950624], "ttft_ms": [3.2006999990699114, 2.916799998274655], "tokens_processed": [8, 8], "throughput_tok_s": [336.76978836915407, 344.08454155779566], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.793799998878967, 4.484499999307445, 4.032100001495564], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 668.01953125, "gpu_memory_peak_mb": 668.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 2.378, "gpu_power_peak_watts": 2.378, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1777.77734375, "cpu_memory_peak_mb": 1777.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652016.6429014}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.88719999908062, 23.354099999778555], "ttft_ms": [3.413200000068173, 2.894600000217906], "tokens_processed": [8, 8], "throughput_tok_s": [334.90739811731413, 342.55227133890224], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.158199999641511, 4.565200000797631, 4.218899999614223], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 668.01953125, "gpu_memory_peak_mb": 668.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 2.378, "gpu_power_peak_watts": 2.378, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1777.7890625, "cpu_memory_peak_mb": 1777.7890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652016.76751}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.383799998555332, 23.412000000462285], "ttft_ms": [2.9418000012810808, 2.981300000101328], "tokens_processed": [8, 8], "throughput_tok_s": [342.1171922653395, 341.70510848462476], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.404199999044067, 3.275200000643963, 3.281000001152279], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 668.01953125, "gpu_memory_peak_mb": 668.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 11.928, "gpu_power_peak_watts": 11.928, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1777.796875, "cpu_memory_peak_mb": 1777.796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652016.901013}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.564699999042205, 23.336799999015057], "ttft_ms": [2.990399998452631, 3.1335000003309688], "tokens_processed": [8, 8], "throughput_tok_s": [339.49084861361115, 342.8062116630234], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.1482000015093945, 3.0370000004040776, 2.9663000004802598], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 668.01953125, "gpu_memory_peak_mb": 668.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 11.928, "gpu_power_peak_watts": 11.928, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1777.796875, "cpu_memory_peak_mb": 1777.796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652017.0310194}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.115799999795854, 25.66809999916586], "ttft_ms": [3.2284999997500563, 3.1565000008413335], "tokens_processed": [8, 8], "throughput_tok_s": [284.5375198307744, 311.6709066997548], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.053100000528502, 3.4280999989277916, 3.245900001275004], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 676.01953125, "gpu_memory_peak_mb": 676.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 11.928, "gpu_power_peak_watts": 11.928, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1783.546875, "cpu_memory_peak_mb": 1783.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652017.1555474}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [25.807599999097874, 25.909300000421354], "ttft_ms": [3.177000000505359, 3.2102000004670117], "tokens_processed": [8, 8], "throughput_tok_s": [309.986205624686, 308.76943799600525], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.686500000185333, 3.5884000008081784, 3.356799999892246], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 676.01953125, "gpu_memory_peak_mb": 676.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 11.928, "gpu_power_peak_watts": 11.928, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1789.30078125, "cpu_memory_peak_mb": 1789.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652017.2811897}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [26.41380000022764, 26.209600000584032], "ttft_ms": [3.636200000983081, 3.304500000012922], "tokens_processed": [8, 8], "throughput_tok_s": [302.8719835817283, 305.2316708313646], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.50199999997858, 5.103999999846565, 4.682200000388548], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 676.01953125, "gpu_memory_peak_mb": 676.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 43.0, "gpu_power_mean_watts": 12.536, "gpu_power_peak_watts": 12.536, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1789.30078125, "cpu_memory_peak_mb": 1789.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652017.4062262}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [26.20310000020254, 25.771700000404962], "ttft_ms": [3.431200000704848, 3.134800001134863], "tokens_processed": [8, 8], "throughput_tok_s": [305.3073872915099, 310.4180166568093], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.1216000010754215, 4.243600000336301, 3.52510000084294], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 676.01953125, "gpu_memory_peak_mb": 676.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 43.0, "gpu_power_mean_watts": 12.536, "gpu_power_peak_watts": 12.536, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1789.30078125, "cpu_memory_peak_mb": 1789.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652017.5276868}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [24.9880999999732, 25.478600000496954], "ttft_ms": [3.2886999997572275, 3.1853000000410248], "tokens_processed": [8, 8], "throughput_tok_s": [320.15239253919185, 313.988994679612], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.44140000056359, 4.5796000013069715, 3.2715999986976385], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 676.01953125, "gpu_memory_peak_mb": 676.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 43.0, "gpu_power_mean_watts": 12.536, "gpu_power_peak_watts": 12.536, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1789.30078125, "cpu_memory_peak_mb": 1789.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652017.6512794}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.71650000048976, 34.60129999984929], "ttft_ms": [3.80580000091868, 4.459800000404357], "tokens_processed": [8, 8], "throughput_tok_s": [223.98611285793123, 231.2051859333275], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.440699999278877, 4.616500000338419, 3.972500000600121], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 676.01953125, "gpu_memory_peak_mb": 676.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 43.0, "gpu_power_mean_watts": 12.536, "gpu_power_peak_watts": 12.536, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1790.8203125, "cpu_memory_peak_mb": 1790.8203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652017.773932}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [33.421799998905044, 33.64470000087749], "ttft_ms": [4.064499999003601, 4.118400000152178], "tokens_processed": [8, 8], "throughput_tok_s": [239.36472602499248, 237.77890722138557], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.395699999804492, 4.0442000008624746, 4.051300000355695], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 676.01953125, "gpu_memory_peak_mb": 676.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 43.0, "gpu_power_mean_watts": 12.701, "gpu_power_peak_watts": 12.701, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1792.3203125, "cpu_memory_peak_mb": 1792.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652017.8989308}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.62830000089889, 33.32520000003569], "ttft_ms": [3.959499999837135, 3.8930999999138294], "tokens_processed": [8, 8], "throughput_tok_s": [261.19634454949227, 240.05857429187017], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.1507000005367445, 3.8180000010470394, 3.64619999891147], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 676.01953125, "gpu_memory_peak_mb": 676.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 43.0, "gpu_power_mean_watts": 12.701, "gpu_power_peak_watts": 12.701, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1792.3203125, "cpu_memory_peak_mb": 1792.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652018.0224683}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.592999999498716, 31.093999999939115], "ttft_ms": [3.736300001037307, 3.8741999997000676], "tokens_processed": [8, 8], "throughput_tok_s": [261.49772824277073, 257.2843635433095], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.093300000022282, 3.8344999993569218, 3.8942999999562744], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 676.01953125, "gpu_memory_peak_mb": 676.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 43.0, "gpu_power_mean_watts": 12.701, "gpu_power_peak_watts": 12.701, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1792.33984375, "cpu_memory_peak_mb": 1792.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652018.1463394}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.81759999966016, 29.342100000576465], "ttft_ms": [3.786299999774201, 3.56620000093244], "tokens_processed": [8, 8], "throughput_tok_s": [268.2979180112141, 272.6457888100316], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.833900000245194, 3.8337999994837446, 3.911300000254414], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 676.01953125, "gpu_memory_peak_mb": 676.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 43.0, "gpu_power_mean_watts": 12.701, "gpu_power_peak_watts": 12.701, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1792.33984375, "cpu_memory_peak_mb": 1792.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652018.2709832}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [51.739200000156416, 52.10900000020047], "ttft_ms": [6.435600000259001, 6.26399999964633], "tokens_processed": [32, 32], "throughput_tok_s": [618.4865633775408, 614.0973728123145], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.307099999205093, 6.232300000192481, 6.48430000001099], "resource_metrics": {"samples": 2, "duration_s": 0.11660218238830566, "gpu_memory_mean_mb": 692.01953125, "gpu_memory_peak_mb": 692.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 12.949, "gpu_power_peak_watts": 12.949, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1808.869140625, "cpu_memory_peak_mb": 1816.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652018.4961178}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [51.710300000195275, 50.538999999844236], "ttft_ms": [6.506499999886728, 6.634099998336751], "tokens_processed": [32, 32], "throughput_tok_s": [618.8322249122352, 633.1743801835934], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.411099999240832, 6.247400000574999, 6.095700000514626], "resource_metrics": {"samples": 2, "duration_s": 0.12077808380126953, "gpu_memory_mean_mb": 692.01953125, "gpu_memory_peak_mb": 692.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 12.949, "gpu_power_peak_watts": 12.949, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1816.796875, "cpu_memory_peak_mb": 1816.796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652018.7274077}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.981500001464156, 29.260499999509193], "ttft_ms": [3.555699999196804, 3.7969999993947567], "tokens_processed": [32, 32], "throughput_tok_s": [1104.1526490479564, 1093.6245108776939], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.15430000066408, 4.004399999757879, 3.6313000000518514], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 692.01953125, "gpu_memory_peak_mb": 692.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 13.228, "gpu_power_peak_watts": 13.228, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1816.81640625, "cpu_memory_peak_mb": 1816.81640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652018.8440156}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.514499998593237, 32.28350000063074], "ttft_ms": [3.7182000014581718, 3.941000000850181], "tokens_processed": [32, 32], "throughput_tok_s": [1015.4056069881622, 991.2184242530952], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.479200000787387, 3.810299998804112, 3.8231999988056486], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 692.01953125, "gpu_memory_peak_mb": 692.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 13.228, "gpu_power_peak_watts": 13.228, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1816.81640625, "cpu_memory_peak_mb": 1816.81640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652018.9692965}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.521499999143998, 30.500300001222058], "ttft_ms": [3.772600000957027, 3.752800001166179], "tokens_processed": [32, 32], "throughput_tok_s": [1015.1801151870627, 1049.1700081218169], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.275300000197603, 5.197100001169019, 4.038700000819517], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 692.01953125, "gpu_memory_peak_mb": 692.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 13.228, "gpu_power_peak_watts": 13.228, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1816.82421875, "cpu_memory_peak_mb": 1816.82421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652019.0953472}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [44.31739999927231, 38.49459999946703], "ttft_ms": [4.806999999345862, 4.743000001326436], "tokens_processed": [32, 32], "throughput_tok_s": [722.0640200130296, 831.2854270584199], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.04009999956179, 5.129499999384279, 4.87520000024233], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 724.01953125, "gpu_memory_peak_mb": 724.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 13.228, "gpu_power_peak_watts": 13.228, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1823.953125, "cpu_memory_peak_mb": 1823.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652019.2191172}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [38.817199998447904, 39.388199998938944], "ttft_ms": [4.731600000013714, 4.746300000988413], "tokens_processed": [32, 32], "throughput_tok_s": [824.3768226785938, 812.4260565565837], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.200199999308097, 4.635400000552181, 4.61639999957697], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 724.01953125, "gpu_memory_peak_mb": 724.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 16.432, "gpu_power_peak_watts": 16.432, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1846.6953125, "cpu_memory_peak_mb": 1846.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652019.3446686}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [39.005600001473795, 39.92119999929855], "ttft_ms": [4.874799999015522, 4.7582999995938735], "tokens_processed": [32, 32], "throughput_tok_s": [820.3950201712294, 801.5791108624558], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.556500000646338, 7.15190000119037, 5.415099998572259], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 724.01953125, "gpu_memory_peak_mb": 724.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 16.432, "gpu_power_peak_watts": 16.432, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1846.6953125, "cpu_memory_peak_mb": 1846.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652019.467229}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [38.57389999939187, 39.52239999853191], "ttft_ms": [4.78819999989355, 4.770899999130052], "tokens_processed": [32, 32], "throughput_tok_s": [829.5764752981806, 809.6674291335714], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.147899999428773, 4.864300000917865, 4.903999999442021], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 724.01953125, "gpu_memory_peak_mb": 724.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 16.432, "gpu_power_peak_watts": 16.432, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1846.70703125, "cpu_memory_peak_mb": 1846.70703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652019.591247}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [37.56910000083735, 39.204000000609085], "ttft_ms": [4.531399999905261, 4.788700000062818], "tokens_processed": [32, 32], "throughput_tok_s": [851.7638165217365, 816.2432404729833], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.807400000776397, 4.286699999283883, 4.5339999996940605], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 724.01953125, "gpu_memory_peak_mb": 724.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 16.432, "gpu_power_peak_watts": 16.432, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1846.70703125, "cpu_memory_peak_mb": 1846.70703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1948.9979999998468, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765652019.718586}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.7147000002732966, 0.9520999992673751, 0.8952000007411698], "resource_metrics": {"samples": 3, "duration_s": 0.21340107917785645, "gpu_memory_mean_mb": 788.359375, "gpu_memory_peak_mb": 909.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 19.838, "gpu_power_peak_watts": 19.838, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1933.7630208333333, "cpu_memory_peak_mb": 2021.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1765652020.0438669}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.695700000913348, 1.3730999999097548, 1.413699999829987], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 19.838, "gpu_power_peak_watts": 19.838, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2037.6875, "cpu_memory_peak_mb": 2037.6875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652020.1729448}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8780000011465745, 1.3899999994464451, 1.3512000004993752], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 22.676, "gpu_power_peak_watts": 22.676, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2037.71484375, "cpu_memory_peak_mb": 2037.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652020.2976105}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.730399999563815, 1.4425000008486677, 1.4697999995405553], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 22.676, "gpu_power_peak_watts": 22.676, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2037.71875, "cpu_memory_peak_mb": 2037.71875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652020.4198816}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.200700000685174, 0.9620999990147538, 0.9255000004486647], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 22.676, "gpu_power_peak_watts": 22.676, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2037.72265625, "cpu_memory_peak_mb": 2037.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652020.5446467}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.6889000002702232, 1.6104000005725538, 1.4403999994101468], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 22.676, "gpu_power_peak_watts": 22.676, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2038.30859375, "cpu_memory_peak_mb": 2038.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652020.667535}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.373900000748108, 1.08639999962179, 0.969700000496232], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 26.691, "gpu_power_peak_watts": 26.691, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2038.30859375, "cpu_memory_peak_mb": 2038.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652020.7932444}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.97839999984717, 1.5509999993810197, 1.5518000000156462], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 26.691, "gpu_power_peak_watts": 26.691, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2038.30859375, "cpu_memory_peak_mb": 2038.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652020.916791}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.6859999998123385, 1.648500001465436, 1.5631999995093793], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 26.691, "gpu_power_peak_watts": 26.691, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2038.30859375, "cpu_memory_peak_mb": 2038.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652021.0394893}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.745600000707782, 1.2679000010393793, 1.1088999999628868], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 26.691, "gpu_power_peak_watts": 26.691, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2038.30859375, "cpu_memory_peak_mb": 2038.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652021.162302}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.897399999710615, 1.5995999983715592, 1.5999000006559072], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 957.0390625, "gpu_memory_peak_mb": 957.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 26.691, "gpu_power_peak_watts": 26.691, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2039.84765625, "cpu_memory_peak_mb": 2039.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652021.2877355}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.939399999580928, 1.849700000093435, 1.8681000001379289], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 957.0390625, "gpu_memory_peak_mb": 957.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.474, "gpu_power_peak_watts": 29.474, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2039.84765625, "cpu_memory_peak_mb": 2039.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652021.410128}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.372500001001754, 1.388000000588363, 1.6317999998136656], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 957.0390625, "gpu_memory_peak_mb": 957.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.474, "gpu_power_peak_watts": 29.474, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2039.86328125, "cpu_memory_peak_mb": 2039.86328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652021.5321615}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.933899999537971, 1.7298999991908204, 1.410099999702652], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 957.0390625, "gpu_memory_peak_mb": 957.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.474, "gpu_power_peak_watts": 29.474, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2039.86328125, "cpu_memory_peak_mb": 2039.86328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652021.6545446}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.822099999320926, 1.12999999873864, 1.1178000004292699], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 957.0390625, "gpu_memory_peak_mb": 957.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.474, "gpu_power_peak_watts": 29.474, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2039.8671875, "cpu_memory_peak_mb": 2039.8671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652021.778141}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.064299999503419, 2.2850000004837057, 2.605200001198682], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 959.0390625, "gpu_memory_peak_mb": 959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.493, "gpu_power_peak_watts": 29.493, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2041.3984375, "cpu_memory_peak_mb": 2041.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652021.903314}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.130600000076811, 1.9313000011607073, 1.6816999996080995], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 959.0390625, "gpu_memory_peak_mb": 959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.493, "gpu_power_peak_watts": 29.493, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2041.41015625, "cpu_memory_peak_mb": 2041.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652022.0280669}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.377499999463907, 2.295800000865711, 2.2475999994640006], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 959.0390625, "gpu_memory_peak_mb": 959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.493, "gpu_power_peak_watts": 29.493, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2041.41015625, "cpu_memory_peak_mb": 2041.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652022.1649795}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.956399999675341, 1.566599999932805, 1.495700000305078], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 959.0390625, "gpu_memory_peak_mb": 959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.493, "gpu_power_peak_watts": 29.493, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2041.41015625, "cpu_memory_peak_mb": 2041.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652022.2887726}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.303800000139745, 1.48559999979625, 1.5090999986568931], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 959.0390625, "gpu_memory_peak_mb": 959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.531, "gpu_power_peak_watts": 29.531, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2041.41015625, "cpu_memory_peak_mb": 2041.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652022.4148455}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [45.66789999989851, 2.8739999997924315, 2.9120999988663243], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 951.0390625, "gpu_memory_peak_mb": 951.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.531, "gpu_power_peak_watts": 29.531, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2037.26171875, "cpu_memory_peak_mb": 2037.26171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652022.5380359}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [9.115300001212745, 3.7769999998999992, 3.2006999990699114], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 967.0390625, "gpu_memory_peak_mb": 967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.531, "gpu_power_peak_watts": 29.531, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2148.4453125, "cpu_memory_peak_mb": 2148.4453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652022.6638033}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.390099999407539, 2.5686999997560633, 2.4966000000858912], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 967.0390625, "gpu_memory_peak_mb": 967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.531, "gpu_power_peak_watts": 29.531, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2148.46875, "cpu_memory_peak_mb": 2148.46875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652022.7901578}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.89409999945201, 2.9574999989563366, 2.9402999989542877], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 967.0390625, "gpu_memory_peak_mb": 967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.533, "gpu_power_peak_watts": 29.533, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2148.515625, "cpu_memory_peak_mb": 2148.515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652022.9279647}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.163399999626563, 2.9900999998062616, 3.1029000001581153], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 967.0390625, "gpu_memory_peak_mb": 967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.533, "gpu_power_peak_watts": 29.533, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2148.51953125, "cpu_memory_peak_mb": 2148.51953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652023.0535967}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.784099999204045, 4.022000000986736, 4.152299999987008], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 973.0390625, "gpu_memory_peak_mb": 973.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.533, "gpu_power_peak_watts": 29.533, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2143.15625, "cpu_memory_peak_mb": 2143.15625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652023.1773238}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.95799999954761, 4.433799998878385, 4.043400000227848], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 973.0390625, "gpu_memory_peak_mb": 973.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 29.584, "gpu_power_peak_watts": 29.584, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2143.47265625, "cpu_memory_peak_mb": 2143.47265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652023.3002884}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.336800000004587, 4.639100001440966, 3.9871999997558305], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 973.0390625, "gpu_memory_peak_mb": 973.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 29.584, "gpu_power_peak_watts": 29.584, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2149.01171875, "cpu_memory_peak_mb": 2149.01171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652023.423538}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.995100001513492, 3.6278999996284256, 3.321700000014971], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 973.0390625, "gpu_memory_peak_mb": 973.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 29.584, "gpu_power_peak_watts": 29.584, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2151.82421875, "cpu_memory_peak_mb": 2151.82421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652023.549634}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [9.56170000063139, 4.032599999845843, 3.9438999992853496], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 973.0390625, "gpu_memory_peak_mb": 973.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 29.584, "gpu_power_peak_watts": 29.584, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2143.35546875, "cpu_memory_peak_mb": 2143.35546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 255.49680000040098, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652023.6740937}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.6675999999715714, 0.893000000360189, 0.9065999984159134], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 951.0390625, "gpu_memory_peak_mb": 951.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 29.684, "gpu_power_peak_watts": 29.684, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2136.72265625, "cpu_memory_peak_mb": 2136.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765652023.7955246}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.275099999678787, 1.2311000009503914, 1.2718999987555435], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 29.684, "gpu_power_peak_watts": 29.684, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2145.8046875, "cpu_memory_peak_mb": 2145.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652023.9203646}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.195400000346126, 1.5053000006446382, 1.4774999999644933], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 29.684, "gpu_power_peak_watts": 29.684, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2145.8046875, "cpu_memory_peak_mb": 2145.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652024.0451763}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.5918000008241506, 0.8911999993870268, 0.9669000010035234], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 29.684, "gpu_power_peak_watts": 29.684, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2145.8046875, "cpu_memory_peak_mb": 2145.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652024.1709065}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.555499999289168, 1.5067000003909925, 1.3901000002078945], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.626, "gpu_power_peak_watts": 29.626, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2145.81640625, "cpu_memory_peak_mb": 2145.81640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652024.2965853}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.246099999363651, 1.6293999997287756, 1.3441999999486143], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.626, "gpu_power_peak_watts": 29.626, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2146.4140625, "cpu_memory_peak_mb": 2146.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652024.4213715}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2444000007672003, 1.5776000000187196, 1.6039000001910608], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.626, "gpu_power_peak_watts": 29.626, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2146.4140625, "cpu_memory_peak_mb": 2146.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652024.5447757}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8631999994104262, 1.3553000007959781, 1.2747000000672415], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.626, "gpu_power_peak_watts": 29.626, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2146.4296875, "cpu_memory_peak_mb": 2146.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652024.667927}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.937700000780751, 0.9503999990556622, 0.9012000009533949], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.477, "gpu_power_peak_watts": 29.477, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2146.4296875, "cpu_memory_peak_mb": 2146.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652024.793469}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.684600000065984, 1.507099999798811, 1.5376999999716645], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 955.0390625, "gpu_memory_peak_mb": 955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.477, "gpu_power_peak_watts": 29.477, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2146.44140625, "cpu_memory_peak_mb": 2146.44140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652024.9182224}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.348000000391039, 1.9531999987520976, 1.748099999531405], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 957.0390625, "gpu_memory_peak_mb": 957.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.477, "gpu_power_peak_watts": 29.477, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2147.9765625, "cpu_memory_peak_mb": 2147.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652025.0428112}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8722999995807186, 1.5008999998826766, 1.355899999907706], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 957.0390625, "gpu_memory_peak_mb": 957.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.477, "gpu_power_peak_watts": 29.477, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2147.9765625, "cpu_memory_peak_mb": 2147.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652025.1648495}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.580500000680331, 1.622400000997004, 1.5786000003572553], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 957.0390625, "gpu_memory_peak_mb": 957.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.477, "gpu_power_peak_watts": 29.477, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2147.9765625, "cpu_memory_peak_mb": 2147.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652025.28881}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.02270000045246, 1.1897000003955327, 1.1816000005637761], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 957.0390625, "gpu_memory_peak_mb": 957.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.445, "gpu_power_peak_watts": 29.445, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2147.9765625, "cpu_memory_peak_mb": 2147.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652025.4145389}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.6123999998380896, 1.571900000271853, 1.414999998814892], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 957.0390625, "gpu_memory_peak_mb": 957.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.445, "gpu_power_peak_watts": 29.445, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2147.9765625, "cpu_memory_peak_mb": 2147.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652025.539261}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.638300001010066, 2.2707999996782746, 2.1744000005128328], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 959.0390625, "gpu_memory_peak_mb": 959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.445, "gpu_power_peak_watts": 29.445, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2149.5078125, "cpu_memory_peak_mb": 2149.5078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652025.6644204}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.214500000467524, 1.6529000004084082, 1.6298999998980435], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 959.0390625, "gpu_memory_peak_mb": 959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.463, "gpu_power_peak_watts": 29.463, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2149.51171875, "cpu_memory_peak_mb": 2149.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652025.8047333}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.880599999523838, 2.48239999928046, 2.593400000478141], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 959.0390625, "gpu_memory_peak_mb": 959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.463, "gpu_power_peak_watts": 29.463, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2149.51171875, "cpu_memory_peak_mb": 2149.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652025.941116}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.802999999403255, 1.7394999995303806, 1.548700000057579], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 959.0390625, "gpu_memory_peak_mb": 959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.463, "gpu_power_peak_watts": 29.463, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2149.51171875, "cpu_memory_peak_mb": 2149.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652026.0660372}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2244000012724428, 2.6561000013316516, 2.653900000950671], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 959.0390625, "gpu_memory_peak_mb": 959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.463, "gpu_power_peak_watts": 29.463, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2149.51171875, "cpu_memory_peak_mb": 2149.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652026.1901064}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x19", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x19"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652026.3161714}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x19", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x19"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652026.4402587}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x19", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x19"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652026.5639975}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x19", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x19"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652026.6878502}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x19", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x19"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652026.8121076}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x27", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x27"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652026.9361427}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x27", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x27"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652027.0585368}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x27", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x27"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652027.196874}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x27", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x27"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652027.319584}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x27", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x27"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 46.81760000130453, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652027.4432318}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.14300000052026, 3.3505999999761116, 3.296399998362176], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 951.0390625, "gpu_memory_peak_mb": 951.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 12.233, "gpu_power_peak_watts": 12.233, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2148.984375, "cpu_memory_peak_mb": 2148.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1765652027.5689232}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.726600001755287, 6.277099999351776, 2.6819999984581955], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 961.0390625, "gpu_memory_peak_mb": 961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 12.233, "gpu_power_peak_watts": 12.233, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2151.60546875, "cpu_memory_peak_mb": 2151.60546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652027.6913767}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.4890000006271293, 6.309599999440252, 3.490199998850585], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 961.0390625, "gpu_memory_peak_mb": 961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 7.049, "gpu_power_peak_watts": 7.049, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2151.60546875, "cpu_memory_peak_mb": 2151.60546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652027.814774}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.7406999999802792, 2.947900000435766, 2.4616000009700656], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 961.0390625, "gpu_memory_peak_mb": 961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 7.049, "gpu_power_peak_watts": 7.049, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2151.609375, "cpu_memory_peak_mb": 2151.609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652027.9385214}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.892200000336743, 3.214099999240716, 3.3848000002763], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 961.0390625, "gpu_memory_peak_mb": 961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 7.049, "gpu_power_peak_watts": 7.049, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2151.609375, "cpu_memory_peak_mb": 2151.609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652028.0636313}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.30109999999695, 6.309399999736343, 3.4445999990566634], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 961.0390625, "gpu_memory_peak_mb": 961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 7.049, "gpu_power_peak_watts": 7.049, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2152.1875, "cpu_memory_peak_mb": 2152.1875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652028.1890073}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.358600001069135, 6.191700000272249, 3.5187000012228964], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 961.0390625, "gpu_memory_peak_mb": 961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 2.265, "gpu_power_peak_watts": 2.265, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2152.1953125, "cpu_memory_peak_mb": 2152.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652028.3135712}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.204000000754604, 3.392399999938789, 3.4106999992218334], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 961.0390625, "gpu_memory_peak_mb": 961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 2.265, "gpu_power_peak_watts": 2.265, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2152.30859375, "cpu_memory_peak_mb": 2152.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652028.4384456}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.8022999999375315, 3.4106999992218334, 3.5260999993624864], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 961.0390625, "gpu_memory_peak_mb": 961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 2.265, "gpu_power_peak_watts": 2.265, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2152.30859375, "cpu_memory_peak_mb": 2152.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652028.5644743}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.719799999293173, 4.277000000001863, 3.1799999997019768], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 961.0390625, "gpu_memory_peak_mb": 961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 2.265, "gpu_power_peak_watts": 2.265, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2152.3203125, "cpu_memory_peak_mb": 2152.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652028.6887639}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.410600000890554, 5.813300000227173, 4.626899999493617], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 963.0390625, "gpu_memory_peak_mb": 963.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 2.311, "gpu_power_peak_watts": 2.311, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2153.859375, "cpu_memory_peak_mb": 2153.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652028.815528}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.279500001051929, 4.4276999997237, 4.256500000337837], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 963.0390625, "gpu_memory_peak_mb": 963.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 2.311, "gpu_power_peak_watts": 2.311, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2153.859375, "cpu_memory_peak_mb": 2153.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652028.9400525}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.683699999281089, 6.015699998897617, 4.7880999991321005], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 963.0390625, "gpu_memory_peak_mb": 963.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 2.311, "gpu_power_peak_watts": 2.311, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2153.86328125, "cpu_memory_peak_mb": 2153.86328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652029.0652194}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.373399999371031, 4.7379000006912975, 4.480199999306933], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 963.0390625, "gpu_memory_peak_mb": 963.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 2.311, "gpu_power_peak_watts": 2.311, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2153.8671875, "cpu_memory_peak_mb": 2153.8671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652029.1900518}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.736800001614029, 6.0130000001663575, 4.787699999724282], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 963.0390625, "gpu_memory_peak_mb": 963.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 2.26, "gpu_power_peak_watts": 2.26, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2153.8671875, "cpu_memory_peak_mb": 2153.8671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652029.3141384}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.6730000000679865, 5.551100000957376, 5.658000000039465], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 965.0390625, "gpu_memory_peak_mb": 965.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 2.26, "gpu_power_peak_watts": 2.26, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2152.4765625, "cpu_memory_peak_mb": 2152.4765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652029.4388444}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.696799999190262, 6.069700000807643, 5.7875000002240995], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 965.0390625, "gpu_memory_peak_mb": 965.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 2.26, "gpu_power_peak_watts": 2.26, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2155.40625, "cpu_memory_peak_mb": 2155.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652029.5764303}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.7490999990695855, 5.783500000688946, 5.880400000023656], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 965.0390625, "gpu_memory_peak_mb": 965.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 2.26, "gpu_power_peak_watts": 2.26, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2155.40625, "cpu_memory_peak_mb": 2155.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652029.7016208}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.818500000008498, 6.208099999639671, 5.884300000616349], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 965.0390625, "gpu_memory_peak_mb": 965.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 2.138, "gpu_power_peak_watts": 2.138, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2153.703125, "cpu_memory_peak_mb": 2153.703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652029.825477}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.55430000006163, 5.667800000082934, 5.241299999397597], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 965.0390625, "gpu_memory_peak_mb": 965.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 2.138, "gpu_power_peak_watts": 2.138, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2155.41015625, "cpu_memory_peak_mb": 2155.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652029.9502995}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [15.28399999915564, 11.271900000792812, 11.282899999059737], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 957.0390625, "gpu_memory_peak_mb": 957.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 2.138, "gpu_power_peak_watts": 2.138, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2150.3203125, "cpu_memory_peak_mb": 2150.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652030.0754673}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.660700000196812, 11.678499999106862, 11.416599998483434], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 975.0390625, "gpu_memory_peak_mb": 975.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 2.138, "gpu_power_peak_watts": 2.138, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2154.85546875, "cpu_memory_peak_mb": 2154.85546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652030.1993454}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.774099999660393, 11.418099998991238, 11.362200000803568], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 975.0390625, "gpu_memory_peak_mb": 975.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 2.294, "gpu_power_peak_watts": 2.294, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2156.9765625, "cpu_memory_peak_mb": 2156.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652030.323992}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.915699999211938, 10.893500000747736, 11.41009999992093], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 975.0390625, "gpu_memory_peak_mb": 975.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 2.294, "gpu_power_peak_watts": 2.294, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2167.25390625, "cpu_memory_peak_mb": 2167.25390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652030.4626174}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.509800000771065, 11.40320000013162, 10.828000000401516], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 975.0390625, "gpu_memory_peak_mb": 975.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 2.294, "gpu_power_peak_watts": 2.294, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2161.73828125, "cpu_memory_peak_mb": 2161.73828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652030.587593}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [18.202700000983896, 15.248699999574455, 15.228800000841147], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 981.0390625, "gpu_memory_peak_mb": 981.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 2.294, "gpu_power_peak_watts": 2.294, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2156.65625, "cpu_memory_peak_mb": 2156.65625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652030.7127774}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.375499999616295, 15.070299999933923, 15.369400000054156], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 981.0390625, "gpu_memory_peak_mb": 981.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 2.553, "gpu_power_peak_watts": 2.553, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2173.39453125, "cpu_memory_peak_mb": 2173.39453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652030.8581722}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.57989999896381, 15.341199999966193, 15.315900000132388], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 981.0390625, "gpu_memory_peak_mb": 981.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 2.553, "gpu_power_peak_watts": 2.553, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2172.703125, "cpu_memory_peak_mb": 2172.703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652030.9946878}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.201000000568456, 15.22310000109428, 14.987900000051013], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 981.0390625, "gpu_memory_peak_mb": 981.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 2.553, "gpu_power_peak_watts": 2.553, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2173.3984375, "cpu_memory_peak_mb": 2173.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652031.1348257}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.186099999889848, 15.393299998322618, 15.38309999887133], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 981.0390625, "gpu_memory_peak_mb": 981.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 2.553, "gpu_power_peak_watts": 2.553, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2153.82421875, "cpu_memory_peak_mb": 2153.82421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765651904.0839114}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.033379799999238, "file_size_mb": 5.254772186279297, "engine_sha256": "90ea8ae5766bb280678e9ef367aacf434d7306ac66f8ef2bf644490b5284586d", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp32.plan", "exists": true, "file_size_bytes": 5510028, "file_size_mb": 5.254772186279297, "deserialize_error": null, "num_layers": 163, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 143, "Int64": 45}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651919.2726154, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651921.2635715, "build_time_s": null, "file_size_mb": 2.165760040283203, "built": false, "reused": true, "error": null, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 30.763751300000877, "file_size_mb": 3.624164581298828, "engine_sha256": "4195617e79344977b1bc0ce343d29afa80c9855260a913e08a82a4ca179baeed", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "exists": true, "file_size_bytes": 3800212, "file_size_mb": 3.624164581298828, "deserialize_error": null, "num_layers": 186, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 171, "Int64": 46}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\calib\\tiny-gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 9475, "cache_sha256_after": "c14a2b4de50ee740799db69cadfd5014b5353016155a312d8e171971af446c62"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765651952.2570565, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 45.45049999978801, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652031.2593336}
