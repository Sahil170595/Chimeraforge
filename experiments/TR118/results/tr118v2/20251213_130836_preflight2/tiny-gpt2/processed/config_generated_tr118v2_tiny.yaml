model:
  name: models/tiny-gpt2
  description: Tiny/toy model run
onnx:
  opset_version: 17
  dynamic_axes: true
  trt_friendly_inputs: true
  optimize_for_inference: true
tensorrt:
  precisions:
  - fp16
  workspace_gb: 2
  dynamic_shapes:
    enabled: true
    profiles:
    - name: smoke
      min_shape:
      - 1
      - 8
      opt_shape:
      - 1
      - 32
      max_shape:
      - 1
      - 64
benchmark:
  prompt_config_path: scripts/tr117/configs/matrix_tier3.yaml
  modes:
  - prefill
  - generate
  backends:
  - transformers-gpu-compile
  - onnxruntime-gpu
  - tensorrt-fp16
  scenarios:
  - single_short
  repetitions: 1
  warmup_runs: 1
  timeout_s: 30
  max_seq_len: 64
  max_new_tokens: 8
  stop_on_eos: true
  enable_resource_monitoring: false
accuracy:
  perplexity_dataset: wikitext-2-raw-v1
  perplexity_samples: 32
  perplexity_batch_size: 4
  perplexity_max_length: 64
  perplexity_thresholds:
    fp16: 0.01
baseline:
  backend: transformers-gpu-compile
output:
  onnx_dir: C:/Users/sahil/OneDrive/Documents/GitHub/Banterhearts/artifacts/tr118v2/tiny-gpt2/onnx
  tensorrt_dir: C:/Users/sahil/OneDrive/Documents/GitHub/Banterhearts/artifacts/tr118v2/tiny-gpt2/tensorrt
  results_dir: C:/Users/sahil/OneDrive/Documents/GitHub/Banterhearts/scripts/tr118/results/tr118v2/20251213_130836_preflight2/tiny-gpt2
seed: 42
torch_deterministic: true
