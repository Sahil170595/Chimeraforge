{
  "tr": "TR118",
  "started_at": 1765649316.6944213,
  "run_id": 1765649316,
  "config_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\results\\tr118v2\\20251213_130836_preflight2\\tiny-gpt2\\processed\\config_generated_tr118v2_tiny.yaml",
  "prompt_config_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr117\\configs\\matrix_tier3.yaml",
  "git_sha": "f73684a2d4d8a87c52032f18dcff57dc3c9584f6",
  "platform": {
    "python": "3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]",
    "os": "Windows-11-10.0.26200-SP0",
    "machine": "AMD64",
    "cuda_device": {
      "index": 0,
      "name": "NVIDIA GeForce RTX 4080 Laptop GPU",
      "capability": "8.9",
      "total_memory_mb": 12281.5
    },
    "onnxruntime_providers": [
      "TensorrtExecutionProvider",
      "CUDAExecutionProvider",
      "CPUExecutionProvider"
    ]
  },
  "package_versions": {
    "torch": "2.8.0+cu128",
    "transformers": "4.57.0",
    "onnx": "1.19.0",
    "onnxruntime": "1.23.2",
    "tensorrt": "10.12.0.36",
    "pycuda": "None",
    "datasets": "3.5.0",
    "numpy": "2.3.5",
    "pandas": "2.2.3",
    "scipy": "1.15.2",
    "matplotlib": "3.9.3"
  },
  "config_snapshot_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\results\\tr118v2\\20251213_130836_preflight2\\tiny-gpt2\\processed\\config_used_1765649316.yaml",
  "runs": {
    "prefill": {
      "raw_results_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\results\\tr118v2\\20251213_130836_preflight2\\tiny-gpt2\\raw\\bench_prefill_1765649316.jsonl",
      "latency_summary_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\results\\tr118v2\\20251213_130836_preflight2\\tiny-gpt2\\processed\\latency_summary_prefill.csv",
      "statistical_analysis_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\results\\tr118v2\\20251213_130836_preflight2\\tiny-gpt2\\processed\\statistical_analysis_prefill.json"
    },
    "generate": {
      "raw_results_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\results\\tr118v2\\20251213_130836_preflight2\\tiny-gpt2\\raw\\bench_generate_1765649316.jsonl",
      "latency_summary_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\results\\tr118v2\\20251213_130836_preflight2\\tiny-gpt2\\processed\\latency_summary_generate.csv",
      "statistical_analysis_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\results\\tr118v2\\20251213_130836_preflight2\\tiny-gpt2\\processed\\statistical_analysis_generate.json"
    }
  },
  "export_metadata_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\results\\tr118v2\\20251213_130836_preflight2\\tiny-gpt2\\processed\\export_metadata_1765649316.json",
  "trt_build_metadata_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\results\\tr118v2\\20251213_130836_preflight2\\tiny-gpt2\\processed\\trt_build_metadata_1765649316.json",
  "ended_at": 1765649374.8680549,
  "duration_s": 58.17363357543945
}