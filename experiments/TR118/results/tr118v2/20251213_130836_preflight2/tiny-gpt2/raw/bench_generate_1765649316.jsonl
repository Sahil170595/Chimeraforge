{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [281.01950000018405, 11.343299999680312], "ttft_ms": [269.1568999998708, 1.3424999997369014], "tokens_processed": [8, 8], "throughput_tok_s": [28.467775367882872, 705.2621371404674], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1951.0964999999487], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": 2.395056999999724, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765649330.0284262, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 2, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.966163400000369, "file_size_mb": 2.165760040283203, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765649346.0932584, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1516.6071000003285, "compile_ms": 756.9882000007055, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765649370.8463612}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.09810000041034, 13.465699999869685], "ttft_ms": [1.9925000005969196, 1.471999999921536], "tokens_processed": [8, 8], "throughput_tok_s": [567.4523517188239, 594.1020518857111], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [69.01490000018384], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": 2.395056999999724, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765649330.0284262, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 2, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.966163400000369, "file_size_mb": 2.165760040283203, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765649346.0932584, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2022.2946000003503, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765649370.9443405}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0922999994800193], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "export_time_s": 2.395056999999724, "file_size_mb": 0.864893913269043, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "9a33f688342aa5860dd9863d416f47e9e81fcb244aa9bdc2b857c9ff1b22f3c0", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "exists": true, "onnx_file_size_bytes": 906907, "onnx_file_size_mb": 0.864893913269043, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 906907, "total_artifact_size_mb": 0.864893913269043, "initializer_count": 15, "initializer_numel": 203190, "initializer_bytes_est": 812760, "initializer_bytes_est_mb": 0.7751083374023438, "initializer_dtype_counts": {"FLOAT": 15}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "models\\tiny-gpt2", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\flax_model.msgpack", "name": "flax_model.msgpack", "size_bytes": 411642, "size_mb": 0.39257240295410156}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\pytorch_model.bin", "name": "pytorch_model.bin", "size_bytes": 2514146, "size_mb": 2.397676467895508}, {"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\tiny-gpt2\\tf_model.h5", "name": "tf_model.h5", "size_bytes": 452120, "size_mb": 0.43117523193359375}], "total_size_bytes": 3377908, "total_size_mb": 3.221424102783203}, "timestamp": 1765649330.0284262, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\onnx\\tiny-gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 2, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 15.966163400000369, "file_size_mb": 2.165760040283203, "engine_sha256": "723c1b37ecc238fa5ba3216ca26790a738d16d0130fd3e60f4c838c6ac7f658e", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\tiny-gpt2\\tensorrt\\tiny-gpt2_fp16.plan", "exists": true, "file_size_bytes": 2270964, "file_size_mb": 2.165760040283203, "deserialize_error": null, "num_layers": 33, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Float": 29, "Int64": 9}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765649346.0932584, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765649371.1054053}
