{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [333.1358999994336, 54.188199999771314], "ttft_ms": [283.3336000003328, 6.408599999303988], "tokens_processed": [8, 8], "throughput_tok_s": [24.01422362469371, 147.6336176516984], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3017.041000000063], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": 7.03537039999992, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765649469.1883621, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 2, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 38.09166540000024, "file_size_mb": 312.3549919128418, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765649509.2917893, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2329.6964999999545, "compile_ms": 712.9166000004261, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765649546.7770395}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [39.14549999990413, 37.99650000019028], "ttft_ms": [5.161799999768846, 4.3967999999949825], "tokens_processed": [8, 8], "throughput_tok_s": [204.36576362594914, 210.5457081562759], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [71.51080000039656], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": 7.03537039999992, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765649469.1883621, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 2, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 38.09166540000024, "file_size_mb": 312.3549919128418, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765649509.2917893, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2757.81569999981, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765649546.9270496}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [37.46639999917534], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": 7.03537039999992, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765649469.1883621, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 2, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 38.09166540000024, "file_size_mb": 312.3549919128418, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765649509.2917893, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765649547.3586798}
