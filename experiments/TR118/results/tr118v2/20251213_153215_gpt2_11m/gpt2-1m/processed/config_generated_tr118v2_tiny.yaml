model:
  name: models/gpt2-1m
  description: Tiny/toy model run
onnx:
  opset_version: 17
  dynamic_axes: true
  trt_friendly_inputs: true
  optimize_for_inference: true
tensorrt:
  precisions:
  - fp32
  - fp16
  - int8
  workspace_gb: 6
  dynamic_shapes:
    enabled: true
    profiles:
    - name: single_short
      min_shape:
      - 1
      - 8
      opt_shape:
      - 1
      - 32
      max_shape:
      - 1
      - 64
    - name: single_medium
      min_shape:
      - 1
      - 32
      opt_shape:
      - 1
      - 128
      max_shape:
      - 1
      - 256
    - name: single_long
      min_shape:
      - 1
      - 128
      opt_shape:
      - 1
      - 256
      max_shape:
      - 1
      - 512
    - name: batch_short
      min_shape:
      - 4
      - 8
      opt_shape:
      - 4
      - 32
      max_shape:
      - 4
      - 64
    - name: batch_medium
      min_shape:
      - 4
      - 32
      opt_shape:
      - 4
      - 128
      max_shape:
      - 4
      - 256
  int8_calibration:
    dataset_name: wikitext
    dataset_config: wikitext-2-raw-v1
    split: test
    text_field: text
    samples: 512
    batch_size: 8
    seq_len: 128
    seed: 42
    cache_path: C:/Users/sahil/OneDrive/Documents/GitHub/Banterhearts/artifacts/tr118v2/gpt2-1m/calib/gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib
benchmark:
  prompt_config_path: scripts/tr117/configs/matrix_tier3.yaml
  modes:
  - prefill
  - generate
  backends:
  - transformers-gpu-compile
  - onnxruntime-cpu
  - onnxruntime-gpu
  - tensorrt-fp32
  - tensorrt-fp16
  - tensorrt-int8
  scenarios:
  - single_micro
  - single_short
  - single_medium
  - single_long
  - batch_short
  - batch_medium
  repetitions: 5
  warmup_runs: 3
  timeout_s: 180
  max_seq_len: 512
  max_new_tokens: 8
  stop_on_eos: true
  enable_resource_monitoring: true
resource_sampling_interval_s: 0.1
accuracy:
  perplexity_dataset: wikitext-2-raw-v1
  perplexity_samples: 1000
  perplexity_batch_size: 4
  perplexity_max_length: 128
  perplexity_thresholds:
    fp32: 0.001
    fp16: 0.005
    int8: 0.02
baseline:
  backend: transformers-gpu-compile
output:
  onnx_dir: C:/Users/sahil/OneDrive/Documents/GitHub/Banterhearts/artifacts/tr118v2/gpt2-1m/onnx
  tensorrt_dir: C:/Users/sahil/OneDrive/Documents/GitHub/Banterhearts/artifacts/tr118v2/gpt2-1m/tensorrt
  results_dir: C:/Users/sahil/OneDrive/Documents/GitHub/Banterhearts/scripts/tr118/results/tr118v2/20251213_153215_gpt2_11m/gpt2-1m
seed: 42
torch_deterministic: true
