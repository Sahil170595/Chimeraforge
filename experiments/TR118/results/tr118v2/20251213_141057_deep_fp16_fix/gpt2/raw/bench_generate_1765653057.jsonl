{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [49.06210000081046, 47.773899999810965], "ttft_ms": [6.045899999662652, 5.784099999800674], "tokens_processed": [8, 8], "throughput_tok_s": [163.05865423346836, 167.45545161754964], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2462.0665999991616, 196.35589999961667, 6.4134000003832625], "resource_metrics": {"samples": 26, "duration_s": 3.0937302112579346, "gpu_memory_mean_mb": 2564.173377403846, "gpu_memory_peak_mb": 3154.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.5384615384615385, "gpu_power_mean_watts": 29.57, "gpu_power_peak_watts": 29.87, "gpu_temperature_mean_c": 44.34615384615385, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1736.5231370192307, "cpu_memory_peak_mb": 2061.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653396.2935913}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [48.06490000009944, 47.543900000164285], "ttft_ms": [5.939199998465483, 5.8625999990908895], "tokens_processed": [8, 8], "throughput_tok_s": [166.44162372091586, 168.26553984785338], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.907099999603815, 5.844000001161476, 5.836799999087816], "resource_metrics": {"samples": 2, "duration_s": 0.1096501350402832, "gpu_memory_mean_mb": 3154.01953125, "gpu_memory_peak_mb": 3154.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.832, "gpu_power_peak_watts": 29.832, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2061.7578125, "cpu_memory_peak_mb": 2061.7578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653396.5095894}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.42689999875438, 46.549499998945976], "ttft_ms": [5.847200000062003, 5.737600000429666], "tokens_processed": [8, 8], "throughput_tok_s": [168.6806432680633, 171.8600629476395], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.269699999393197, 5.829499999890686, 5.811200000607641], "resource_metrics": {"samples": 2, "duration_s": 0.10873746871948242, "gpu_memory_mean_mb": 3154.01953125, "gpu_memory_peak_mb": 3154.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 36.7825, "gpu_power_peak_watts": 43.733, "gpu_temperature_mean_c": 45.5, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2061.91015625, "cpu_memory_peak_mb": 2061.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653396.723672}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [46.70760000044538, 47.86039999999048], "ttft_ms": [5.772399999841582, 5.712799998946139], "tokens_processed": [8, 8], "throughput_tok_s": [171.27833585805556, 167.1528027346531], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.926399999225396, 5.771500000264496, 5.742299999837996], "resource_metrics": {"samples": 2, "duration_s": 0.10898900032043457, "gpu_memory_mean_mb": 3154.01953125, "gpu_memory_peak_mb": 3154.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 43.733, "gpu_power_peak_watts": 43.733, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2061.921875, "cpu_memory_peak_mb": 2061.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653396.9397056}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.99329999877955, 46.685199999046745], "ttft_ms": [5.758799999966868, 5.717800000638817], "tokens_processed": [8, 8], "throughput_tok_s": [166.6899338074989, 171.3605168268177], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.719499999235268, 6.089400001656031, 5.739299998822389], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3154.01953125, "gpu_memory_peak_mb": 3154.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 43.733, "gpu_power_peak_watts": 43.733, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2062.00390625, "cpu_memory_peak_mb": 2062.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653397.0695848}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [136.10630000039237, 110.17080000056012], "ttft_ms": [15.082399999300833, 15.799599999809288], "tokens_processed": [8, 8], "throughput_tok_s": [58.77758781170995, 72.61452217792126], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1769.9627000001783, 14.817400000538328, 13.958400000774418], "resource_metrics": {"samples": 23, "duration_s": 2.3730592727661133, "gpu_memory_mean_mb": 3609.932574728261, "gpu_memory_peak_mb": 3674.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.9130434782608696, "gpu_power_mean_watts": 45.73765217391304, "gpu_power_peak_watts": 62.099, "gpu_temperature_mean_c": 45.869565217391305, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2096.8862092391305, "cpu_memory_peak_mb": 2510.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653399.5488966}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [108.76859999916633, 107.40219999934197], "ttft_ms": [13.292399999045301, 13.149000000339583], "tokens_processed": [8, 8], "throughput_tok_s": [73.55063869592252, 74.48636992583964], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.655200000357581, 13.12329999927897, 14.068599999518483], "resource_metrics": {"samples": 3, "duration_s": 0.21061468124389648, "gpu_memory_mean_mb": 3674.01953125, "gpu_memory_peak_mb": 3674.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 34.78966666666667, "gpu_power_peak_watts": 35.399, "gpu_temperature_mean_c": 45.666666666666664, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2081.62109375, "cpu_memory_peak_mb": 2081.62109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653399.865095}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [103.50579999976617, 105.42410000016389], "ttft_ms": [12.422600000718376, 12.452200000552693], "tokens_processed": [8, 8], "throughput_tok_s": [77.2903547435803, 75.88397719295268], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.499799999408424, 12.800799999240553, 14.169199999741977], "resource_metrics": {"samples": 3, "duration_s": 0.20797348022460938, "gpu_memory_mean_mb": 3674.01953125, "gpu_memory_peak_mb": 3674.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 36.92766666666667, "gpu_power_peak_watts": 39.985, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2081.6328125, "cpu_memory_peak_mb": 2081.6328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653400.1784296}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [108.7258000006841, 131.95099999938975], "ttft_ms": [12.760600000547129, 14.884199999869452], "tokens_processed": [8, 8], "throughput_tok_s": [73.57959196390979, 60.62856666517873], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.58950000051118, 13.755199999650358, 12.96349999938684], "resource_metrics": {"samples": 3, "duration_s": 0.20680928230285645, "gpu_memory_mean_mb": 3674.01953125, "gpu_memory_peak_mb": 3674.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 39.985, "gpu_power_peak_watts": 39.985, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2081.640625, "cpu_memory_peak_mb": 2081.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653400.4914572}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [111.3920000007056, 108.80659999929776], "ttft_ms": [13.797999999951571, 14.305299999250565], "tokens_processed": [8, 8], "throughput_tok_s": [71.81844297570136, 73.52495161186576], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.894800000751275, 13.842999998814776, 13.71859999926528], "resource_metrics": {"samples": 3, "duration_s": 0.2077465057373047, "gpu_memory_mean_mb": 3674.01953125, "gpu_memory_peak_mb": 3674.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.333333333333332, "gpu_power_mean_watts": 42.17766666666667, "gpu_power_peak_watts": 43.274, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2081.66796875, "cpu_memory_peak_mb": 2081.66796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653400.8056672}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [139.42169999972975, 114.50069999955304], "ttft_ms": [17.15870000043651, 14.293300000645104], "tokens_processed": [8, 8], "throughput_tok_s": [57.3798770206898, 69.86856848937367], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1803.3242000001337, 13.620800000353483, 13.562099999035127], "resource_metrics": {"samples": 24, "duration_s": 2.495480537414551, "gpu_memory_mean_mb": 4125.76953125, "gpu_memory_peak_mb": 4194.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.083333333333333, "gpu_power_mean_watts": 29.416666666666668, "gpu_power_peak_watts": 43.274, "gpu_temperature_mean_c": 44.833333333333336, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2098.521484375, "cpu_memory_peak_mb": 2394.8203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653403.4066775}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [109.33079999995243, 125.20959999892511], "ttft_ms": [13.29019999866432, 15.58610000029148], "tokens_processed": [8, 8], "throughput_tok_s": [73.17242716602715, 63.892864445447294], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.622200000303565, 13.279700000566663, 13.391000000410713], "resource_metrics": {"samples": 3, "duration_s": 0.21335673332214355, "gpu_memory_mean_mb": 4194.01953125, "gpu_memory_peak_mb": 4194.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.666666666666668, "gpu_power_mean_watts": 17.093, "gpu_power_peak_watts": 18.483, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2096.7734375, "cpu_memory_peak_mb": 2096.7734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653403.725491}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [108.2103000007919, 106.60769999958575], "ttft_ms": [12.562799998704577, 12.985100000150851], "tokens_processed": [8, 8], "throughput_tok_s": [73.93011570933132, 75.04148387059365], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.763800001470372, 13.069000000541564, 12.152799999967101], "resource_metrics": {"samples": 3, "duration_s": 0.22013092041015625, "gpu_memory_mean_mb": 4194.01953125, "gpu_memory_peak_mb": 4194.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 18.483, "gpu_power_peak_watts": 18.483, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2096.77734375, "cpu_memory_peak_mb": 2096.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653404.0521884}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [107.33319999962987, 110.30989999926533], "ttft_ms": [12.50889999937499, 13.02889999897161], "tokens_processed": [8, 8], "throughput_tok_s": [74.53425408007575, 72.52295578233033], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.255599998956313, 12.878499999715132, 12.515099999291124], "resource_metrics": {"samples": 3, "duration_s": 0.2142176628112793, "gpu_memory_mean_mb": 4194.01953125, "gpu_memory_peak_mb": 4194.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 21.267, "gpu_power_peak_watts": 21.267, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2096.80078125, "cpu_memory_peak_mb": 2096.80078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653404.3798528}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [112.75770000065677, 110.63759999888134], "ttft_ms": [13.81539999965753, 13.68450000154553], "tokens_processed": [8, 8], "throughput_tok_s": [70.94859153701613, 72.30814840597489], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.0001000003831, 13.956200000393437, 14.0692000004492], "resource_metrics": {"samples": 3, "duration_s": 0.21747374534606934, "gpu_memory_mean_mb": 4194.01953125, "gpu_memory_peak_mb": 4194.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 49.0, "gpu_power_mean_watts": 21.53233333333333, "gpu_power_peak_watts": 22.063, "gpu_temperature_mean_c": 44.666666666666664, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2096.82421875, "cpu_memory_peak_mb": 2096.82421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653404.706712}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [150.19849999953294, 117.2908999997162], "ttft_ms": [17.973500000152853, 15.742399998998735], "tokens_processed": [8, 8], "throughput_tok_s": [53.26284883021386, 68.20648490223331], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1778.1973000001017, 17.45169999958307, 17.568999999639345], "resource_metrics": {"samples": 22, "duration_s": 2.379153251647949, "gpu_memory_mean_mb": 4647.746803977273, "gpu_memory_peak_mb": 4716.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.227272727272727, "gpu_power_mean_watts": 20.453318181818183, "gpu_power_peak_watts": 22.063, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2123.16015625, "cpu_memory_peak_mb": 2533.03515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653407.1915276}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [113.05859999993118, 118.28910000076576], "ttft_ms": [13.66309999866644, 13.900300000386778], "tokens_processed": [8, 8], "throughput_tok_s": [70.75976528990161, 67.63091442870231], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.20970000071975, 13.826099999278085, 13.845800000126474], "resource_metrics": {"samples": 3, "duration_s": 0.21596789360046387, "gpu_memory_mean_mb": 4716.01953125, "gpu_memory_peak_mb": 4716.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.16, "gpu_power_peak_watts": 21.16, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2110.69140625, "cpu_memory_peak_mb": 2110.69140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653407.51463}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [113.19139999977779, 113.56569999952626], "ttft_ms": [13.812200000757002, 13.564300001235097], "tokens_processed": [8, 8], "throughput_tok_s": [70.67674752689432, 70.4438047758555], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.59439999962342, 14.666600000055041, 13.980800000354066], "resource_metrics": {"samples": 3, "duration_s": 0.21561503410339355, "gpu_memory_mean_mb": 4716.01953125, "gpu_memory_peak_mb": 4716.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 22.28533333333333, "gpu_power_peak_watts": 22.848, "gpu_temperature_mean_c": 44.666666666666664, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2110.69140625, "cpu_memory_peak_mb": 2110.69140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653407.838732}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [112.78560000027937, 113.6183999988134], "ttft_ms": [13.823799999954645, 13.426899999103625], "tokens_processed": [8, 8], "throughput_tok_s": [70.93104084191762, 70.41113059225925], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.198600001691375, 14.238300000215531, 13.916599998992751], "resource_metrics": {"samples": 3, "duration_s": 0.21807456016540527, "gpu_memory_mean_mb": 4716.01953125, "gpu_memory_peak_mb": 4716.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 23.308666666666667, "gpu_power_peak_watts": 24.23, "gpu_temperature_mean_c": 44.666666666666664, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2110.69140625, "cpu_memory_peak_mb": 2110.69140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653408.1850145}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [107.96740000114369, 108.87189999994007], "ttft_ms": [12.864899999840418, 13.15450000038254], "tokens_processed": [8, 8], "throughput_tok_s": [74.09644022098576, 73.48085226770547], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.232199999241857, 13.947400000688503, 13.002600000618258], "resource_metrics": {"samples": 3, "duration_s": 0.21882104873657227, "gpu_memory_mean_mb": 4716.01953125, "gpu_memory_peak_mb": 4716.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 24.23, "gpu_power_peak_watts": 24.23, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2110.69140625, "cpu_memory_peak_mb": 2110.69140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653408.509206}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [152.5020000008226, 129.64519999877666], "ttft_ms": [17.42510000076436, 15.390800001114258], "tokens_processed": [32, 32], "throughput_tok_s": [209.83331366032834, 246.82749535117347], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1593.2527999993908, 18.19959999920684, 18.528900000092108], "resource_metrics": {"samples": 22, "duration_s": 2.240130662918091, "gpu_memory_mean_mb": 5175.837713068182, "gpu_memory_peak_mb": 5238.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.7272727272727275, "gpu_power_mean_watts": 21.55159090909091, "gpu_power_peak_watts": 24.23, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2140.587002840909, "cpu_memory_peak_mb": 2600.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653410.8564713}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [128.81999999990512, 119.22940000113158], "ttft_ms": [15.002200001617894, 15.962499999659485], "tokens_processed": [32, 32], "throughput_tok_s": [248.4086322001519, 268.3901789298302], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.809599999556667, 15.45570000052976, 15.024399999674642], "resource_metrics": {"samples": 3, "duration_s": 0.21631217002868652, "gpu_memory_mean_mb": 5238.01953125, "gpu_memory_peak_mb": 5238.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 23.0, "gpu_power_mean_watts": 23.566999999999997, "gpu_power_peak_watts": 25.837, "gpu_temperature_mean_c": 44.333333333333336, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2138.3828125, "cpu_memory_peak_mb": 2143.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653411.179938}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [126.08150000050955, 124.62559999949008], "ttft_ms": [15.453900001375587, 14.513399999486865], "tokens_processed": [32, 32], "throughput_tok_s": [253.80408703791338, 256.7690747336898], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [24.725499999476597, 18.331599998418824, 15.926099998978316], "resource_metrics": {"samples": 4, "duration_s": 0.3079190254211426, "gpu_memory_mean_mb": 5238.01953125, "gpu_memory_peak_mb": 5238.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 23.0, "gpu_power_mean_watts": 25.837, "gpu_power_peak_watts": 25.837, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2139.671875, "cpu_memory_peak_mb": 2143.328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653411.5943072}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [131.32120000045688, 134.09259999934875], "ttft_ms": [15.252799999871058, 15.85470000100031], "tokens_processed": [32, 32], "throughput_tok_s": [243.67733465646575, 238.64105849357395], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.95940000131668, 15.381500001240056, 15.350699999544304], "resource_metrics": {"samples": 3, "duration_s": 0.21476531028747559, "gpu_memory_mean_mb": 5238.01953125, "gpu_memory_peak_mb": 5238.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 28.0, "gpu_power_mean_watts": 31.439000000000004, "gpu_power_peak_watts": 31.439, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2138.453125, "cpu_memory_peak_mb": 2143.328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653411.9162967}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [130.01179999992019, 122.58449999899312], "ttft_ms": [14.974799998526578, 14.285100000051898], "tokens_processed": [32, 32], "throughput_tok_s": [246.13150498662156, 261.0444224209655], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.614100001286715, 16.886699999304255, 14.681900000141468], "resource_metrics": {"samples": 3, "duration_s": 0.2201552391052246, "gpu_memory_mean_mb": 5238.01953125, "gpu_memory_peak_mb": 5238.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 28.0, "gpu_power_mean_watts": 32.007, "gpu_power_peak_watts": 33.143, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2138.46484375, "cpu_memory_peak_mb": 2143.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653412.2426689}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [171.81820000041625, 151.33420000165643], "ttft_ms": [22.110099998826627, 18.471299999873736], "tokens_processed": [32, 32], "throughput_tok_s": [186.2433665346423, 211.45253352943183], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1689.9894999987737, 26.651200001651887, 23.346699999819975], "resource_metrics": {"samples": 23, "duration_s": 2.409726142883301, "gpu_memory_mean_mb": 5698.367357336957, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.695652173913043, "gpu_power_mean_watts": 25.29195652173913, "gpu_power_peak_watts": 33.143, "gpu_temperature_mean_c": 44.21739130434783, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2152.33984375, "cpu_memory_peak_mb": 2609.66015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653414.772539}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [129.95760000012524, 139.19480000004114], "ttft_ms": [15.571199999612872, 15.942699999868637], "tokens_processed": [32, 32], "throughput_tok_s": [246.2341563707637, 229.89364545220468], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.400300000692368, 15.128700000786921, 15.404100000523613], "resource_metrics": {"samples": 3, "duration_s": 0.2218027114868164, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 80.0, "gpu_power_mean_watts": 21.024, "gpu_power_peak_watts": 21.024, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2171.40625, "cpu_memory_peak_mb": 2171.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653415.1013374}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [126.72969999948691, 125.08820000039123], "ttft_ms": [14.12510000045586, 15.124800000194227], "tokens_processed": [32, 32], "throughput_tok_s": [252.50592402672427, 255.81949376439917], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.224499999021646, 14.172499999403954, 14.037099999768543], "resource_metrics": {"samples": 3, "duration_s": 0.20695042610168457, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 80.0, "gpu_power_mean_watts": 55.263, "gpu_power_peak_watts": 55.263, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2171.40625, "cpu_memory_peak_mb": 2171.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653415.4137325}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [123.12479999854986, 118.65150000085123], "ttft_ms": [15.275200001269695, 14.48539999910281], "tokens_processed": [32, 32], "throughput_tok_s": [259.89889933122237, 269.6973910972084], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.159700000775047, 18.765999999232008, 17.591499999980442], "resource_metrics": {"samples": 3, "duration_s": 0.22092247009277344, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 63.333333333333336, "gpu_power_mean_watts": 56.42033333333333, "gpu_power_peak_watts": 58.735, "gpu_temperature_mean_c": 47.333333333333336, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2171.41015625, "cpu_memory_peak_mb": 2171.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653415.740028}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [155.38349999951606, 140.32310000038706], "ttft_ms": [17.42980000017269, 17.740100000082748], "tokens_processed": [32, 32], "throughput_tok_s": [205.94207235710138, 228.04513298175235], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.990899999247631, 15.426099998876452, 14.425299999857089], "resource_metrics": {"samples": 4, "duration_s": 0.3226132392883301, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 58.21125, "gpu_power_peak_watts": 58.735, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2171.41796875, "cpu_memory_peak_mb": 2171.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1441.1554000016622, "compile_ms": 571.270700000241, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765653416.1694744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [109.09759999958624, 111.18340000030003], "ttft_ms": [13.582100000348873, 14.268200000515208], "tokens_processed": [8, 8], "throughput_tok_s": [73.32883583168045, 71.95318725617685], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.57429999836313, 13.73760000024049, 13.517200000933371], "resource_metrics": {"samples": 3, "duration_s": 0.2119922637939453, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 56.64000000000001, "gpu_power_peak_watts": 56.64, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2177.1223958333335, "cpu_memory_peak_mb": 2179.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653416.487846}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [107.93220000050496, 109.9233999993885], "ttft_ms": [14.45140000032552, 12.927700001455378], "tokens_processed": [8, 8], "throughput_tok_s": [74.12060534263706, 72.77795264742997], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.125100000252132, 13.279299999339855, 13.92390000000887], "resource_metrics": {"samples": 3, "duration_s": 0.21022486686706543, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 40.82933333333333, "gpu_power_peak_watts": 56.64, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2179.3125, "cpu_memory_peak_mb": 2179.3125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653416.8038433}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [113.22370000016235, 106.74880000078701], "ttft_ms": [14.35019999917131, 14.18799999919429], "tokens_processed": [8, 8], "throughput_tok_s": [70.65658514947425, 74.94229443273385], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.04769999862765, 12.461399999665446, 13.334600000234786], "resource_metrics": {"samples": 3, "duration_s": 0.21534466743469238, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.924, "gpu_power_peak_watts": 32.924, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2179.3984375, "cpu_memory_peak_mb": 2179.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653417.1254094}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [113.54580000079295, 112.57169999953476], "ttft_ms": [14.269299999796203, 14.415499999813619], "tokens_processed": [8, 8], "throughput_tok_s": [70.45615073339685, 71.06581849641663], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.393900000664871, 12.988000000405009, 13.687600001503597], "resource_metrics": {"samples": 3, "duration_s": 0.21923470497131348, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.401, "gpu_power_peak_watts": 21.401, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2179.4375, "cpu_memory_peak_mb": 2179.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653417.4511476}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [113.47220000061498, 106.52730000037991], "ttft_ms": [12.967900000148802, 14.087400000789785], "tokens_processed": [8, 8], "throughput_tok_s": [70.50184979190183, 75.09812038765152], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.780099999872618, 12.6682999998593, 12.674899999183253], "resource_metrics": {"samples": 3, "duration_s": 0.22746014595031738, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 18.011666666666667, "gpu_power_peak_watts": 21.401, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2179.48046875, "cpu_memory_peak_mb": 2179.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653417.7850344}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [116.6397999986657, 122.12530000033439], "ttft_ms": [15.66620000085095, 15.59610000003886], "tokens_processed": [8, 8], "throughput_tok_s": [68.58722322990538, 65.5064921026036], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.171799999530776, 13.47900000109803, 14.325199999802862], "resource_metrics": {"samples": 3, "duration_s": 0.2183225154876709, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 16.317, "gpu_power_peak_watts": 16.317, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2180.4921875, "cpu_memory_peak_mb": 2180.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653418.1089694}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [123.07630000032077, 121.89810000018042], "ttft_ms": [14.552500000718283, 15.760700000100769], "tokens_processed": [8, 8], "throughput_tok_s": [65.00032906399647, 65.6285864996104], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.739600000917562, 13.560699999288772, 16.217099999266793], "resource_metrics": {"samples": 3, "duration_s": 0.21415352821350098, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.997, "gpu_power_peak_watts": 15.997, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2180.6875, "cpu_memory_peak_mb": 2180.6875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653418.4293106}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [121.67129999943427, 152.7224000001297], "ttft_ms": [14.63530000000901, 14.785199999096221], "tokens_processed": [8, 8], "throughput_tok_s": [65.7509207186674, 52.38262363604295], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.037300001291442, 13.548700000683311, 13.467400000081398], "resource_metrics": {"samples": 4, "duration_s": 0.30995798110961914, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.771, "gpu_power_peak_watts": 15.997, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2180.69921875, "cpu_memory_peak_mb": 2180.69921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653418.8575172}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [130.45310000052268, 115.79310000161058], "ttft_ms": [16.441300000224146, 15.662300000258256], "tokens_processed": [8, 8], "throughput_tok_s": [61.32472129805997, 69.08874535605945], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.64759999969101, 16.802500000267173, 14.574099999663304], "resource_metrics": {"samples": 3, "duration_s": 0.2133619785308838, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.541666666666666, "gpu_power_peak_watts": 15.545, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2180.69921875, "cpu_memory_peak_mb": 2180.69921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653419.1773412}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [121.7677000004187, 123.8178000003245], "ttft_ms": [15.634900000804919, 15.452399999048794], "tokens_processed": [8, 8], "throughput_tok_s": [65.69886759766746, 64.61106561398307], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.290699999037315, 14.844199999060947, 16.70670000021346], "resource_metrics": {"samples": 3, "duration_s": 0.20879578590393066, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.535000000000002, "gpu_power_peak_watts": 15.535, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2180.77734375, "cpu_memory_peak_mb": 2180.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653419.4928043}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [136.34839999940596, 131.36039999881177], "ttft_ms": [15.897400000540074, 16.221899999436573], "tokens_processed": [8, 8], "throughput_tok_s": [58.673222421640844, 60.90115438193219], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.647700000045006, 14.879199999995762, 15.769699999509612], "resource_metrics": {"samples": 3, "duration_s": 0.22188425064086914, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.535000000000002, "gpu_power_peak_watts": 15.535, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2189.7434895833335, "cpu_memory_peak_mb": 2191.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653419.8215497}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [129.16450000011537, 139.23260000046866], "ttft_ms": [14.979600000515347, 18.49960000072315], "tokens_processed": [8, 8], "throughput_tok_s": [61.93652280613369, 57.45780801315979], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.485699999771896, 14.947900001061498, 14.881200000672834], "resource_metrics": {"samples": 3, "duration_s": 0.21760845184326172, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.535000000000002, "gpu_power_peak_watts": 15.535, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2191.69921875, "cpu_memory_peak_mb": 2191.69921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653420.1460578}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [161.52349999902071, 167.0797999995557], "ttft_ms": [18.9420999995491, 19.09970000087924], "tokens_processed": [8, 8], "throughput_tok_s": [49.528396797051215, 47.88131180442683], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.956900000877795, 16.417699998783064, 18.39780000045721], "resource_metrics": {"samples": 4, "duration_s": 0.32172656059265137, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 9.586, "gpu_power_peak_watts": 9.586, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2191.77734375, "cpu_memory_peak_mb": 2191.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653420.5754004}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [158.94159999879776, 148.08690000063507], "ttft_ms": [23.107000000891276, 20.507999999608728], "tokens_processed": [8, 8], "throughput_tok_s": [50.33295248104029, 54.02233418327814], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [19.427100000029895, 19.490300001052674, 20.79989999947429], "resource_metrics": {"samples": 4, "duration_s": 0.31732630729675293, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 9.586, "gpu_power_peak_watts": 9.586, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2191.78515625, "cpu_memory_peak_mb": 2191.78515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653421.0005643}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [154.4811000003392, 142.1864000003552], "ttft_ms": [20.786399998542038, 16.632200000458397], "tokens_processed": [8, 8], "throughput_tok_s": [51.78627029444012, 56.264171538065625], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.148699998870143, 18.075300000418792, 18.21879999988596], "resource_metrics": {"samples": 4, "duration_s": 0.31794238090515137, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 5.428, "gpu_power_peak_watts": 9.586, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2191.8203125, "cpu_memory_peak_mb": 2191.8203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653421.4258366}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [151.84769999905257, 149.908499999583], "ttft_ms": [18.907499999841093, 17.822499999965657], "tokens_processed": [8, 8], "throughput_tok_s": [52.68436729729798, 53.36588652426149], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.552699999214383, 17.757199999323348, 17.888000000311877], "resource_metrics": {"samples": 4, "duration_s": 0.31552577018737793, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 4.042, "gpu_power_peak_watts": 4.042, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2194.12890625, "cpu_memory_peak_mb": 2194.89453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653421.8486671}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [149.34320000065782, 140.48299999922165], "ttft_ms": [16.913899999053683, 17.095199998948374], "tokens_processed": [8, 8], "throughput_tok_s": [53.56788926422336, 56.94639209046165], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.619500000568223, 17.272299999604, 17.153200000393554], "resource_metrics": {"samples": 4, "duration_s": 0.31674718856811523, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.4749999999999996, "gpu_power_peak_watts": 4.042, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2194.89453125, "cpu_memory_peak_mb": 2194.89453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653422.2724676}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [156.01299999980256, 152.32859999923676], "ttft_ms": [16.989199999443372, 16.815900000437978], "tokens_processed": [8, 8], "throughput_tok_s": [51.277778133938355, 52.51804323049043], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.290600000706036, 16.864399998667068, 17.004899998937617], "resource_metrics": {"samples": 4, "duration_s": 0.31702637672424316, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.908, "gpu_power_peak_watts": 2.908, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2194.89453125, "cpu_memory_peak_mb": 2194.89453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653422.6965184}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [150.60929999890504, 151.19740000045567], "ttft_ms": [17.888200000015786, 18.62770000116143], "tokens_processed": [8, 8], "throughput_tok_s": [53.11756976533429, 52.91096275449108], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.329600001176004, 16.99449999978242, 17.515199999252218], "resource_metrics": {"samples": 4, "duration_s": 0.31284356117248535, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.908, "gpu_power_peak_watts": 2.908, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2194.89453125, "cpu_memory_peak_mb": 2194.89453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653423.1161485}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [149.1641000011441, 160.96650000145019], "ttft_ms": [18.25240000107442, 19.419800000832765], "tokens_processed": [8, 8], "throughput_tok_s": [53.63220774930858, 49.69978225238125], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.644700001255842, 16.959299999143695, 17.65530000011495], "resource_metrics": {"samples": 4, "duration_s": 0.31357502937316895, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.781, "gpu_power_peak_watts": 1.781, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2194.953125, "cpu_memory_peak_mb": 2194.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653423.536853}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [258.77459999901475, 274.3965000008757], "ttft_ms": [30.392300001039985, 34.889900000052876], "tokens_processed": [32, 32], "throughput_tok_s": [123.659740948771, 116.6195632958069], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [31.185700001515215, 34.73579999990761, 33.49849999904109], "resource_metrics": {"samples": 7, "duration_s": 0.6162598133087158, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7807142857142857, "gpu_power_peak_watts": 1.781, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2213.503348214286, "cpu_memory_peak_mb": 2219.0859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653424.2598362}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [260.5550000007497, 269.2650999997568], "ttft_ms": [33.96309999880032, 29.361700000663404], "tokens_processed": [32, 32], "throughput_tok_s": [122.81476079871015, 118.84198880593476], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [28.25229999871226, 28.54019999904267, 33.22920000027807], "resource_metrics": {"samples": 7, "duration_s": 0.6100702285766602, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.779, "gpu_power_peak_watts": 1.779, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2219.13671875, "cpu_memory_peak_mb": 2219.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653424.97659}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [270.34379999895464, 265.6508000000031], "ttft_ms": [34.0474999993603, 32.61919999931706], "tokens_processed": [32, 32], "throughput_tok_s": [118.36779685764473, 120.45888813434641], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [28.50360000047658, 28.22609999930137, 32.67239999877347], "resource_metrics": {"samples": 7, "duration_s": 0.6098268032073975, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7249999999999999, "gpu_power_peak_watts": 1.779, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2219.17578125, "cpu_memory_peak_mb": 2219.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653425.6930087}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [269.5164000015211, 268.31899999888265], "ttft_ms": [33.90369999942777, 31.376900000395835], "tokens_processed": [32, 32], "throughput_tok_s": [118.73117925224363, 119.26102885048489], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [29.069199999867124, 28.532000000268454, 30.198000000382308], "resource_metrics": {"samples": 7, "duration_s": 0.6251161098480225, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7172857142857143, "gpu_power_peak_watts": 1.719, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2219.1953125, "cpu_memory_peak_mb": 2219.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653426.4250283}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [270.3923000008217, 270.7343000001856], "ttft_ms": [33.91859999828739, 35.51130000050762], "tokens_processed": [32, 32], "throughput_tok_s": [118.34656534192266, 118.19706627486086], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [30.05710000070394, 27.9378999985056, 30.769899998631445], "resource_metrics": {"samples": 7, "duration_s": 0.6243910789489746, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.719, "gpu_power_peak_watts": 1.719, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2219.20703125, "cpu_memory_peak_mb": 2219.20703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653427.1558726}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [321.2280000007013, 326.2584000003699], "ttft_ms": [41.91180000088934, 44.1716000004817], "tokens_processed": [32, 32], "throughput_tok_s": [99.61771701075293, 98.08176586400143], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [35.437200000160374, 39.13730000022042, 41.63890000018], "resource_metrics": {"samples": 8, "duration_s": 0.7113847732543945, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.714, "gpu_power_peak_watts": 1.714, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2241.66162109375, "cpu_memory_peak_mb": 2248.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653427.9740307}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [331.94410000032804, 322.69040000028326], "ttft_ms": [42.117299999517854, 39.211599998452584], "tokens_processed": [32, 32], "throughput_tok_s": [96.40177367203809, 99.16625967172222], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [38.50430000056804, 37.79670000039914, 40.13920000033977], "resource_metrics": {"samples": 8, "duration_s": 0.7246644496917725, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.714, "gpu_power_peak_watts": 1.714, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2248.11328125, "cpu_memory_peak_mb": 2248.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653428.804801}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [327.72450000084064, 330.66470000085246], "ttft_ms": [43.54120000061812, 42.57850000067265], "tokens_processed": [32, 32], "throughput_tok_s": [97.64298976706935, 96.77476912388138], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [39.32170000007318, 37.6907999998366, 37.176300000282936], "resource_metrics": {"samples": 8, "duration_s": 0.7220370769500732, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.729, "gpu_power_peak_watts": 1.738, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2248.11328125, "cpu_memory_peak_mb": 2248.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653429.6331637}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [332.1622000003117, 329.7232000004442], "ttft_ms": [42.43320000023232, 43.4079999995447], "tokens_processed": [32, 32], "throughput_tok_s": [96.33847560008324, 97.05110225776315], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [37.71409999899333, 40.611899999930756, 39.91119999955117], "resource_metrics": {"samples": 8, "duration_s": 0.72373366355896, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.742875, "gpu_power_peak_watts": 1.751, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2248.11328125, "cpu_memory_peak_mb": 2248.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653430.4633434}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [336.4569000004849, 324.3829999992158], "ttft_ms": [44.1289999998844, 42.14410000167845], "tokens_processed": [32, 32], "throughput_tok_s": [95.10876430221488, 98.64881945131945], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [37.02830000111135, 37.69479999937175, 42.96180000164895], "resource_metrics": {"samples": 8, "duration_s": 0.712205171585083, "gpu_memory_mean_mb": 5758.01953125, "gpu_memory_peak_mb": 5758.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.75175, "gpu_power_peak_watts": 1.754, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2248.11328125, "cpu_memory_peak_mb": 2248.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1129.9548000006325, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653431.2825305}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [193.14590000067255, 33.6912000002485], "ttft_ms": [45.175300001574215, 3.876799999488867], "tokens_processed": [8, 8], "throughput_tok_s": [41.41946580265045, 237.45072897198656], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [126.68110000049637, 44.867900000099326, 45.116900000721216], "resource_metrics": {"samples": 5, "duration_s": 0.4092566967010498, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 39.2, "gpu_power_mean_watts": 2.0236, "gpu_power_peak_watts": 2.428, "gpu_temperature_mean_c": 44.4, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2369.5671875, "cpu_memory_peak_mb": 2399.95703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653431.7991984}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [27.45859999959066, 27.30130000054487], "ttft_ms": [3.395599998839316, 3.437100000155624], "tokens_processed": [8, 8], "throughput_tok_s": [291.347701635162, 293.02633939923516], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.396899999846937, 3.74770000053104, 3.473800001302152], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 98.0, "gpu_power_mean_watts": 2.428, "gpu_power_peak_watts": 2.428, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2400.046875, "cpu_memory_peak_mb": 2400.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653431.9128022}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.198099998917314, 27.94940000057977], "ttft_ms": [3.6801000005652895, 3.342900001371163], "tokens_processed": [8, 8], "throughput_tok_s": [283.70705828786924, 286.23154700401625], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.046000000016647, 4.071499999554362, 4.0466999998898245], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 98.0, "gpu_power_mean_watts": 2.428, "gpu_power_peak_watts": 2.428, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2400.07421875, "cpu_memory_peak_mb": 2400.07421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653432.037308}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [27.18070000082662, 27.194300000701332], "ttft_ms": [3.4343000006629154, 3.400100000362727], "tokens_processed": [8, 8], "throughput_tok_s": [294.3264890071523, 294.1792949181881], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.955899999913527, 3.8468999991891906, 3.376900000148453], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 98.0, "gpu_power_mean_watts": 15.405, "gpu_power_peak_watts": 15.405, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2400.15625, "cpu_memory_peak_mb": 2400.15625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653432.1784687}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [26.912699999229517, 27.012099999410566], "ttft_ms": [3.313400000479305, 3.396600000996841], "tokens_processed": [8, 8], "throughput_tok_s": [297.257428657438, 296.1635711468034], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.224800000883988, 3.6538000003929483, 3.2821999993757345], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 98.0, "gpu_power_mean_watts": 15.405, "gpu_power_peak_watts": 15.405, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2400.15625, "cpu_memory_peak_mb": 2400.15625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653432.3043363}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.682199999821023, 28.401199999279925], "ttft_ms": [3.574000000298838, 3.4849999992729863], "tokens_processed": [8, 8], "throughput_tok_s": [278.91863246368547, 281.6782389547917], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.033299999922747, 3.8925000008021016, 3.545400000803056], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 98.0, "gpu_power_mean_watts": 15.405, "gpu_power_peak_watts": 15.405, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2401.22265625, "cpu_memory_peak_mb": 2401.22265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653432.427922}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.452799999489798, 29.729599998972844], "ttft_ms": [4.230500000630855, 3.577799998311093], "tokens_processed": [8, 8], "throughput_tok_s": [271.62103433760393, 269.0920833202061], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.502399999182671, 3.839999999399879, 3.5833999991154997], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 98.0, "gpu_power_mean_watts": 15.405, "gpu_power_peak_watts": 15.405, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2401.828125, "cpu_memory_peak_mb": 2401.828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653432.5517726}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.022899998584762, 29.620199999044416], "ttft_ms": [3.702400001202477, 3.685199999381439], "tokens_processed": [8, 8], "throughput_tok_s": [266.46326638589574, 270.0859548638459], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.7289000012824545, 3.9837000003899448, 3.7052000006951857], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 64.15, "gpu_power_peak_watts": 64.15, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2401.828125, "cpu_memory_peak_mb": 2401.828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653432.6883655}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.551999999966938, 29.758599999695434], "ttft_ms": [3.6344000000099186, 3.7311000014597084], "tokens_processed": [8, 8], "throughput_tok_s": [270.70925825693524, 268.8298508693916], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.405200001201592, 3.875599999446422, 3.8480999992316356], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 64.15, "gpu_power_peak_watts": 64.15, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2401.83984375, "cpu_memory_peak_mb": 2401.83984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653432.8156302}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.5031999994535, 29.801499998939107], "ttft_ms": [3.6503999999695225, 3.6706000009871786], "tokens_processed": [8, 8], "throughput_tok_s": [271.15702703937836, 268.4428636238038], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.402799999297713, 3.6689000007754657, 3.762500000448199], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 64.15, "gpu_power_peak_watts": 64.15, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2401.84765625, "cpu_memory_peak_mb": 2401.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653432.9439113}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.04140000040934, 31.486100000620354], "ttft_ms": [4.363699999885284, 3.9025000005494803], "tokens_processed": [8, 8], "throughput_tok_s": [228.30138064993258, 254.08037196865857], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.899199999475968, 4.497399999308982, 4.900500000076136], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 64.15, "gpu_power_peak_watts": 64.15, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2407.359375, "cpu_memory_peak_mb": 2407.359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653433.0632532}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.92619999915769, 31.16039999986242], "ttft_ms": [3.945700000258512, 3.9743999986967538], "tokens_processed": [8, 8], "throughput_tok_s": [258.68034224113825, 256.73611378657915], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.336199999670498, 4.104499999812106, 3.9883999997982755], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 79.047, "gpu_power_peak_watts": 79.047, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2413.08203125, "cpu_memory_peak_mb": 2413.08203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653433.1867795}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.156899998677545, 30.87940000114031], "ttft_ms": [4.023899999083369, 3.77920000028098], "tokens_processed": [8, 8], "throughput_tok_s": [256.76495416230625, 259.07239129337285], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.684600000473438, 4.121699999814155, 3.979700000854791], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 79.047, "gpu_power_peak_watts": 79.047, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2413.08203125, "cpu_memory_peak_mb": 2413.08203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653433.3110743}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.41990000019723, 31.435700000656652], "ttft_ms": [3.948100000343402, 3.926600000340841], "tokens_processed": [8, 8], "throughput_tok_s": [262.9857428837087, 254.48773209544848], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.542399999991176, 3.9537000011478085, 3.9706999996269587], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 79.047, "gpu_power_peak_watts": 79.047, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2413.08203125, "cpu_memory_peak_mb": 2413.08203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653433.434497}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.008899999505957, 32.20510000028298], "ttft_ms": [3.728100000444101, 3.902899999957299], "tokens_processed": [8, 8], "throughput_tok_s": [257.99044790777674, 248.4078608645744], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.4696000004478265, 3.8865000005898764, 3.7614000011672033], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 51.0, "gpu_power_mean_watts": 79.047, "gpu_power_peak_watts": 79.047, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2413.08203125, "cpu_memory_peak_mb": 2413.08203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653433.5585365}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.22290000101202, 30.663600000480074], "ttft_ms": [3.925500001059845, 3.6985999995522434], "tokens_processed": [8, 8], "throughput_tok_s": [256.22219587996943, 260.895654778785], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.024399999456364, 3.8287999996100552, 3.967499998907442], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 61.704, "gpu_power_peak_watts": 61.704, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2414.58203125, "cpu_memory_peak_mb": 2414.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653433.6830935}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.747899998459616, 31.480399999054498], "ttft_ms": [4.069799999342649, 3.919099999620812], "tokens_processed": [8, 8], "throughput_tok_s": [260.1803700545656, 254.12637705493822], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.635299999790732, 4.147499999817228, 3.9402999991580145], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 61.704, "gpu_power_peak_watts": 61.704, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2416.08203125, "cpu_memory_peak_mb": 2416.08203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653433.8101847}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.18969999923138, 31.398699999044766], "ttft_ms": [3.8117999993119156, 3.7389000008261064], "tokens_processed": [8, 8], "throughput_tok_s": [256.4949326283083, 254.78761860342567], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.890899999736575, 3.966099999161088, 3.8676999993185746], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 61.704, "gpu_power_peak_watts": 61.704, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2416.08203125, "cpu_memory_peak_mb": 2416.08203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653433.9339662}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.98390000013751, 31.433099999048864], "ttft_ms": [3.74760000158858, 3.8385999996535247], "tokens_processed": [8, 8], "throughput_tok_s": [258.19861282680665, 254.50878215136504], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.483799999434268, 4.105100000742823, 3.8129000004119007], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 61.704, "gpu_power_peak_watts": 61.704, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2416.0859375, "cpu_memory_peak_mb": 2416.0859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653434.0612702}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.87940000114031, 30.813900000794092], "ttft_ms": [3.7844999988010386, 3.7088999997649807], "tokens_processed": [8, 8], "throughput_tok_s": [259.07239129337285, 259.62309216924297], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.6743000002607005, 4.078099998878315, 4.059600001710351], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 62.751, "gpu_power_peak_watts": 62.751, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2416.0859375, "cpu_memory_peak_mb": 2416.0859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653434.1847062}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [38.601300000664196, 36.351100001411396], "ttft_ms": [4.652199999327422, 4.450299999007257], "tokens_processed": [32, 32], "throughput_tok_s": [828.98762475485, 880.3034845921455], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.773600000087754, 4.827499999009888, 4.797999999937019], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 62.751, "gpu_power_peak_watts": 62.751, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2424.15234375, "cpu_memory_peak_mb": 2424.15234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653434.3094995}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.668400000053225, 36.702299999888055], "ttft_ms": [4.668400000809925, 4.609600000549108], "tokens_processed": [32, 32], "throughput_tok_s": [872.6860184778598, 871.8799639286258], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.456200000480749, 4.69619999967108, 4.712300000392133], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 62.751, "gpu_power_peak_watts": 62.751, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2439.76171875, "cpu_memory_peak_mb": 2439.76171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653434.4353774}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.828399999649264, 37.147400000321795], "ttft_ms": [4.55830000100832, 4.503500000282656], "tokens_processed": [32, 32], "throughput_tok_s": [868.8946573922503, 861.4331016362597], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.1151000006939285, 4.667999999583117, 4.539800000202376], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 62.751, "gpu_power_peak_watts": 62.751, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2439.765625, "cpu_memory_peak_mb": 2439.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653434.5575445}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.24610000042594, 37.372400000094785], "ttft_ms": [4.757500000778236, 4.4989999987592455], "tokens_processed": [32, 32], "throughput_tok_s": [882.8536035497324, 856.246855966404], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.041200000050594, 4.819399999178131, 5.461900000227615], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 60.0, "gpu_power_mean_watts": 66.248, "gpu_power_peak_watts": 66.248, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2439.7734375, "cpu_memory_peak_mb": 2439.7734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653434.6823647}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.95540000060282, 35.63440000107221], "ttft_ms": [4.498299998886068, 4.43000000086613], "tokens_processed": [32, 32], "throughput_tok_s": [889.9914894414607, 898.0086657566045], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.506499999683001, 4.719800001112162, 4.375800001071184], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 60.0, "gpu_power_mean_watts": 66.248, "gpu_power_peak_watts": 66.248, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2439.7734375, "cpu_memory_peak_mb": 2439.7734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653434.8068564}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [43.78969999925175, 43.79569999946398], "ttft_ms": [5.198599999857834, 5.537900000490481], "tokens_processed": [32, 32], "throughput_tok_s": [730.7654539891068, 730.665339300243], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.79860000127519, 5.215299999690615, 5.05189999967115], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 60.0, "gpu_power_mean_watts": 66.248, "gpu_power_peak_watts": 66.248, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2445.9296875, "cpu_memory_peak_mb": 2445.9296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653434.9312024}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [40.29919999993581, 41.221700001187855], "ttft_ms": [4.982000000381959, 4.954500000167172], "tokens_processed": [32, 32], "throughput_tok_s": [794.0604279998355, 776.290157831382], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.318499999906635, 5.667299999913666, 5.420800000138115], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 60.0, "gpu_power_mean_watts": 66.248, "gpu_power_peak_watts": 66.248, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2468.640625, "cpu_memory_peak_mb": 2468.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653435.0543578}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [42.939999999362044, 40.95409999899857], "ttft_ms": [5.070400000477093, 5.212199999732547], "tokens_processed": [32, 32], "throughput_tok_s": [745.2258966109786, 781.3625498004468], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.592199999227887, 5.069900000307825, 5.008599999200669], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 60.0, "gpu_power_mean_watts": 71.198, "gpu_power_peak_watts": 71.198, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2468.640625, "cpu_memory_peak_mb": 2468.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653435.1794615}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [40.66380000040226, 40.32139999981155], "ttft_ms": [4.961899998306762, 4.997500000172295], "tokens_processed": [32, 32], "throughput_tok_s": [786.9407187641943, 793.623237292097], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.584700000326848, 5.02520000009099, 5.032799999753479], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 60.0, "gpu_power_mean_watts": 71.198, "gpu_power_peak_watts": 71.198, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2468.640625, "cpu_memory_peak_mb": 2468.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653435.3024359}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [41.84050000003481, 40.2486000002682], "ttft_ms": [5.19450000138022, 5.101799999465584], "tokens_processed": [32, 32], "throughput_tok_s": [764.8092159504159, 795.0587101113273], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.601299999398179, 5.2598999991460005, 5.023299998356379], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5768.01953125, "gpu_memory_peak_mb": 5768.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 60.0, "gpu_power_mean_watts": 71.198, "gpu_power_peak_watts": 71.198, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2468.640625, "cpu_memory_peak_mb": 2468.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2580.907699999443, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765653435.427099}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.14869999885559, 2.108000000589527, 2.1750999985670205], "resource_metrics": {"samples": 8, "duration_s": 0.720759391784668, "gpu_memory_mean_mb": 6132.7841796875, "gpu_memory_peak_mb": 6961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 68.9785, "gpu_power_peak_watts": 71.198, "gpu_temperature_mean_c": 48.25, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2988.458984375, "cpu_memory_peak_mb": 3419.875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1765653436.2550712}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5635000001784647, 2.162700000553741, 2.1775000004709], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6967.0390625, "gpu_memory_peak_mb": 6967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 54.087, "gpu_power_peak_watts": 54.087, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2668.68359375, "cpu_memory_peak_mb": 2668.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653436.3789842}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.665500000148313, 2.2497000009025214, 2.0867000002908753], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6967.0390625, "gpu_memory_peak_mb": 6967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 54.087, "gpu_power_peak_watts": 54.087, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2668.71484375, "cpu_memory_peak_mb": 2668.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653436.5064235}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.812300001096446, 2.213300000221352, 2.0893999990221346], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6967.0390625, "gpu_memory_peak_mb": 6967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 54.087, "gpu_power_peak_watts": 54.087, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2668.71484375, "cpu_memory_peak_mb": 2668.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653436.6307137}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.459100000123726, 2.0822999995289138, 2.0893000000796746], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6967.0390625, "gpu_memory_peak_mb": 6967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 37.144, "gpu_power_peak_watts": 37.144, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2668.71875, "cpu_memory_peak_mb": 2668.71875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653436.7569587}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2637999993312405, 2.1565000006376067, 2.113200000167126], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6967.0390625, "gpu_memory_peak_mb": 6967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 37.144, "gpu_power_peak_watts": 37.144, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2669.38671875, "cpu_memory_peak_mb": 2669.38671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653436.8835402}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.730999998675543, 2.163799999834737, 2.1955000011075754], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6967.0390625, "gpu_memory_peak_mb": 6967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 37.144, "gpu_power_peak_watts": 37.144, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2669.390625, "cpu_memory_peak_mb": 2669.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653437.0060902}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5895999988279073, 2.154300000256626, 2.2470000003522728], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6967.0390625, "gpu_memory_peak_mb": 6967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 37.144, "gpu_power_peak_watts": 37.144, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2669.390625, "cpu_memory_peak_mb": 2669.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653437.1304579}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.6354999990871875, 2.1498999994946644, 2.116000001478824], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6967.0390625, "gpu_memory_peak_mb": 6967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 38.51, "gpu_power_peak_watts": 38.51, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2669.390625, "cpu_memory_peak_mb": 2669.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653437.2526104}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5652999993326375, 2.190799999880255, 2.1687000007659663], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6967.0390625, "gpu_memory_peak_mb": 6967.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 38.51, "gpu_power_peak_watts": 38.51, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2669.3984375, "cpu_memory_peak_mb": 2669.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653437.3787875}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.7806000000273343, 2.36149999909685, 2.3075999997672625], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6969.0390625, "gpu_memory_peak_mb": 6969.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 38.51, "gpu_power_peak_watts": 38.51, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2671.0234375, "cpu_memory_peak_mb": 2671.0234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653437.5014222}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0869000001985114, 2.402300000539981, 2.4142999991454417], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6969.0390625, "gpu_memory_peak_mb": 6969.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 38.51, "gpu_power_peak_watts": 38.51, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2671.0234375, "cpu_memory_peak_mb": 2671.0234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653437.6258626}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.222299999833922, 2.84049999936542, 2.3342000004049623], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6969.0390625, "gpu_memory_peak_mb": 6969.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 36.633, "gpu_power_peak_watts": 36.633, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2671.0234375, "cpu_memory_peak_mb": 2671.0234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653437.7497854}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0061999987083254, 2.4009000007936265, 2.3665999997319886], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6969.0390625, "gpu_memory_peak_mb": 6969.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 36.633, "gpu_power_peak_watts": 36.633, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2671.03125, "cpu_memory_peak_mb": 2671.03125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653437.875085}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0334000002767425, 2.3576000003231457, 2.4902999994083075], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6969.0390625, "gpu_memory_peak_mb": 6969.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 36.633, "gpu_power_peak_watts": 36.633, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2671.03125, "cpu_memory_peak_mb": 2671.03125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653438.000475}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.2269000005035195, 2.574599999206839, 2.585700000054203], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6971.0390625, "gpu_memory_peak_mb": 6971.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 36.633, "gpu_power_peak_watts": 36.633, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2672.5625, "cpu_memory_peak_mb": 2672.5625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653438.1239831}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2887999986996874, 2.5991999991674675, 2.5519000009808224], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6971.0390625, "gpu_memory_peak_mb": 6971.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 34.432, "gpu_power_peak_watts": 34.432, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2672.57421875, "cpu_memory_peak_mb": 2672.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653438.2481065}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2615000000078, 2.532100001189974, 2.5599999989935895], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6971.0390625, "gpu_memory_peak_mb": 6971.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 34.432, "gpu_power_peak_watts": 34.432, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2672.57421875, "cpu_memory_peak_mb": 2672.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653438.3717403}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.4653000002435874, 2.5752999990800163, 2.529800000047544], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6971.0390625, "gpu_memory_peak_mb": 6971.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 34.432, "gpu_power_peak_watts": 34.432, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2672.5859375, "cpu_memory_peak_mb": 2672.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653438.4981794}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.5754000000451924, 2.5909999985742616, 2.611899999465095], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6971.0390625, "gpu_memory_peak_mb": 6971.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 34.432, "gpu_power_peak_watts": 34.432, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2672.58984375, "cpu_memory_peak_mb": 2672.58984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653438.6226232}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.366399999838904, 3.394700001081219, 3.36790000073961], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6963.0390625, "gpu_memory_peak_mb": 6963.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 33.475, "gpu_power_peak_watts": 33.475, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2671.5, "cpu_memory_peak_mb": 2671.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653438.7454212}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.883999999947264, 3.3813999998528743, 3.366700000697165], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6979.0390625, "gpu_memory_peak_mb": 6979.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 33.475, "gpu_power_peak_watts": 33.475, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2693.515625, "cpu_memory_peak_mb": 2693.515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653438.8707597}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.004099999496248, 3.4414000001561362, 3.468899998551933], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6979.0390625, "gpu_memory_peak_mb": 6979.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 33.475, "gpu_power_peak_watts": 33.475, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2693.5234375, "cpu_memory_peak_mb": 2693.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653438.9949672}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.316300001140917, 3.6719999989145435, 3.6717999992106343], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6979.0390625, "gpu_memory_peak_mb": 6979.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 33.475, "gpu_power_peak_watts": 33.475, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2693.53125, "cpu_memory_peak_mb": 2693.53125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653439.1181517}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.0494000006438, 3.4573999982967507, 3.4421999989717733], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6979.0390625, "gpu_memory_peak_mb": 6979.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 34.778, "gpu_power_peak_watts": 34.778, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2693.47265625, "cpu_memory_peak_mb": 2693.47265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653439.2419465}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.821899998612935, 3.971300000557676, 4.010500000731554], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6985.0390625, "gpu_memory_peak_mb": 6985.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 34.778, "gpu_power_peak_watts": 34.778, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2699.73828125, "cpu_memory_peak_mb": 2699.73828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653439.3655684}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.154200000310084, 3.9424999995389953, 4.010700000435463], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6985.0390625, "gpu_memory_peak_mb": 6985.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 34.778, "gpu_power_peak_watts": 34.778, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2699.7421875, "cpu_memory_peak_mb": 2699.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653439.490818}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.268699999054661, 4.004000000350061, 4.00170000102662], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6985.0390625, "gpu_memory_peak_mb": 6985.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 34.778, "gpu_power_peak_watts": 34.778, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2699.74609375, "cpu_memory_peak_mb": 2699.74609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653439.6177244}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.367899999531801, 4.124200000660494, 3.9633000014873687], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6985.0390625, "gpu_memory_peak_mb": 6985.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 12.0, "gpu_power_mean_watts": 35.758, "gpu_power_peak_watts": 35.758, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2699.74609375, "cpu_memory_peak_mb": 2699.74609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653439.7416708}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.0933000004297355, 3.9639000005990965, 3.9734000001772074], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6985.0390625, "gpu_memory_peak_mb": 6985.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 12.0, "gpu_power_mean_watts": 35.758, "gpu_power_peak_watts": 35.758, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2699.74609375, "cpu_memory_peak_mb": 2699.74609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 766.0209000005125, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653439.8664997}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [40.48449999936565, 1.6535000013391254, 1.6052999999374151], "resource_metrics": {"samples": 12, "duration_s": 1.1663448810577393, "gpu_memory_mean_mb": 7229.0390625, "gpu_memory_peak_mb": 8299.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 33.73341666666666, "gpu_power_peak_watts": 35.758, "gpu_temperature_mean_c": 46.166666666666664, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 3402.6311848958335, "cpu_memory_peak_mb": 3620.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765653441.140339}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.9857999996020226, 1.5639000012015458, 1.4203999999153893], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8299.0390625, "gpu_memory_peak_mb": 8299.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.855, "gpu_power_peak_watts": 30.855, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2801.46484375, "cpu_memory_peak_mb": 2801.46484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653441.26523}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.8044999997073319, 1.6317999998136656, 1.5406000002258224], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8299.0390625, "gpu_memory_peak_mb": 8299.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.855, "gpu_power_peak_watts": 30.855, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2801.50390625, "cpu_memory_peak_mb": 2801.50390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653441.3895068}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.984299999094219, 1.8411000000924105, 1.7550999982631765], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8299.0390625, "gpu_memory_peak_mb": 8299.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.855, "gpu_power_peak_watts": 30.855, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2801.515625, "cpu_memory_peak_mb": 2801.515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653441.5141907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.8278999996255152, 1.5547000002698041, 1.4114000005065463], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8299.0390625, "gpu_memory_peak_mb": 8299.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.855, "gpu_power_peak_watts": 30.855, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2801.52734375, "cpu_memory_peak_mb": 2801.52734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653441.64043}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.606599999126047, 1.5133000015339348, 1.421499999196385], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8299.0390625, "gpu_memory_peak_mb": 8299.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.54, "gpu_power_peak_watts": 31.54, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2802.24609375, "cpu_memory_peak_mb": 2802.24609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653441.765736}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.0046000008733245, 1.5196999993349891, 1.4686999984405702], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8299.0390625, "gpu_memory_peak_mb": 8299.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.54, "gpu_power_peak_watts": 31.54, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2802.25, "cpu_memory_peak_mb": 2802.25, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653441.8905332}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.052600000752136, 1.5025000011519296, 1.4726000008522533], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8299.0390625, "gpu_memory_peak_mb": 8299.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.54, "gpu_power_peak_watts": 31.54, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2802.2578125, "cpu_memory_peak_mb": 2802.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653442.015147}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.941399999850546, 1.5882000006968156, 1.5466999993805075], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8299.0390625, "gpu_memory_peak_mb": 8299.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.54, "gpu_power_peak_watts": 31.54, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2802.26171875, "cpu_memory_peak_mb": 2802.26171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653442.1409767}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.1773000007669907, 1.6716000009182608, 1.6622000002826098], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8299.0390625, "gpu_memory_peak_mb": 8299.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.317, "gpu_power_peak_watts": 31.317, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2802.265625, "cpu_memory_peak_mb": 2802.265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653442.2648509}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1708999995316844, 1.833700000133831, 1.8517000007705064], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8301.0390625, "gpu_memory_peak_mb": 8301.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.317, "gpu_power_peak_watts": 31.317, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2803.80859375, "cpu_memory_peak_mb": 2803.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653442.388313}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5950999988708645, 1.955199999429169, 2.056299999821931], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8301.0390625, "gpu_memory_peak_mb": 8301.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.317, "gpu_power_peak_watts": 31.317, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2803.80859375, "cpu_memory_peak_mb": 2803.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653442.5128906}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.6878999997279607, 2.170400000977679, 2.2017000010237098], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8301.0390625, "gpu_memory_peak_mb": 8301.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.317, "gpu_power_peak_watts": 31.317, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2803.80859375, "cpu_memory_peak_mb": 2803.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653442.639951}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.755299999989802, 2.0189999995636754, 1.9851999986713054], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8301.0390625, "gpu_memory_peak_mb": 8301.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.762, "gpu_power_peak_watts": 29.762, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2803.80859375, "cpu_memory_peak_mb": 2803.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653442.7627432}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8020999998261686, 2.1140999997442123, 2.0631000006687827], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8301.0390625, "gpu_memory_peak_mb": 8301.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.762, "gpu_power_peak_watts": 29.762, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2803.80859375, "cpu_memory_peak_mb": 2803.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653442.8860438}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.8879000003362307, 2.9114000008121366, 2.9083999997965293], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8303.0390625, "gpu_memory_peak_mb": 8303.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.762, "gpu_power_peak_watts": 29.762, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2805.34375, "cpu_memory_peak_mb": 2805.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653443.010571}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.435999999055639, 2.916600000389735, 2.9345000002649613], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8303.0390625, "gpu_memory_peak_mb": 8303.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.762, "gpu_power_peak_watts": 29.762, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2805.34765625, "cpu_memory_peak_mb": 2805.34765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653443.1355264}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.309300000182702, 2.95659999937925, 2.943999999843072], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8303.0390625, "gpu_memory_peak_mb": 8303.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 24.766, "gpu_power_peak_watts": 24.766, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2805.3515625, "cpu_memory_peak_mb": 2805.3515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653443.2600312}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.589300000385265, 3.0203000005712966, 2.9642000008607283], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8303.0390625, "gpu_memory_peak_mb": 8303.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 24.766, "gpu_power_peak_watts": 24.766, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2805.36328125, "cpu_memory_peak_mb": 2805.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653443.3831754}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.4992000000784174, 3.06549999913841, 2.991900000779424], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8303.0390625, "gpu_memory_peak_mb": 8303.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 24.766, "gpu_power_peak_watts": 24.766, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2805.36328125, "cpu_memory_peak_mb": 2805.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653443.5059922}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.540400001351372, 7.6420000004873145, 7.571299998744507], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8295.0390625, "gpu_memory_peak_mb": 8295.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 24.766, "gpu_power_peak_watts": 24.766, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2804.6171875, "cpu_memory_peak_mb": 2804.6171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653443.6282706}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.548300000256859, 7.718900000327267, 7.9258999994635815], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8311.0390625, "gpu_memory_peak_mb": 8311.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 18.884, "gpu_power_peak_watts": 18.884, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2825.953125, "cpu_memory_peak_mb": 2825.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653443.755214}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.851700000377605, 7.9117999994196, 7.9258000005211215], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8311.0390625, "gpu_memory_peak_mb": 8311.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 18.884, "gpu_power_peak_watts": 18.884, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2825.95703125, "cpu_memory_peak_mb": 2825.95703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653443.8780737}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [25.344699999550357, 25.222500000381842, 26.92659999956959], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8311.0390625, "gpu_memory_peak_mb": 8311.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 18.884, "gpu_power_peak_watts": 18.884, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2811.38671875, "cpu_memory_peak_mb": 2811.38671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653444.0029957}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [25.47220000087691, 26.60910000122385, 24.895599999581464], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8311.0390625, "gpu_memory_peak_mb": 8311.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 18.884, "gpu_power_peak_watts": 18.884, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2811.3984375, "cpu_memory_peak_mb": 2811.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653444.12662}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [28.812599999582744, 27.687699999660254, 27.781700000559795], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8317.0390625, "gpu_memory_peak_mb": 8317.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.236, "gpu_power_peak_watts": 17.236, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2811.3984375, "cpu_memory_peak_mb": 2811.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653444.2540329}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.273200000781799, 4.91620000138937, 5.090299999210401], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8317.0390625, "gpu_memory_peak_mb": 8317.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.236, "gpu_power_peak_watts": 17.236, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2832.10546875, "cpu_memory_peak_mb": 2832.10546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653444.3785753}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.027600000583334, 5.080200000520563, 4.989300001398078], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8317.0390625, "gpu_memory_peak_mb": 8317.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.236, "gpu_power_peak_watts": 17.236, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2832.10546875, "cpu_memory_peak_mb": 2832.10546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653444.5041652}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.053799999994226, 4.945100001350511, 4.888400000709225], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8317.0390625, "gpu_memory_peak_mb": 8317.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.236, "gpu_power_peak_watts": 17.236, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2832.11328125, "cpu_memory_peak_mb": 2832.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653444.6295707}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.472199999232544, 5.0889000012830365, 4.859799999394454], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8317.0390625, "gpu_memory_peak_mb": 8317.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 18.823, "gpu_power_peak_watts": 18.823, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2832.11328125, "cpu_memory_peak_mb": 2832.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 1129.790499999217, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653444.754288}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.895199998733005, 2.392300000792602, 2.3828999983379617], "resource_metrics": {"samples": 5, "duration_s": 0.44353604316711426, "gpu_memory_mean_mb": 8602.2390625, "gpu_memory_peak_mb": 9063.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 19.5606, "gpu_power_peak_watts": 20.667, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 3309.53359375, "cpu_memory_peak_mb": 3591.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1765653445.3059366}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.802299999530078, 2.5243000000045868, 2.4171999993995996], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9275.0390625, "gpu_memory_peak_mb": 9275.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 20.667, "gpu_power_peak_watts": 20.667, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2836.67578125, "cpu_memory_peak_mb": 2836.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653445.4275997}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0654000001959503, 2.2417999989556847, 2.2748999999748776], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9275.0390625, "gpu_memory_peak_mb": 9275.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 20.667, "gpu_power_peak_watts": 20.667, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2836.6875, "cpu_memory_peak_mb": 2836.6875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653445.5708477}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8203999991092132, 2.2432999994634883, 2.191300000049523], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9275.0390625, "gpu_memory_peak_mb": 9275.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 23.481, "gpu_power_peak_watts": 23.481, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2836.69140625, "cpu_memory_peak_mb": 2836.69140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653445.6970787}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.965200001199264, 2.3678999987168936, 2.3513000014645513], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9275.0390625, "gpu_memory_peak_mb": 9275.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 23.481, "gpu_power_peak_watts": 23.481, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2836.6953125, "cpu_memory_peak_mb": 2836.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653445.821684}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.922600000805687, 2.2885999987920513, 2.2347000012814533], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9275.0390625, "gpu_memory_peak_mb": 9275.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 23.481, "gpu_power_peak_watts": 23.481, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2837.3984375, "cpu_memory_peak_mb": 2837.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653445.949377}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.433500000028289, 2.3080999999365304, 2.281899998706649], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9275.0390625, "gpu_memory_peak_mb": 9275.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 23.481, "gpu_power_peak_watts": 23.481, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2837.3984375, "cpu_memory_peak_mb": 2837.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653446.0723567}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.133799998977338, 2.341700001124991, 2.309600000444334], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9275.0390625, "gpu_memory_peak_mb": 9275.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 25.719, "gpu_power_peak_watts": 25.719, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2837.3984375, "cpu_memory_peak_mb": 2837.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653446.1967437}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1846000001678476, 2.310300000317511, 2.3610000007465715], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9275.0390625, "gpu_memory_peak_mb": 9275.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 25.719, "gpu_power_peak_watts": 25.719, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2837.3984375, "cpu_memory_peak_mb": 2837.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653446.3216066}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0327000004035654, 2.582899998742505, 2.275299999382696], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9275.0390625, "gpu_memory_peak_mb": 9275.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 25.719, "gpu_power_peak_watts": 25.719, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2837.40625, "cpu_memory_peak_mb": 2837.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653446.4460363}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.377700000986806, 2.447500000926084, 2.40730000041367], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9277.0390625, "gpu_memory_peak_mb": 9277.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 25.719, "gpu_power_peak_watts": 25.719, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2838.94140625, "cpu_memory_peak_mb": 2838.94140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653446.5692725}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1381999997392995, 2.4676000011822907, 2.3806999997759704], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9277.0390625, "gpu_memory_peak_mb": 9277.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 26.404, "gpu_power_peak_watts": 26.404, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2838.94140625, "cpu_memory_peak_mb": 2838.94140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653446.6939714}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.961600001071929, 2.494799999112729, 2.4543000017729355], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9277.0390625, "gpu_memory_peak_mb": 9277.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 26.404, "gpu_power_peak_watts": 26.404, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2838.94140625, "cpu_memory_peak_mb": 2838.94140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653446.8200326}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.9436999993777135, 2.4752999997872394, 2.3956000004545785], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9277.0390625, "gpu_memory_peak_mb": 9277.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 26.404, "gpu_power_peak_watts": 26.404, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2838.94140625, "cpu_memory_peak_mb": 2838.94140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653446.959441}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2339999997930136, 2.455300000292482, 2.5081000003410736], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9277.0390625, "gpu_memory_peak_mb": 9277.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 26.404, "gpu_power_peak_watts": 26.404, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2838.94140625, "cpu_memory_peak_mb": 2838.94140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653447.0856118}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.661699999312987, 5.352100000891369, 5.362599998989026], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9279.0390625, "gpu_memory_peak_mb": 9279.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 26.44, "gpu_power_peak_watts": 26.44, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2840.47265625, "cpu_memory_peak_mb": 2840.47265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653447.2089822}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.900500000279862, 5.412200000137091, 5.536499998925137], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9279.0390625, "gpu_memory_peak_mb": 9279.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 26.44, "gpu_power_peak_watts": 26.44, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2840.47265625, "cpu_memory_peak_mb": 2840.47265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653447.3328605}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.896799999391078, 5.531099999643629, 5.587999999988824], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9279.0390625, "gpu_memory_peak_mb": 9279.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 26.44, "gpu_power_peak_watts": 26.44, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2840.47265625, "cpu_memory_peak_mb": 2840.47265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653447.455954}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.180900001709233, 5.7446999999228865, 5.762500000855653], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9279.0390625, "gpu_memory_peak_mb": 9279.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 26.44, "gpu_power_peak_watts": 26.44, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2840.48046875, "cpu_memory_peak_mb": 2840.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653447.5801282}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.276300000536139, 5.740700000387733, 5.792600000859238], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9279.0390625, "gpu_memory_peak_mb": 9279.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 17.0, "gpu_power_mean_watts": 22.88, "gpu_power_peak_watts": 22.88, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2840.484375, "cpu_memory_peak_mb": 2840.484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653447.7054417}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.2733000015578, 9.892800000670832, 9.898600001179148], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9271.0390625, "gpu_memory_peak_mb": 9271.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 17.0, "gpu_power_mean_watts": 22.88, "gpu_power_peak_watts": 22.88, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2838.94921875, "cpu_memory_peak_mb": 2838.94921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653447.8290517}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.891699999774573, 10.339399999793386, 10.299200001099962], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9287.0390625, "gpu_memory_peak_mb": 9287.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 17.0, "gpu_power_mean_watts": 22.88, "gpu_power_peak_watts": 22.88, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2859.21484375, "cpu_memory_peak_mb": 2859.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653447.9540079}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.65940000100818, 10.331999999834807, 10.335299999496783], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9287.0390625, "gpu_memory_peak_mb": 9287.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 17.0, "gpu_power_mean_watts": 22.88, "gpu_power_peak_watts": 22.88, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2859.21875, "cpu_memory_peak_mb": 2859.21875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653448.0794387}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.021100001220475, 10.64829999995709, 10.719800000515534], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9287.0390625, "gpu_memory_peak_mb": 9287.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 17.0, "gpu_power_mean_watts": 19.499, "gpu_power_peak_watts": 19.499, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2859.23046875, "cpu_memory_peak_mb": 2859.23046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653448.2033973}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.00789999893459, 10.964699999021832, 11.260799999945448], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9287.0390625, "gpu_memory_peak_mb": 9287.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 17.0, "gpu_power_mean_watts": 19.499, "gpu_power_peak_watts": 19.499, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2859.23828125, "cpu_memory_peak_mb": 2859.23828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653448.32793}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.511600000332692, 12.036600001010811, 12.337300000581308], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9293.0390625, "gpu_memory_peak_mb": 9293.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 17.0, "gpu_power_mean_watts": 19.499, "gpu_power_peak_watts": 19.499, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2844.72265625, "cpu_memory_peak_mb": 2844.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653448.4519234}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.591699998869444, 12.031099999148864, 12.287699999433244], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9293.0390625, "gpu_memory_peak_mb": 9293.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 17.0, "gpu_power_mean_watts": 19.499, "gpu_power_peak_watts": 19.499, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2856.78515625, "cpu_memory_peak_mb": 2856.78515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653448.5761075}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.65570000052685, 12.289700000110315, 12.300200000026962], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9293.0390625, "gpu_memory_peak_mb": 9293.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 19.075, "gpu_power_peak_watts": 19.075, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2862.72265625, "cpu_memory_peak_mb": 2862.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653448.6999533}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.6581999995542, 12.527299999419483, 12.625299999854178], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9293.0390625, "gpu_memory_peak_mb": 9293.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 19.075, "gpu_power_peak_watts": 19.075, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2865.59765625, "cpu_memory_peak_mb": 2865.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653448.8264484}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.619900000776397, 12.693599999693106, 12.854200000219862], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 9293.0390625, "gpu_memory_peak_mb": 9293.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 19.075, "gpu_power_peak_watts": 19.075, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2865.85546875, "cpu_memory_peak_mb": 2865.85546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765653069.0672815}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 57.23784100000012, "file_size_mb": 778.362361907959, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816172092, "file_size_mb": 778.362361907959, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653128.5847259, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 96.85176750000028, "file_size_mb": 941.8324089050293, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 987582860, "file_size_mb": 941.8324089050293, "deserialize_error": null, "num_layers": 792, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 224, "Int64": 243, "Float": 450}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653231.33721, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 83.4072971000005, "file_size_mb": 779.870677947998, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 817753676, "file_size_mb": 779.870677947998, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 51819, "cache_sha256_before": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31", "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765653321.6665063, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 509.7643999997672, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765653448.951953}
