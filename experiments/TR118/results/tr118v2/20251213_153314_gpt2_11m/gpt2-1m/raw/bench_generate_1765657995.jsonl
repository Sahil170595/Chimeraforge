{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [17.936599999302416, 15.210199999273755], "ttft_ms": [2.4977000011858763, 1.651500000662054], "tokens_processed": [8, 8], "throughput_tok_s": [446.015409849756, 525.962840750416], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2112.8591999986384, 288.67629999876954, 1.7801000012696022], "resource_metrics": {"samples": 18, "duration_s": 2.4584879875183105, "gpu_memory_mean_mb": 842.4639756944445, "gpu_memory_peak_mb": 950.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.248500000000003, "gpu_power_peak_watts": 29.376, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1131.9281684027778, "cpu_memory_peak_mb": 1472.54296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658255.741707}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [17.552600000271923, 15.45319999968342], "ttft_ms": [1.9940000001952285, 2.138300000297022], "tokens_processed": [8, 8], "throughput_tok_s": [455.7729339172581, 517.6921285017919], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.208500000051572, 1.7922999995789723, 2.016200000070967], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 950.01953125, "gpu_memory_peak_mb": 950.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.376, "gpu_power_peak_watts": 29.376, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1476.5625, "cpu_memory_peak_mb": 1476.5625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658255.8696454}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [18.728299999565934, 15.343999999458902], "ttft_ms": [2.193000000261236, 1.8500999995012535], "tokens_processed": [8, 8], "throughput_tok_s": [427.16103438034503, 521.376433803579], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.02199999896402, 2.1432000012282515, 1.679599999988568], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 950.01953125, "gpu_memory_peak_mb": 950.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.376, "gpu_power_peak_watts": 29.376, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1476.609375, "cpu_memory_peak_mb": 1476.609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658255.9930208}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.683399998844834, 15.70220000030531], "ttft_ms": [3.5778999990725424, 1.7155999994429294], "tokens_processed": [8, 8], "throughput_tok_s": [337.7893376960319, 509.4827476305517], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.692100000786013, 3.37279999985185, 3.4070000001520384], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 950.01953125, "gpu_memory_peak_mb": 950.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.376, "gpu_power_peak_watts": 29.376, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1476.65625, "cpu_memory_peak_mb": 1476.65625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658256.1159587}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [16.571800000747317, 15.634400000635651], "ttft_ms": [1.9911999988835305, 1.9158999984938418], "tokens_processed": [8, 8], "throughput_tok_s": [482.7478004585642, 511.69216597213466], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.2035000001778826, 1.699200000075507, 2.001599999857717], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 950.01953125, "gpu_memory_peak_mb": 950.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.168, "gpu_power_peak_watts": 31.168, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1476.6953125, "cpu_memory_peak_mb": 1476.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658256.2404969}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [53.026700001282734, 51.085800001601456], "ttft_ms": [7.4194000007992145, 6.592800000362331], "tokens_processed": [8, 8], "throughput_tok_s": [150.8673932152383, 156.59928981731153], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [791.2479000005987, 6.92940000044473, 5.924600000071223], "resource_metrics": {"samples": 9, "duration_s": 0.9112091064453125, "gpu_memory_mean_mb": 990.9084201388889, "gpu_memory_peak_mb": 996.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.672444444444448, "gpu_power_peak_watts": 32.318, "gpu_temperature_mean_c": 44.333333333333336, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1476.986545138889, "cpu_memory_peak_mb": 1486.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658257.2592885}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [50.62090000137687, 52.058899998883135], "ttft_ms": [5.634400000417372, 6.577099999049096], "tokens_processed": [8, 8], "throughput_tok_s": [158.03749043937194, 153.67209065446315], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.008500000461936, 6.598500000109198, 6.442700001571211], "resource_metrics": {"samples": 2, "duration_s": 0.11059165000915527, "gpu_memory_mean_mb": 996.01953125, "gpu_memory_peak_mb": 996.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.138, "gpu_power_peak_watts": 31.138, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1486.421875, "cpu_memory_peak_mb": 1486.421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658257.4777994}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [51.50829999911366, 59.45079999946756], "ttft_ms": [6.380900000294787, 6.063400000130059], "tokens_processed": [8, 8], "throughput_tok_s": [155.31477451474154, 134.5650521115216], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.664499998805695, 11.215200000151526, 5.6904000011854805], "resource_metrics": {"samples": 2, "duration_s": 0.10859394073486328, "gpu_memory_mean_mb": 996.01953125, "gpu_memory_peak_mb": 996.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.5, "gpu_power_mean_watts": 30.804000000000002, "gpu_power_peak_watts": 31.138, "gpu_temperature_mean_c": 44.5, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1486.447265625, "cpu_memory_peak_mb": 1486.44921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658257.694344}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [51.308899999639834, 51.05329999969399], "ttft_ms": [5.968199999188073, 6.663000000116881], "tokens_processed": [8, 8], "throughput_tok_s": [155.918368939037, 156.6989793029628], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.763600000340375, 6.115000000136206, 9.05109999985143], "resource_metrics": {"samples": 2, "duration_s": 0.1203298568725586, "gpu_memory_mean_mb": 996.01953125, "gpu_memory_peak_mb": 996.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.47, "gpu_power_peak_watts": 30.47, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1486.44921875, "cpu_memory_peak_mb": 1486.44921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658257.921713}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [50.60490000141726, 52.69959999895946], "ttft_ms": [6.533399999170797, 6.548000001203036], "tokens_processed": [8, 8], "throughput_tok_s": [158.087457929488, 151.80380876055906], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.447799998772098, 7.454900000084308, 5.870200000572368], "resource_metrics": {"samples": 2, "duration_s": 0.11333370208740234, "gpu_memory_mean_mb": 996.01953125, "gpu_memory_peak_mb": 996.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.198999999999998, "gpu_power_peak_watts": 31.928, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1486.51953125, "cpu_memory_peak_mb": 1486.51953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658258.1447525}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [53.69109999992361, 56.00690000028408], "ttft_ms": [6.7906000003858935, 6.697599999824888], "tokens_processed": [8, 8], "throughput_tok_s": [149.00048611429796, 142.8395429841577], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [792.354900000646, 6.845800000519375, 7.185000000390573], "resource_metrics": {"samples": 10, "duration_s": 0.9500277042388916, "gpu_memory_mean_mb": 1039.21953125, "gpu_memory_peak_mb": 1044.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.4, "gpu_power_mean_watts": 31.3904, "gpu_power_peak_watts": 31.928, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1482.796875, "cpu_memory_peak_mb": 1494.5078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658259.2079604}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [52.73989999841433, 55.748200000380166], "ttft_ms": [6.680799999230658, 5.691200000001118], "tokens_processed": [8, 8], "throughput_tok_s": [151.68781132009212, 143.50239110761325], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.377000000924454, 5.972400000246125, 6.181999999171239], "resource_metrics": {"samples": 2, "duration_s": 0.10979270935058594, "gpu_memory_mean_mb": 1044.01953125, "gpu_memory_peak_mb": 1044.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.977, "gpu_power_peak_watts": 29.977, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1494.5234375, "cpu_memory_peak_mb": 1494.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658259.4263525}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [52.00390000027255, 54.0900000014517], "ttft_ms": [6.475199999840697, 6.061399999452988], "tokens_processed": [8, 8], "throughput_tok_s": [153.83461624912886, 147.90164540183568], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.218900000225403, 7.126599999537575, 5.929200000537094], "resource_metrics": {"samples": 2, "duration_s": 0.11023139953613281, "gpu_memory_mean_mb": 1044.01953125, "gpu_memory_peak_mb": 1044.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.5, "gpu_power_mean_watts": 30.389499999999998, "gpu_power_peak_watts": 30.802, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1494.52734375, "cpu_memory_peak_mb": 1494.52734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658259.6461487}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [54.12290000094799, 55.27869999968971], "ttft_ms": [6.912799999554409, 6.621200000154204], "tokens_processed": [8, 8], "throughput_tok_s": [147.81173957529762, 144.72120364706308], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.664399999863235, 12.200600000142003, 6.197400000019115], "resource_metrics": {"samples": 2, "duration_s": 0.11126041412353516, "gpu_memory_mean_mb": 1044.01953125, "gpu_memory_peak_mb": 1044.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.802, "gpu_power_peak_watts": 30.802, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1494.54296875, "cpu_memory_peak_mb": 1494.54296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658259.8667269}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [55.489300000772346, 54.75840000144672], "ttft_ms": [6.757800001651049, 6.130399999165093], "tokens_processed": [8, 8], "throughput_tok_s": [144.17193945298732, 146.09630668150714], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.679399999484303, 6.059700001060264, 7.304500000827829], "resource_metrics": {"samples": 2, "duration_s": 0.1190178394317627, "gpu_memory_mean_mb": 1044.01953125, "gpu_memory_peak_mb": 1044.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.802, "gpu_power_peak_watts": 30.802, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1494.54296875, "cpu_memory_peak_mb": 1494.54296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658260.0981348}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [78.94619999933639, 70.10799999989104], "ttft_ms": [8.455400000457303, 8.484199999656994], "tokens_processed": [8, 8], "throughput_tok_s": [101.33483308971486, 114.1096593828441], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1092.1565999997256, 8.596899999247398, 8.189100000890903], "resource_metrics": {"samples": 12, "duration_s": 1.2494988441467285, "gpu_memory_mean_mb": 1086.1861979166667, "gpu_memory_peak_mb": 1090.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.6666666666666667, "gpu_power_mean_watts": 27.101, "gpu_power_peak_watts": 32.344, "gpu_temperature_mean_c": 44.333333333333336, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1486.19921875, "cpu_memory_peak_mb": 1502.7109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658261.45824}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [66.2159999992582, 91.98549999928218], "ttft_ms": [8.107200001177262, 8.1609999997454], "tokens_processed": [8, 8], "throughput_tok_s": [120.8167210355446, 86.97022900416293], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.921699999831617, 8.05199999922479, 8.087700000032783], "resource_metrics": {"samples": 2, "duration_s": 0.11336112022399902, "gpu_memory_mean_mb": 1090.01953125, "gpu_memory_peak_mb": 1090.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.5, "gpu_power_mean_watts": 17.191000000000003, "gpu_power_peak_watts": 20.324, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1502.71484375, "cpu_memory_peak_mb": 1502.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658261.6892452}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [156.780000001163, 84.40260000134003], "ttft_ms": [17.73519999915152, 16.895700000532088], "tokens_processed": [8, 8], "throughput_tok_s": [51.026916698179974, 94.7838099759129], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.182800000431598, 23.99149999837391, 19.395900000745314], "resource_metrics": {"samples": 3, "duration_s": 0.21545886993408203, "gpu_memory_mean_mb": 1090.01953125, "gpu_memory_peak_mb": 1090.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 14.058, "gpu_power_peak_watts": 14.058, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1502.71484375, "cpu_memory_peak_mb": 1502.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658262.0204496}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [88.16490000026533, 89.29929999976594], "ttft_ms": [16.296499999953085, 8.627499999420252], "tokens_processed": [8, 8], "throughput_tok_s": [90.73905828709525, 89.58636853839805], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.473500000036438, 8.501100001012674, 15.974599999026395], "resource_metrics": {"samples": 2, "duration_s": 0.12275195121765137, "gpu_memory_mean_mb": 1090.01953125, "gpu_memory_peak_mb": 1090.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 14.63, "gpu_power_peak_watts": 14.63, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1502.71484375, "cpu_memory_peak_mb": 1502.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658262.258637}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [121.45409999902768, 95.99530000014056], "ttft_ms": [13.054299999566865, 15.183899999101413], "tokens_processed": [8, 8], "throughput_tok_s": [65.86850505717013, 83.3374133940754], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.48229999934847, 13.343800001166528, 18.963399999847752], "resource_metrics": {"samples": 3, "duration_s": 0.21576952934265137, "gpu_memory_mean_mb": 1090.01953125, "gpu_memory_peak_mb": 1090.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 14.63, "gpu_power_peak_watts": 14.63, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1502.72265625, "cpu_memory_peak_mb": 1502.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658262.5896895}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [176.53249999966647, 148.45840000089083], "ttft_ms": [18.053300000246963, 26.162999998632586], "tokens_processed": [32, 32], "throughput_tok_s": [181.2697378673075, 215.54859812451153], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1035.69410000091, 19.1501999997854, 18.658200000572833], "resource_metrics": {"samples": 14, "duration_s": 1.4440011978149414, "gpu_memory_mean_mb": 1134.5909598214287, "gpu_memory_peak_mb": 1138.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.714285714285715, "gpu_power_mean_watts": 9.714857142857143, "gpu_power_peak_watts": 14.329, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1498.5170200892858, "cpu_memory_peak_mb": 1529.49609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658264.1503465}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [106.62159999992582, 104.72130000016477], "ttft_ms": [11.92339999943215, 11.875200001668418], "tokens_processed": [32, 32], "throughput_tok_s": [300.126803574719, 305.572982764248], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [20.658499999626656, 21.665399999619694, 17.629399999350426], "resource_metrics": {"samples": 3, "duration_s": 0.2130417823791504, "gpu_memory_mean_mb": 1138.01953125, "gpu_memory_peak_mb": 1138.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 4.742, "gpu_power_peak_watts": 4.742, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1529.2838541666667, "cpu_memory_peak_mb": 1529.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658264.4773395}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [128.54930000139575, 102.74550000031013], "ttft_ms": [11.45610000094166, 11.583600000449223], "tokens_processed": [32, 32], "throughput_tok_s": [248.93173280331013, 311.4491632227534], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.492200000357116, 12.653600000703591, 15.829100000701146], "resource_metrics": {"samples": 3, "duration_s": 0.21107959747314453, "gpu_memory_mean_mb": 1138.01953125, "gpu_memory_peak_mb": 1138.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.666666666666668, "gpu_power_mean_watts": 11.384, "gpu_power_peak_watts": 14.705, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1524.6184895833333, "cpu_memory_peak_mb": 1529.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658264.8023639}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [162.2551000000385, 125.05069999861007], "ttft_ms": [19.852699999319157, 11.60859999981767], "tokens_processed": [32, 32], "throughput_tok_s": [197.22030309058024, 255.89620850067755], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [19.946899999922607, 19.78190000045288, 19.2760999998427], "resource_metrics": {"samples": 4, "duration_s": 0.31168437004089355, "gpu_memory_mean_mb": 1138.01953125, "gpu_memory_peak_mb": 1138.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 14.719999999999999, "gpu_power_peak_watts": 14.735, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1518.5302734375, "cpu_memory_peak_mb": 1529.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658265.2265985}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [131.37260000075912, 104.90480000044045], "ttft_ms": [20.775400000275113, 11.426099999880535], "tokens_processed": [32, 32], "throughput_tok_s": [243.58199502647503, 305.03847297612356], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [20.375699999931385, 22.041000000172062, 20.05250000001979], "resource_metrics": {"samples": 3, "duration_s": 0.21868538856506348, "gpu_memory_mean_mb": 1138.01953125, "gpu_memory_peak_mb": 1138.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 14.735, "gpu_power_peak_watts": 14.735, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1524.625, "cpu_memory_peak_mb": 1529.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658265.5569763}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [117.89709999902698, 122.52470000021276], "ttft_ms": [14.154599999528727, 13.7207000007038], "tokens_processed": [32, 32], "throughput_tok_s": [271.4231308510905, 261.17182902667327], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [850.1157999999123, 16.671399998813285, 13.503300000593299], "resource_metrics": {"samples": 11, "duration_s": 1.1158061027526855, "gpu_memory_mean_mb": 1183.8377130681818, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.81818181818182, "gpu_power_mean_watts": 12.95290909090909, "gpu_power_peak_watts": 14.885, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1516.8128551136363, "cpu_memory_peak_mb": 1554.4375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658266.780159}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [77.13030000013532, 76.26729999901727], "ttft_ms": [9.483600000748993, 9.277700000893674], "tokens_processed": [32, 32], "throughput_tok_s": [414.88234844080546, 419.5769353368001], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.13479999973788, 9.051600000020699, 9.079100000235485], "resource_metrics": {"samples": 2, "duration_s": 0.11202335357666016, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 11.961, "gpu_power_peak_watts": 11.961, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1554.45703125, "cpu_memory_peak_mb": 1554.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658267.0036108}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [75.37760000013805, 73.84540000020934], "ttft_ms": [8.829599999444326, 7.563500001197099], "tokens_processed": [32, 32], "throughput_tok_s": [424.52930313437145, 433.33775698837417], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.897699999986799, 11.570700000447687, 9.180799999739975], "resource_metrics": {"samples": 2, "duration_s": 0.11762237548828125, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 20.449, "gpu_power_peak_watts": 20.449, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1554.45703125, "cpu_memory_peak_mb": 1554.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658267.2323816}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [76.23400000011316, 78.26180000120075], "ttft_ms": [9.222200000294833, 10.533599999689613], "tokens_processed": [32, 32], "throughput_tok_s": [419.76021197828396, 408.88402770584156], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.848799999730545, 9.041399998750421, 9.1141000011703], "resource_metrics": {"samples": 2, "duration_s": 0.11346769332885742, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 20.449, "gpu_power_peak_watts": 20.449, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1554.45703125, "cpu_memory_peak_mb": 1554.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658267.4534953}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [76.84059999883175, 77.45880000038596], "ttft_ms": [9.51600000007602, 9.42380000014964], "tokens_processed": [32, 32], "throughput_tok_s": [416.4465139585911, 413.1228472406047], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.076799999093055, 8.9497000008123, 9.410700000444194], "resource_metrics": {"samples": 2, "duration_s": 0.10776638984680176, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.5, "gpu_power_mean_watts": 21.520000000000003, "gpu_power_peak_watts": 22.591, "gpu_temperature_mean_c": 44.5, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1554.45703125, "cpu_memory_peak_mb": 1554.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2496.6827999996895, "compile_ms": 936.9815000009112, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765658267.670389}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [15.755000000353903, 15.274699999281438], "ttft_ms": [1.6636000000289641, 1.935300000695861], "tokens_processed": [8, 8], "throughput_tok_s": [507.7753094141731, 523.7418738421272], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.985800000009476, 2.384100000199396, 2.2051000014471356], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 22.591, "gpu_power_peak_watts": 22.591, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1561.46875, "cpu_memory_peak_mb": 1561.46875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658267.805077}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.067600000998937, 12.371799999527866], "ttft_ms": [2.3791999992681667, 1.732199998514261], "tokens_processed": [8, 8], "throughput_tok_s": [568.6826466086555, 646.6318563430783], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.3433999995177146, 1.9654999996419065, 1.983000000109314], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 22.591, "gpu_power_peak_watts": 22.591, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1561.49609375, "cpu_memory_peak_mb": 1561.49609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658267.9398444}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.23379999869212, 13.934500000686967], "ttft_ms": [1.9403000005695503, 1.6364999992219964], "tokens_processed": [8, 8], "throughput_tok_s": [562.0424623596709, 574.1146076002442], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.589899999293266, 2.153100000214181, 2.4051000000326894], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 22.591, "gpu_power_peak_watts": 22.591, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1561.49609375, "cpu_memory_peak_mb": 1561.49609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658268.066615}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [13.252999999167514, 15.195800000583404], "ttft_ms": [2.112699999997858, 1.766499999575899], "tokens_processed": [8, 8], "throughput_tok_s": [603.6369124351105, 526.4612590118888], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.2308000006887596, 2.0578000003297348, 1.821100000597653], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 21.286, "gpu_power_peak_watts": 21.286, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1561.49609375, "cpu_memory_peak_mb": 1561.49609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658268.1941617}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [16.407999999501044, 17.140899999503745], "ttft_ms": [2.412099998764461, 2.4023999994824408], "tokens_processed": [8, 8], "throughput_tok_s": [487.56704048289095, 466.7199505411975], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.4123000002873596, 2.410200000667828, 1.930000000356813], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 21.286, "gpu_power_peak_watts": 21.286, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1561.50390625, "cpu_memory_peak_mb": 1561.50390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658268.3179686}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [16.405799999120063, 17.767199999070726], "ttft_ms": [2.11699999999837, 2.224500000011176], "tokens_processed": [8, 8], "throughput_tok_s": [487.6324227059385, 450.26790942964686], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.086299999267794, 2.3425000017596176, 2.5330999997095205], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 21.286, "gpu_power_peak_watts": 21.286, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1562.17578125, "cpu_memory_peak_mb": 1562.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658268.4376528}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [16.259400001217728, 16.633199998977943], "ttft_ms": [2.0668999986810377, 2.050700000836514], "tokens_processed": [8, 8], "throughput_tok_s": [492.02307584540944, 480.9657793143577], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.117600001132814, 2.5920999996742466, 2.2896999998920364], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 21.286, "gpu_power_peak_watts": 21.286, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1562.85546875, "cpu_memory_peak_mb": 1562.85546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658268.5654871}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [15.357199999925797, 14.864300001136144], "ttft_ms": [2.200600001742714, 1.3828999999532243], "tokens_processed": [8, 8], "throughput_tok_s": [520.9282942228176, 538.202269826936], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.420499999061576, 2.251399999295245, 2.329200000531273], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.162, "gpu_power_peak_watts": 21.162, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1562.9140625, "cpu_memory_peak_mb": 1562.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658268.688971}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [19.195099999706144, 18.650200001502526], "ttft_ms": [2.077699999063043, 2.2332999997161096], "tokens_processed": [8, 8], "throughput_tok_s": [416.77303062356907, 428.94982355982734], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.947699998912867, 2.323900000192225, 2.3409999994328246], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.162, "gpu_power_peak_watts": 21.162, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1562.9140625, "cpu_memory_peak_mb": 1562.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658268.8123333}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [16.153299999132287, 15.754599999127095], "ttft_ms": [2.1028999999543885, 1.9155999998474726], "tokens_processed": [8, 8], "throughput_tok_s": [495.2548395949892, 507.7882015692719], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8984999989916105, 2.1863999991182936, 2.384600000368664], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.162, "gpu_power_peak_watts": 21.162, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1562.94140625, "cpu_memory_peak_mb": 1562.94140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658268.9387064}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.513600000413135, 20.336800000222865], "ttft_ms": [2.0547999993141275, 2.5456000003032386], "tokens_processed": [8, 8], "throughput_tok_s": [389.9851805552845, 393.37555563866147], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6675000010291114, 3.092599999945378, 2.3701999998593237], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.162, "gpu_power_peak_watts": 21.162, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1568.4921875, "cpu_memory_peak_mb": 1568.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658269.063069}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.897600000040256, 18.443200000547222], "ttft_ms": [2.0087000011699274, 1.4147000001685228], "tokens_processed": [8, 8], "throughput_tok_s": [536.9992481996014, 433.76420576486913], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.964100000099279, 2.1777000001748092, 2.60330000128306], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.159, "gpu_power_peak_watts": 21.159, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1574.171875, "cpu_memory_peak_mb": 1574.171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658269.1893249}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [19.6923000003153, 21.97890000024927], "ttft_ms": [2.300199999808683, 2.9288999994605547], "tokens_processed": [8, 8], "throughput_tok_s": [406.25015868496365, 363.9854587767936], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.225399999791989, 2.764700000625453, 2.7370999996492174], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.159, "gpu_power_peak_watts": 21.159, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1574.171875, "cpu_memory_peak_mb": 1574.171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658269.314666}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.191800000247895, 21.101799999087234], "ttft_ms": [2.972399999634945, 2.531500000259257], "tokens_processed": [8, 8], "throughput_tok_s": [396.2004377966196, 379.11457791970554], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.281399998741108, 2.8802000015275553, 2.619599999889033], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.159, "gpu_power_peak_watts": 21.159, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1574.17578125, "cpu_memory_peak_mb": 1574.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658269.4377992}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [16.799900000478374, 20.11029999994207], "ttft_ms": [1.518999999461812, 2.341899999009911], "tokens_processed": [8, 8], "throughput_tok_s": [476.19331066090876, 397.8060993631644], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.892799999244744, 3.063500000280328, 2.1797000008518808], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.159, "gpu_power_peak_watts": 21.159, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1574.17578125, "cpu_memory_peak_mb": 1574.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658269.5656984}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [19.99220000107016, 22.485699999378994], "ttft_ms": [2.7966999987256713, 2.3925000004965113], "tokens_processed": [8, 8], "throughput_tok_s": [400.15606084231695, 355.78167458522273], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.152000001136912, 2.6136999986192677, 2.3885999999038177], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.159, "gpu_power_peak_watts": 21.159, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1576.70703125, "cpu_memory_peak_mb": 1576.70703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658269.6904068}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.639500000877888, 20.496099999945727], "ttft_ms": [2.4483000015607104, 2.625500001158798], "tokens_processed": [8, 8], "throughput_tok_s": [353.3646944362634, 390.3181580896455], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.48649999978079, 2.877700000681216, 3.041599999050959], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.159, "gpu_power_peak_watts": 21.159, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1577.30859375, "cpu_memory_peak_mb": 1577.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658269.813794}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.451500000897795, 21.665399999619694], "ttft_ms": [3.2957000003079884, 3.0220000007830095], "tokens_processed": [8, 8], "throughput_tok_s": [356.3236309235505, 369.2523562980803], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8966000008949777, 3.0912000001990236, 3.259799999796087], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.159, "gpu_power_peak_watts": 21.159, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1577.30859375, "cpu_memory_peak_mb": 1577.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658269.939603}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.09969999967143, 21.752100001322106], "ttft_ms": [2.514399999199668, 2.7616000006673858], "tokens_processed": [8, 8], "throughput_tok_s": [361.9958642026336, 367.7805820823624], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3934000002773246, 2.876099999411963, 3.2322999995813007], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.159, "gpu_power_peak_watts": 21.159, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1577.30859375, "cpu_memory_peak_mb": 1577.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658270.065349}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.793099999034894, 23.26549999997951], "ttft_ms": [2.4133000006258953, 2.8579999998328276], "tokens_processed": [8, 8], "throughput_tok_s": [350.9834116613684, 343.85678364991276], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2910999998421175, 2.8103999993618345, 3.0662999997730367], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 11.835, "gpu_power_peak_watts": 11.835, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1577.31640625, "cpu_memory_peak_mb": 1577.31640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658270.1907153}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.61560000000463, 31.55979999974079], "ttft_ms": [4.41569999929925, 3.4285999990970595], "tokens_processed": [32, 32], "throughput_tok_s": [873.9444389821812, 1013.9481238874399], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.223300000579911, 4.25090000135242, 3.565000000889995], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 11.835, "gpu_power_peak_watts": 11.835, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1585.9921875, "cpu_memory_peak_mb": 1585.9921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658270.3181753}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.318599999300204, 35.63499999836495], "ttft_ms": [4.165899999861722, 4.008800000519841], "tokens_processed": [32, 32], "throughput_tok_s": [906.0381782016852, 897.9935457125935], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.447999999683816, 4.436500001247623, 4.2751999990287], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 11.835, "gpu_power_peak_watts": 11.835, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1601.625, "cpu_memory_peak_mb": 1601.625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658270.4437237}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [38.720000000466825, 37.321499999961816], "ttft_ms": [4.985499999747844, 4.730499998913729], "tokens_processed": [32, 32], "throughput_tok_s": [826.4462809817716, 857.414626958529], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.694999999628635, 4.473399998460081, 4.377700000986806], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 11.835, "gpu_power_peak_watts": 11.835, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1601.6328125, "cpu_memory_peak_mb": 1601.6328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658270.5696042}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.73549999984971, 34.856000000218046], "ttft_ms": [3.961899999922025, 4.392400000142516], "tokens_processed": [32, 32], "throughput_tok_s": [871.0919954847741, 918.0628873020376], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.0290999988646945, 3.782199999477598, 3.6145000012766104], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 11.835, "gpu_power_peak_watts": 11.835, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1601.640625, "cpu_memory_peak_mb": 1601.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658270.6951663}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [37.73970000111149, 35.18659999826923], "ttft_ms": [4.566800000247895, 4.849400000239257], "tokens_processed": [32, 32], "throughput_tok_s": [847.9134704053704, 909.437115310204], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.865300001256401, 4.093300000022282, 4.301599999962491], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 11.835, "gpu_power_peak_watts": 11.835, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1601.640625, "cpu_memory_peak_mb": 1601.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658270.8196158}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.99670000102196, 46.10290000164241], "ttft_ms": [5.513799998880131, 6.058599999960279], "tokens_processed": [32, 32], "throughput_tok_s": [666.7125031370624, 694.0995034772217], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.170900000142865, 5.144099999597529, 5.742100000134087], "resource_metrics": {"samples": 2, "duration_s": 0.1105802059173584, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 11.835, "gpu_power_peak_watts": 11.835, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1619.3203125, "cpu_memory_peak_mb": 1630.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658271.0414896}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [42.22529999969993, 44.55710000002], "ttft_ms": [5.897099999856437, 5.5167000009532785], "tokens_processed": [32, 32], "throughput_tok_s": [757.839494336983, 718.1795942730931], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.504799999471288, 4.242799999701674, 5.15350000023318], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 6.606, "gpu_power_peak_watts": 6.606, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1630.67578125, "cpu_memory_peak_mb": 1630.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658271.1606312}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.66850000123668, 47.45259999981499], "ttft_ms": [6.443300000682939, 6.208200000401121], "tokens_processed": [32, 32], "throughput_tok_s": [671.3028519707944, 674.357147977661], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.7720000004337635, 5.993599999783328, 5.361899999115849], "resource_metrics": {"samples": 2, "duration_s": 0.1133575439453125, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 6.606, "gpu_power_peak_watts": 6.606, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1630.67578125, "cpu_memory_peak_mb": 1630.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658271.3892634}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.03969999900437, 45.407800000248244], "ttft_ms": [5.565199999182369, 5.827799999678973], "tokens_processed": [32, 32], "throughput_tok_s": [680.2764473556869, 704.7247389176541], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.067399999665213, 5.123700000694953, 5.86230000044452], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 6.606, "gpu_power_peak_watts": 6.606, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1630.67578125, "cpu_memory_peak_mb": 1630.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658271.521408}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [46.88039999928151, 43.87409999981173], "ttft_ms": [5.190699999729986, 5.830199999763863], "tokens_processed": [32, 32], "throughput_tok_s": [682.5880325357812, 729.359690572281], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.527799999981653, 4.9450999995315215, 4.804399999557063], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1206.01953125, "gpu_memory_peak_mb": 1206.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 6.606, "gpu_power_peak_watts": 6.606, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1630.7890625, "cpu_memory_peak_mb": 1630.7890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 290.35189999922295, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658271.6454065}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [44.502799999463605, 52.252299999963725], "ttft_ms": [5.347400001483038, 5.502699999851757], "tokens_processed": [8, 8], "throughput_tok_s": [179.76396990967814, 153.10330837122106], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [112.35889999989013, 5.745099999330705, 6.41879999966477], "resource_metrics": {"samples": 3, "duration_s": 0.21284222602844238, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 6.605999999999999, "gpu_power_peak_watts": 6.606, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1730.6158854166667, "cpu_memory_peak_mb": 1774.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658271.9712834}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [45.5603999998857, 44.163900000057765], "ttft_ms": [5.575200000748737, 5.4870000003575115], "tokens_processed": [8, 8], "throughput_tok_s": [175.59108348522113, 181.14342256887494], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.001399999149726, 5.229399999734596, 5.718700000215904], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 6.606, "gpu_power_peak_watts": 6.606, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1774.59375, "cpu_memory_peak_mb": 1774.59375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658272.0951867}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [43.02550000102201, 41.7025000006106], "ttft_ms": [5.446900000606547, 5.404800000178511], "tokens_processed": [8, 8], "throughput_tok_s": [185.93624710485577, 191.83502187837337], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.164099999296013, 5.539799998587114, 4.885899999862886], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.016, "gpu_power_peak_watts": 2.016, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1774.625, "cpu_memory_peak_mb": 1774.625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658272.2166905}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [41.10860000037064, 40.46100000050501], "ttft_ms": [4.811599999811733, 4.86319999981788], "tokens_processed": [8, 8], "throughput_tok_s": [194.6064813671074, 197.7212624477929], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.751799999619834, 4.6160000001691515, 4.645600000003469], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.016, "gpu_power_peak_watts": 2.016, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1774.63671875, "cpu_memory_peak_mb": 1774.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658272.3400245}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.33140000035928, 26.891899999100133], "ttft_ms": [4.86799999998766, 3.5195999989809934], "tokens_processed": [8, 8], "throughput_tok_s": [226.42748376567724, 297.48734750120667], "predicted_tokens": ["", ""], "outputs": ["Hello , the first time , and the first", "Test , the first of the first time ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.967600000076345, 5.3478999998333165, 4.822799999601557], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.016, "gpu_power_peak_watts": 2.016, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1774.69921875, "cpu_memory_peak_mb": 1774.69921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658272.4630492}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.04649999961839, 28.99969999998575], "ttft_ms": [3.3530999990034616, 3.869000000122469], "tokens_processed": [8, 8], "throughput_tok_s": [285.24058260777105, 275.8649227407156], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.963299999872106, 3.510900000037509, 3.8229999991017394], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.016, "gpu_power_peak_watts": 2.016, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1775.6796875, "cpu_memory_peak_mb": 1775.6796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658272.5875118}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.37369999906514, 28.42150000105903], "ttft_ms": [3.9068000005499925, 3.6106999996263767], "tokens_processed": [8, 8], "throughput_tok_s": [281.9512435904935, 281.4770508137117], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.897699998968164, 4.880899999989197, 3.7028999995527556], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 3.046, "gpu_power_peak_watts": 3.046, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1776.2421875, "cpu_memory_peak_mb": 1776.2421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658272.712992}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.691799998341594, 26.54640000037034], "ttft_ms": [3.692300000693649, 3.4319000005780254], "tokens_processed": [8, 8], "throughput_tok_s": [278.8253089894118, 301.35912967062933], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.22530000146071, 5.664400001478498, 3.768500000660424], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 3.046, "gpu_power_peak_watts": 3.046, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1776.25, "cpu_memory_peak_mb": 1776.25, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658272.834656}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.156299998954637, 29.462899999998626], "ttft_ms": [3.688600001623854, 3.7544000006164424], "tokens_processed": [8, 8], "throughput_tok_s": [284.12824129225135, 271.5279215555961], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.385499998941668, 4.696099998909631, 3.63160000051721], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 3.046, "gpu_power_peak_watts": 3.046, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1776.2578125, "cpu_memory_peak_mb": 1776.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658272.9592152}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.320600000573904, 27.524700000867597], "ttft_ms": [3.687699998408789, 3.748999999515945], "tokens_processed": [8, 8], "throughput_tok_s": [272.84571256534355, 290.6480361183895], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.6172000002115965, 6.241099999897415, 3.264699998908327], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 3.046, "gpu_power_peak_watts": 3.046, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1776.265625, "cpu_memory_peak_mb": 1776.265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658273.081758}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [34.05959999872721, 40.04320000058215], "ttft_ms": [4.450800000995514, 4.390899999634712], "tokens_processed": [8, 8], "throughput_tok_s": [234.88238265566702, 199.78423302542495], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.08350000079372, 6.346699999994598, 4.470899999432731], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 9.472, "gpu_power_peak_watts": 9.472, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1781.7265625, "cpu_memory_peak_mb": 1781.7265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658273.205724}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [41.23990000152844, 37.69060000013269], "ttft_ms": [6.9922000002407, 4.084700000021257], "tokens_processed": [8, 8], "throughput_tok_s": [193.98689132862842, 212.25451438745566], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.853299999420415, 6.019200000082492, 4.423099999257829], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 9.472, "gpu_power_peak_watts": 9.472, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1787.4921875, "cpu_memory_peak_mb": 1787.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658273.3291533}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.4356999998563, 34.515199999077595], "ttft_ms": [6.456000000980566, 4.000499999165186], "tokens_processed": [8, 8], "throughput_tok_s": [219.56487730526797, 231.78193955746445], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.4996999988361495, 6.422899999961373, 4.779900000357884], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 9.472, "gpu_power_peak_watts": 9.472, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1787.51171875, "cpu_memory_peak_mb": 1787.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658273.4539292}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.518800001227646, 34.27179999926011], "ttft_ms": [4.432100000485661, 4.311199998483062], "tokens_processed": [8, 8], "throughput_tok_s": [225.23283443482026, 233.42806622858183], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.265699999654316, 4.10340000053111, 4.500999999436317], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 9.472, "gpu_power_peak_watts": 9.472, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1787.51171875, "cpu_memory_peak_mb": 1787.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658273.5786839}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.988299999487936, 36.440900001252885], "ttft_ms": [4.309400001147878, 4.456399999980931], "tokens_processed": [8, 8], "throughput_tok_s": [242.5102233253663, 219.53354609038058], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.88570000056643, 4.054200000609853, 4.120099998544902], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 14.272, "gpu_power_peak_watts": 14.272, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1787.51171875, "cpu_memory_peak_mb": 1787.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658273.723708}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [39.395499999955064, 28.07080000093265], "ttft_ms": [4.807399998753681, 4.74940000094648], "tokens_processed": [8, 8], "throughput_tok_s": [203.06887842543247, 284.9936588816208], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.3551000002917135, 4.793100000824779, 5.086999999548425], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 14.272, "gpu_power_peak_watts": 14.272, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1789.10546875, "cpu_memory_peak_mb": 1789.10546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658273.844254}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.366600000168546, 22.485099998448277], "ttft_ms": [2.747500000623404, 2.6209000006929273], "tokens_processed": [8, 8], "throughput_tok_s": [357.6761778696679, 355.7911683982766], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1328999994002515, 2.717299999858369, 2.6054000009025913], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 14.272, "gpu_power_peak_watts": 14.272, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1790.60546875, "cpu_memory_peak_mb": 1790.60546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658273.9724941}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.78429999932996, 21.972499998810235], "ttft_ms": [2.629299999171053, 2.9642999998031883], "tokens_processed": [8, 8], "throughput_tok_s": [351.11897228509383, 364.0914780035582], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2131999996636296, 2.9324999995878898, 2.9785999995510792], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 14.272, "gpu_power_peak_watts": 14.272, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1790.61328125, "cpu_memory_peak_mb": 1790.61328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658274.097495}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.807300001659314, 22.364100001141196], "ttft_ms": [2.951599999505561, 2.4171999993995996], "tokens_processed": [8, 8], "throughput_tok_s": [350.76488665549937, 357.71616115076284], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.544799999872339, 2.6569000001472887, 2.805899999657413], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 21.807, "gpu_power_peak_watts": 21.807, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1790.62890625, "cpu_memory_peak_mb": 1790.62890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658274.2235913}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.420699999202043, 22.24980000028154], "ttft_ms": [3.055099999983213, 2.666099999260041], "tokens_processed": [8, 8], "throughput_tok_s": [356.8131235993846, 359.5537937374166], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S.S.S.S.", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.412600000956445, 2.3649999984627357, 2.9662999986612704], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 21.807, "gpu_power_peak_watts": 21.807, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1790.62890625, "cpu_memory_peak_mb": 1790.62890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658274.349074}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [33.41059999911522, 31.263099999705446], "ttft_ms": [4.066899999088491, 4.04290000005858], "tokens_processed": [32, 32], "throughput_tok_s": [957.7798662953501, 1023.5709190803694], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.505799999809824, 4.092200000741286, 4.100000000107684], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 21.807, "gpu_power_peak_watts": 21.807, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1798.578125, "cpu_memory_peak_mb": 1798.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658274.4749222}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.260199999451288, 31.666900000345777], "ttft_ms": [4.124899998714682, 4.356499999630614], "tokens_processed": [32, 32], "throughput_tok_s": [1023.6658754762188, 1010.5188698499248], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.225000000587897, 4.192399999737972, 4.242399998474866], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 21.807, "gpu_power_peak_watts": 21.807, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1814.1875, "cpu_memory_peak_mb": 1814.1875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658274.5945294}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [41.94960000131687, 32.40589999950316], "ttft_ms": [8.187100000213832, 4.384300000310759], "tokens_processed": [32, 32], "throughput_tok_s": [762.8201460561118, 987.4745031148839], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.952799998951377, 7.157800000641146, 7.880300001488649], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 22.759, "gpu_power_peak_watts": 22.759, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1814.19140625, "cpu_memory_peak_mb": 1814.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658274.7178512}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.463199999256176, 32.60909999880823], "ttft_ms": [3.8782000010542106, 4.134500000873231], "tokens_processed": [32, 32], "throughput_tok_s": [985.7315360387519, 981.3211649867524], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.458000001250184, 4.391899999973248, 3.0157000001054257], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 22.759, "gpu_power_peak_watts": 22.759, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1814.19140625, "cpu_memory_peak_mb": 1814.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658274.8413763}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.175599999187398, 33.68170000067039], "ttft_ms": [4.1935000008379575, 4.394999999931315], "tokens_processed": [32, 32], "throughput_tok_s": [1026.4437573241282, 950.0708099461453], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.S.S.S.S.", "List two ways to improve throughput on local LLMs.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.6518999988620635, 4.349099999672035, 4.202499998427811], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 22.759, "gpu_power_peak_watts": 22.759, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1814.19140625, "cpu_memory_peak_mb": 1814.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658274.9661145}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [41.3408000003983, 37.75329999916721], "ttft_ms": [3.70660000044154, 3.7867999999434687], "tokens_processed": [32, 32], "throughput_tok_s": [774.0537193206636, 847.6080236881512], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.016200000885874, 5.5126999995991355, 5.119199999171542], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 22.759, "gpu_power_peak_watts": 22.759, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1820.31640625, "cpu_memory_peak_mb": 1820.31640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658275.0910728}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [37.64960000080464, 37.87030000057712], "ttft_ms": [3.429300000789226, 3.5352999984752387], "tokens_processed": [32, 32], "throughput_tok_s": [849.9426288543863, 844.9893451995981], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.3972000005160226, 5.144299999301438, 5.438500000309432], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 22.74, "gpu_power_peak_watts": 22.74, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1843.0625, "cpu_memory_peak_mb": 1843.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658275.215397}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [37.10330000103568, 39.11370000059833], "ttft_ms": [3.6240000008547213, 4.630600000382401], "tokens_processed": [32, 32], "throughput_tok_s": [862.456978196192, 818.1276636961088], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.0152000003436115, 4.834099998333841, 5.469900001116912], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 22.74, "gpu_power_peak_watts": 22.74, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1843.0625, "cpu_memory_peak_mb": 1843.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658275.337513}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [40.19200000038836, 37.9464999987249], "ttft_ms": [4.862199999479344, 5.242699999143952], "tokens_processed": [32, 32], "throughput_tok_s": [796.1783439413514, 843.292530301221], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.0197999993979465, 5.458699999508099, 3.6387999989528907], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 22.74, "gpu_power_peak_watts": 22.74, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1843.0703125, "cpu_memory_peak_mb": 1843.0703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658275.4652257}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [38.446600001407205, 41.0916000000725], "ttft_ms": [4.249499999787076, 5.603100000371342], "tokens_processed": [32, 32], "throughput_tok_s": [832.323274329297, 778.747967953147], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S.S.S.S.", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S.S.S.S."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.424999999784632, 5.428099999335245, 5.106200000227545], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1216.01953125, "gpu_memory_peak_mb": 1216.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 22.74, "gpu_power_peak_watts": 22.74, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1843.0703125, "cpu_memory_peak_mb": 1843.0703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 906.9231000012223, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx"}, "started_at": 1765658275.603319}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.183600000033039, 0.9071999993466306, 1.1773999995057238], "resource_metrics": {"samples": 3, "duration_s": 0.21938872337341309, "gpu_memory_mean_mb": 1280.359375, "gpu_memory_peak_mb": 1401.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 22.982, "gpu_power_peak_watts": 22.982, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1963.97265625, "cpu_memory_peak_mb": 2100.08984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1765658275.9299574}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.097800001138239, 0.9081999996851664, 1.2289999995118706], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1703.0390625, "gpu_memory_peak_mb": 1703.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 22.982, "gpu_power_peak_watts": 22.982, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2031.80859375, "cpu_memory_peak_mb": 2031.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658276.0552523}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.1488000000099419, 1.1914000006072456, 0.9030999990500277], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1703.0390625, "gpu_memory_peak_mb": 1703.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 24.344, "gpu_power_peak_watts": 24.344, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2031.88671875, "cpu_memory_peak_mb": 2031.88671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658276.1790037}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.391699999658158, 0.8754999998927815, 1.1472999995021382], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1703.0390625, "gpu_memory_peak_mb": 1703.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 24.344, "gpu_power_peak_watts": 24.344, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2031.9296875, "cpu_memory_peak_mb": 2031.9296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658276.3041677}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.3104999998176936, 1.312599999437225, 0.9568999994371552], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1703.0390625, "gpu_memory_peak_mb": 1703.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 24.344, "gpu_power_peak_watts": 24.344, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2031.93359375, "cpu_memory_peak_mb": 2031.93359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658276.4259212}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.4147999993147096, 1.1422999996284489, 0.9307000000262633], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1703.0390625, "gpu_memory_peak_mb": 1703.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 24.344, "gpu_power_peak_watts": 24.344, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2032.52734375, "cpu_memory_peak_mb": 2032.52734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658276.5503943}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.9707999999809545, 2.1775000004709, 1.6636000000289641], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1703.0390625, "gpu_memory_peak_mb": 1703.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.733, "gpu_power_peak_watts": 29.733, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2032.5390625, "cpu_memory_peak_mb": 2032.5390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658276.6757352}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.3789999995642575, 2.178200000344077, 1.7941000005521346], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1703.0390625, "gpu_memory_peak_mb": 1703.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.733, "gpu_power_peak_watts": 29.733, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2032.546875, "cpu_memory_peak_mb": 2032.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658276.7967048}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.5554000001429813, 1.3486000007105758, 0.9722000013425713], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1703.0390625, "gpu_memory_peak_mb": 1703.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.733, "gpu_power_peak_watts": 29.733, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2032.58203125, "cpu_memory_peak_mb": 2032.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658276.9238753}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.8764999986160547, 1.4989000010245945, 1.283300000068266], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1703.0390625, "gpu_memory_peak_mb": 1703.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.733, "gpu_power_peak_watts": 29.733, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2032.58203125, "cpu_memory_peak_mb": 2032.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658277.0456762}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.02430000010645, 1.37660000109463, 1.783699999577948], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1705.0390625, "gpu_memory_peak_mb": 1705.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.742, "gpu_power_peak_watts": 29.742, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2034.12890625, "cpu_memory_peak_mb": 2034.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658277.171146}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.673099999810802, 1.538099999379483, 1.5597999990859535], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1705.0390625, "gpu_memory_peak_mb": 1705.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.742, "gpu_power_peak_watts": 29.742, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2034.13671875, "cpu_memory_peak_mb": 2034.13671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658277.2964828}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.7812999994930578, 1.692699999694014, 1.1801000000559725], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1705.0390625, "gpu_memory_peak_mb": 1705.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.742, "gpu_power_peak_watts": 29.742, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2034.1484375, "cpu_memory_peak_mb": 2034.1484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658277.420759}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.2308999996312195, 1.7726000005495735, 1.357099999950151], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1705.0390625, "gpu_memory_peak_mb": 1705.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.742, "gpu_power_peak_watts": 29.742, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2034.15625, "cpu_memory_peak_mb": 2034.15625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658277.5486853}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.1348999998735962, 1.7852000000857515, 1.3276999998197425], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1705.0390625, "gpu_memory_peak_mb": 1705.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.76, "gpu_power_peak_watts": 29.76, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2034.171875, "cpu_memory_peak_mb": 2034.171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658277.6711109}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.5282000008010073, 1.6071999998530373, 1.8710000003920868], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1707.0390625, "gpu_memory_peak_mb": 1707.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.76, "gpu_power_peak_watts": 29.76, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2035.7109375, "cpu_memory_peak_mb": 2035.7109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658277.7960703}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.748099999735132, 1.3758999994024634, 1.9529000001057284], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1707.0390625, "gpu_memory_peak_mb": 1707.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.76, "gpu_power_peak_watts": 29.76, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2035.7109375, "cpu_memory_peak_mb": 2035.7109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658277.9188495}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.242300000943942, 2.0215000004100148, 1.4217999996617436], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1707.0390625, "gpu_memory_peak_mb": 1707.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.76, "gpu_power_peak_watts": 29.76, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2035.7109375, "cpu_memory_peak_mb": 2035.7109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658278.0445404}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.7954999986832263, 2.007499999308493, 1.408899999660207], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1707.0390625, "gpu_memory_peak_mb": 1707.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.841, "gpu_power_peak_watts": 29.841, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2035.7109375, "cpu_memory_peak_mb": 2035.7109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658278.1665032}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.6902999998128507, 1.5260999989550328, 2.012299999478273], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1707.0390625, "gpu_memory_peak_mb": 1707.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.841, "gpu_power_peak_watts": 29.841, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2035.7109375, "cpu_memory_peak_mb": 2035.7109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658278.2919877}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.2414000005665, 3.157900000587688, 3.4515000006649643], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1699.0390625, "gpu_memory_peak_mb": 1699.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.841, "gpu_power_peak_watts": 29.841, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2032.18359375, "cpu_memory_peak_mb": 2032.18359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658278.4155452}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.058500000814092, 3.5315000004629837, 3.8366000007954426], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1715.0390625, "gpu_memory_peak_mb": 1715.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.841, "gpu_power_peak_watts": 29.841, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2050.05078125, "cpu_memory_peak_mb": 2050.05078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658278.542013}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.449100000987528, 3.3922000002348796, 3.838099999484257], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1715.0390625, "gpu_memory_peak_mb": 1715.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 29.989, "gpu_power_peak_watts": 29.989, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2050.0546875, "cpu_memory_peak_mb": 2050.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658278.6634965}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.944399999658344, 3.462099999524071, 2.0088999990548473], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1715.0390625, "gpu_memory_peak_mb": 1715.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 29.989, "gpu_power_peak_watts": 29.989, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2050.0546875, "cpu_memory_peak_mb": 2050.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658278.7885993}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.080499999166932, 6.559400000696769, 6.316900000456371], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1715.0390625, "gpu_memory_peak_mb": 1715.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 29.989, "gpu_power_peak_watts": 29.989, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2050.0546875, "cpu_memory_peak_mb": 2050.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658278.9112651}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.982299999639508, 8.496000000377535, 8.053199999267235], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1721.0390625, "gpu_memory_peak_mb": 1721.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 29.989, "gpu_power_peak_watts": 29.989, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2056.20703125, "cpu_memory_peak_mb": 2056.20703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658279.0373452}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.114199999909033, 7.677400000829948, 6.203799999639159], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1721.0390625, "gpu_memory_peak_mb": 1721.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.172, "gpu_power_peak_watts": 30.172, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2052.25, "cpu_memory_peak_mb": 2052.25, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658279.158461}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.5492999983689515, 4.484500001126435, 4.517300001680269], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1721.0390625, "gpu_memory_peak_mb": 1721.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.172, "gpu_power_peak_watts": 30.172, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2056.4765625, "cpu_memory_peak_mb": 2056.4765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658279.282497}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.868700000268291, 4.269299999577925, 7.044300000416115], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1721.0390625, "gpu_memory_peak_mb": 1721.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.172, "gpu_power_peak_watts": 30.172, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2056.4765625, "cpu_memory_peak_mb": 2056.4765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658279.4099226}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.491299998742761, 4.627000000255066, 2.5896999995893566], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1721.0390625, "gpu_memory_peak_mb": 1721.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.172, "gpu_power_peak_watts": 30.172, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2056.4765625, "cpu_memory_peak_mb": 2056.4765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 269.08300000104646, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658279.5331144}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [32.627500000671716, 1.2614999996003462, 0.9996999997383682], "resource_metrics": {"samples": 2, "duration_s": 0.12247753143310547, "gpu_memory_mean_mb": 1878.0390625, "gpu_memory_peak_mb": 2057.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.346, "gpu_power_peak_watts": 30.346, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2118.92578125, "cpu_memory_peak_mb": 2196.06640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765658279.7711885}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.6965000013442477, 0.8789000003162073, 0.7015999999566702], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2061.0390625, "gpu_memory_peak_mb": 2061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.346, "gpu_power_peak_watts": 30.346, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2146.95703125, "cpu_memory_peak_mb": 2146.95703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658279.9041028}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.1961000000155764, 1.8584999997983687, 0.961599998845486], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2061.0390625, "gpu_memory_peak_mb": 2061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.346, "gpu_power_peak_watts": 30.346, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2147.0703125, "cpu_memory_peak_mb": 2147.0703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658280.0284054}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.203800000643241, 1.4114000005065463, 1.4763999988645082], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2061.0390625, "gpu_memory_peak_mb": 2061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.27, "gpu_power_peak_watts": 30.27, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2147.0703125, "cpu_memory_peak_mb": 2147.0703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658280.1498318}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.179200000478886, 1.1084999987360789, 0.9107000005315058], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2061.0390625, "gpu_memory_peak_mb": 2061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.27, "gpu_power_peak_watts": 30.27, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2147.078125, "cpu_memory_peak_mb": 2147.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658280.2747338}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.9424000003928086, 1.9726999998965766, 1.2913000009575626], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2061.0390625, "gpu_memory_peak_mb": 2061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.27, "gpu_power_peak_watts": 30.27, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2147.69140625, "cpu_memory_peak_mb": 2147.69140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658280.4020908}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.628599999094149, 0.9809000002860557, 0.8270999987871619], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2061.0390625, "gpu_memory_peak_mb": 2061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.27, "gpu_power_peak_watts": 30.27, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2147.70703125, "cpu_memory_peak_mb": 2147.70703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658280.5258067}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.6668999996909406, 0.8717000000615371, 1.1357999992469558], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2061.0390625, "gpu_memory_peak_mb": 2061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.867, "gpu_power_peak_watts": 29.867, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2147.70703125, "cpu_memory_peak_mb": 2147.70703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658280.6494193}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.7788000004657079, 0.8907999999792082, 0.7621999993716599], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2061.0390625, "gpu_memory_peak_mb": 2061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.867, "gpu_power_peak_watts": 29.867, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2147.71484375, "cpu_memory_peak_mb": 2147.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658280.7765083}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.57919999967271, 1.0972000000037951, 0.754300001062802], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2061.0390625, "gpu_memory_peak_mb": 2061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.867, "gpu_power_peak_watts": 29.867, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2147.71484375, "cpu_memory_peak_mb": 2147.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658280.8967178}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.7478000010887627, 0.9929999996529659, 1.3740999984293012], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2063.0390625, "gpu_memory_peak_mb": 2063.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.867, "gpu_power_peak_watts": 29.867, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2149.2578125, "cpu_memory_peak_mb": 2149.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658281.0215836}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.1766999998362735, 1.0794000008900184, 1.2016999990009936], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2063.0390625, "gpu_memory_peak_mb": 2063.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.541, "gpu_power_peak_watts": 29.541, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2149.3359375, "cpu_memory_peak_mb": 2149.3359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658281.146604}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.120499999364256, 1.1310000008961651, 1.469599999836646], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2063.0390625, "gpu_memory_peak_mb": 2063.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.541, "gpu_power_peak_watts": 29.541, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2149.33984375, "cpu_memory_peak_mb": 2149.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658281.270947}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.4471000015182653, 1.3252000007923925, 1.3883999999961816], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2063.0390625, "gpu_memory_peak_mb": 2063.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.541, "gpu_power_peak_watts": 29.541, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2149.33984375, "cpu_memory_peak_mb": 2149.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658281.395979}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.7139999999926658, 1.4103000012255507, 0.9402999985468341], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2063.0390625, "gpu_memory_peak_mb": 2063.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 29.541, "gpu_power_peak_watts": 29.541, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2149.33984375, "cpu_memory_peak_mb": 2149.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658281.520819}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.4735999997792533, 2.345299999433337, 3.0584999985876493], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2065.0390625, "gpu_memory_peak_mb": 2065.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.556, "gpu_power_peak_watts": 29.556, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2150.87109375, "cpu_memory_peak_mb": 2150.87109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658281.645345}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.2700999998050975, 1.883199998701457, 1.3859000009688316], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2065.0390625, "gpu_memory_peak_mb": 2065.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.556, "gpu_power_peak_watts": 29.556, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2150.87109375, "cpu_memory_peak_mb": 2150.87109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658281.7703083}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8626999992411584, 2.3966000007931143, 3.370500000528409], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2065.0390625, "gpu_memory_peak_mb": 2065.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.556, "gpu_power_peak_watts": 29.556, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2150.87109375, "cpu_memory_peak_mb": 2150.87109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658281.894941}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.58880000001227, 1.1734999989130301, 1.765700000760262], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2065.0390625, "gpu_memory_peak_mb": 2065.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.556, "gpu_power_peak_watts": 29.556, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2150.87109375, "cpu_memory_peak_mb": 2150.87109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658282.0173354}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5802999989537057, 1.8909999998868443, 1.3588000001618639], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2065.0390625, "gpu_memory_peak_mb": 2065.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.605, "gpu_power_peak_watts": 29.605, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2150.87109375, "cpu_memory_peak_mb": 2150.87109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658282.1429782}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.872100000691717, 3.321700000014971, 3.5690999993676087], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2057.0390625, "gpu_memory_peak_mb": 2057.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.605, "gpu_power_peak_watts": 29.605, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2147.3203125, "cpu_memory_peak_mb": 2147.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658282.270352}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.245999998805928, 4.572199999529403, 7.728200000201468], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2073.0390625, "gpu_memory_peak_mb": 2073.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.605, "gpu_power_peak_watts": 29.605, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2164.85546875, "cpu_memory_peak_mb": 2164.85546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658282.3929949}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.133400000588153, 8.434699999270379, 8.392099998673075], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2073.0390625, "gpu_memory_peak_mb": 2073.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 29.605, "gpu_power_peak_watts": 29.605, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2164.875, "cpu_memory_peak_mb": 2164.875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658282.5174482}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.9902999987098156, 7.733600001301966, 7.785199999489123], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2073.0390625, "gpu_memory_peak_mb": 2073.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 22.0, "gpu_power_mean_watts": 27.281, "gpu_power_peak_watts": 27.281, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2164.8828125, "cpu_memory_peak_mb": 2164.8828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658282.6413596}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.231399999203859, 7.662199999685981, 7.584200000565033], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2073.0390625, "gpu_memory_peak_mb": 2073.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 22.0, "gpu_power_mean_watts": 27.281, "gpu_power_peak_watts": 27.281, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2164.8828125, "cpu_memory_peak_mb": 2164.8828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658282.7688072}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.441699998817057, 10.213900000962894, 10.139100000742474], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2079.0390625, "gpu_memory_peak_mb": 2079.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 22.0, "gpu_power_mean_watts": 27.281, "gpu_power_peak_watts": 27.281, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2164.3359375, "cpu_memory_peak_mb": 2164.3359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658282.8908656}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.621099998388672, 10.221200000160025, 10.24429999961285], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2079.0390625, "gpu_memory_peak_mb": 2079.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 22.0, "gpu_power_mean_watts": 27.281, "gpu_power_peak_watts": 27.281, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2164.83984375, "cpu_memory_peak_mb": 2164.83984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658283.014353}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.87339999867254, 10.216299999228795, 10.133699999641976], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2079.0390625, "gpu_memory_peak_mb": 2079.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 22.0, "gpu_power_mean_watts": 20.419, "gpu_power_peak_watts": 20.419, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2169.4453125, "cpu_memory_peak_mb": 2169.4453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658283.1386747}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.257899999487563, 10.342600000512903, 10.114600001543295], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2079.0390625, "gpu_memory_peak_mb": 2079.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 22.0, "gpu_power_mean_watts": 20.419, "gpu_power_peak_watts": 20.419, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2171.0234375, "cpu_memory_peak_mb": 2171.0234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658283.2640126}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.144199999966077, 11.502499999551219, 11.472399999547633], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2079.0390625, "gpu_memory_peak_mb": 2079.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 22.0, "gpu_power_mean_watts": 20.419, "gpu_power_peak_watts": 20.419, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2167.10546875, "cpu_memory_peak_mb": 2167.10546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 143.25730000018666, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658283.3892052}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.277999999336316, 2.721400000154972, 2.733700001044781], "resource_metrics": {"samples": 2, "duration_s": 0.11318206787109375, "gpu_memory_mean_mb": 2286.0390625, "gpu_memory_peak_mb": 2515.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 22.0, "gpu_power_mean_watts": 20.419, "gpu_power_peak_watts": 20.419, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2197.51171875, "cpu_memory_peak_mb": 2235.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1765658283.6153877}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.163400000630645, 2.953400000478723, 2.2723000001860783], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2519.0390625, "gpu_memory_peak_mb": 2519.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 31.0, "gpu_power_mean_watts": 14.127, "gpu_power_peak_watts": 14.127, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2163.21484375, "cpu_memory_peak_mb": 2163.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658283.7348003}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.066599998419406, 2.7318000011291588, 2.9881000009481795], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2519.0390625, "gpu_memory_peak_mb": 2519.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 31.0, "gpu_power_mean_watts": 14.127, "gpu_power_peak_watts": 14.127, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2163.22265625, "cpu_memory_peak_mb": 2163.22265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658283.8594196}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.504100001009647, 2.907299998696544, 5.741599999964819], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2519.0390625, "gpu_memory_peak_mb": 2519.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 31.0, "gpu_power_mean_watts": 14.127, "gpu_power_peak_watts": 14.127, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2163.2265625, "cpu_memory_peak_mb": 2163.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658283.9822216}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1976999998732936, 3.234100000554463, 2.9559000013250625], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2519.0390625, "gpu_memory_peak_mb": 2519.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 31.0, "gpu_power_mean_watts": 14.127, "gpu_power_peak_watts": 14.127, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2163.2265625, "cpu_memory_peak_mb": 2163.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658284.1070151}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.8139999996928964, 3.193900000042049, 6.323300000076415], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2519.0390625, "gpu_memory_peak_mb": 2519.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 31.0, "gpu_power_mean_watts": 12.285, "gpu_power_peak_watts": 12.285, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2163.80078125, "cpu_memory_peak_mb": 2163.80078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658284.229456}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.299899999954505, 8.481999999276013, 5.733100000725244], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2519.0390625, "gpu_memory_peak_mb": 2519.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 31.0, "gpu_power_mean_watts": 12.285, "gpu_power_peak_watts": 12.285, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2163.8046875, "cpu_memory_peak_mb": 2163.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658284.3547502}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.736099999921862, 6.6052000001946, 5.713599999580765], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2519.0390625, "gpu_memory_peak_mb": 2519.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 31.0, "gpu_power_mean_watts": 12.285, "gpu_power_peak_watts": 12.285, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2163.8046875, "cpu_memory_peak_mb": 2163.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658284.4802372}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.299200000081328, 7.372000000032131, 5.758100000093691], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2519.0390625, "gpu_memory_peak_mb": 2519.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 31.0, "gpu_power_mean_watts": 12.285, "gpu_power_peak_watts": 12.285, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2163.8046875, "cpu_memory_peak_mb": 2163.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658284.606916}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.722499999843421, 5.779200000688434, 5.86730000031821], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2519.0390625, "gpu_memory_peak_mb": 2519.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 8.458, "gpu_power_peak_watts": 8.458, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2163.8046875, "cpu_memory_peak_mb": 2163.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658284.7320664}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.4039000010088785, 8.959000000686501, 8.19969999975001], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2521.0390625, "gpu_memory_peak_mb": 2521.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 8.458, "gpu_power_peak_watts": 8.458, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2165.34765625, "cpu_memory_peak_mb": 2165.34765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658284.8747027}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.137200000215671, 8.788599998297286, 7.731400000920985], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2521.0390625, "gpu_memory_peak_mb": 2521.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 8.458, "gpu_power_peak_watts": 8.458, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2163.8359375, "cpu_memory_peak_mb": 2163.8359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658284.9953763}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.702300001052208, 8.685200000400073, 7.407499999317224], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2521.0390625, "gpu_memory_peak_mb": 2521.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 8.458, "gpu_power_peak_watts": 8.458, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2165.35546875, "cpu_memory_peak_mb": 2165.35546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658285.1201763}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.702699998641037, 9.38289999976405, 7.99639999968349], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2521.0390625, "gpu_memory_peak_mb": 2521.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 4.857, "gpu_power_peak_watts": 4.857, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2165.35546875, "cpu_memory_peak_mb": 2165.35546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658285.2463582}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.8554999998013955, 9.402599998793448, 7.857900000090012], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2521.0390625, "gpu_memory_peak_mb": 2521.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 4.857, "gpu_power_peak_watts": 4.857, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2165.35546875, "cpu_memory_peak_mb": 2165.35546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658285.3711503}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [9.848199999396456, 10.52210000125342, 10.185799999817391], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2523.0390625, "gpu_memory_peak_mb": 2523.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 4.857, "gpu_power_peak_watts": 4.857, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2166.88671875, "cpu_memory_peak_mb": 2166.88671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658285.5116549}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.809999999357387, 9.963700000298559, 11.149300000397488], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2523.0390625, "gpu_memory_peak_mb": 2523.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 2.773, "gpu_power_peak_watts": 2.773, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2164.484375, "cpu_memory_peak_mb": 2164.484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658285.6343243}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.717700000488549, 9.844099999099853, 11.304999999993015], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2523.0390625, "gpu_memory_peak_mb": 2523.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 2.773, "gpu_power_peak_watts": 2.773, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2166.890625, "cpu_memory_peak_mb": 2166.890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658285.7619348}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.357200000318699, 9.782500001165317, 10.380499999882886], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2523.0390625, "gpu_memory_peak_mb": 2523.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 2.773, "gpu_power_peak_watts": 2.773, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2165.24609375, "cpu_memory_peak_mb": 2165.24609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658285.8863144}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [9.006399999634596, 9.714599998915219, 10.311100000762963], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2523.0390625, "gpu_memory_peak_mb": 2523.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 2.773, "gpu_power_peak_watts": 2.773, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2166.8984375, "cpu_memory_peak_mb": 2166.8984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658286.0123112}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [18.485400001736707, 16.53199999964272, 16.495199999553734], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2515.0390625, "gpu_memory_peak_mb": 2515.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 2.936, "gpu_power_peak_watts": 2.936, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2163.6796875, "cpu_memory_peak_mb": 2163.6796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658286.147064}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.11400000001595, 16.474800000651157, 16.480400001455564], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2533.0390625, "gpu_memory_peak_mb": 2533.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 2.936, "gpu_power_peak_watts": 2.936, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2167.79296875, "cpu_memory_peak_mb": 2167.79296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658286.270961}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.241199999058153, 16.407999999501044, 16.415099998994265], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2533.0390625, "gpu_memory_peak_mb": 2533.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 2.936, "gpu_power_peak_watts": 2.936, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2169.7421875, "cpu_memory_peak_mb": 2169.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658286.3950565}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [15.677999999752501, 16.34870000088995, 16.402100000050268], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2533.0390625, "gpu_memory_peak_mb": 2533.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 2.936, "gpu_power_peak_watts": 2.936, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2172.76953125, "cpu_memory_peak_mb": 2172.76953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658286.5197008}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.476000000693602, 16.31710000037856, 16.289400000459864], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2533.0390625, "gpu_memory_peak_mb": 2533.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 3.31, "gpu_power_peak_watts": 3.31, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2173.42578125, "cpu_memory_peak_mb": 2173.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658286.6454146}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [22.134499999083346, 21.345499999370077, 21.280899998600944], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2539.0390625, "gpu_memory_peak_mb": 2539.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 3.31, "gpu_power_peak_watts": 3.31, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2166.78125, "cpu_memory_peak_mb": 2166.78125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658286.7751606}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [21.287499999743886, 21.401500000138185, 21.38839999861375], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2539.0390625, "gpu_memory_peak_mb": 2539.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 3.31, "gpu_power_peak_watts": 3.31, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2177.8125, "cpu_memory_peak_mb": 2177.8125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658286.909512}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [21.301500000845408, 20.92850000008184, 21.32319999873289], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2539.0390625, "gpu_memory_peak_mb": 2539.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 3.31, "gpu_power_peak_watts": 3.31, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2185.71484375, "cpu_memory_peak_mb": 2185.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658287.0486827}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [21.164899999348563, 21.44120000048133, 21.208699999988312], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2539.0390625, "gpu_memory_peak_mb": 2539.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 3.633, "gpu_power_peak_watts": 3.633, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2184.8046875, "cpu_memory_peak_mb": 2184.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658287.1844108}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "scripts/tr118/models/gpt2-1m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [21.072199999252916, 21.002900000894442, 21.05169999958889], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2539.0390625, "gpu_memory_peak_mb": 2539.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 46.0, "gpu_power_mean_watts": 3.633, "gpu_power_peak_watts": 3.633, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2169.125, "cpu_memory_peak_mb": 2169.125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "scripts/tr118/models/gpt2-1m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "export_time_s": 3.1396361000006436, "file_size_mb": 79.58442687988281, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "b6f09e4a9af8555931b14d6742673a29fcbafece18ef04355a78b538df956faf", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "exists": true, "onnx_file_size_bytes": 83450320, "onnx_file_size_mb": 79.58442687988281, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 83450320, "total_artifact_size_mb": 79.58442687988281, "initializer_count": 41, "initializer_numel": 20830272, "initializer_bytes_est": 83321088, "initializer_bytes_est_mb": 79.461181640625, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "scripts\\tr118\\models\\gpt2-1m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\scripts\\tr118\\models\\gpt2-1m\\model.safetensors", "name": "model.safetensors", "size_bytes": 44727592, "size_mb": 42.655555725097656}], "total_size_bytes": 44727592, "total_size_mb": 42.655555725097656}, "timestamp": 1765658009.5684667, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 51.47382329999891, "file_size_mb": 83.61310958862305, "engine_sha256": "ef67620caf5496603323a6e0e607d089c7675a867c3c4a16da3dfe895c4bd427", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp32.plan", "exists": true, "file_size_bytes": 87674700, "file_size_mb": 83.61310958862305, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658061.755181, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 62.81318300000021, "file_size_mb": 160.29001235961914, "engine_sha256": "8b417e6175e473151f3ef10c6a603edcd41d5303f6d41f077ed82fce68b64c1b", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_fp16.plan", "exists": true, "file_size_bytes": 168076260, "file_size_mb": 160.29001235961914, "deserialize_error": null, "num_layers": 232, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 31, "Int64": 66, "Float": 171}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658128.8048608, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\onnx\\gpt2-1m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 59.422635200000514, "file_size_mb": 84.8734245300293, "engine_sha256": "d6d93f95975ffb1e77fdf813622a2fa2de15f747861160ce91187be3bcafb72a", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "exists": true, "file_size_bytes": 88996236, "file_size_mb": 84.8734245300293, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\calib\\gpt2-1m_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 13208, "cache_sha256_after": "9d806e03c1d217b066f07a6232f85083363da5e795db50c8ec997f5917bc4758"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765658193.1537511, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 112.2918999990361, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2-1m\\tensorrt\\gpt2-1m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765658287.3089054}
