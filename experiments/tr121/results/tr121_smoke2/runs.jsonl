{"scenario": "micro", "backend": "hf_cpu_fp32", "backend_kind": "hf", "model": "models/gpt2-5m", "model_kind": "hf", "params_millions": 5.0, "prompt": "Hello", "gen_tokens_target": 16, "rep": 0, "mode": "prefill", "status": "ok", "error": "", "started_at_unix": 1766455928.7197065, "prompt_tokens": 1, "gen_tokens": 0, "prefill_ms": 32.44100000006256, "prefill_cuda_event_ms": null, "kv_decode_ms": 379.4093999999859, "kv_decode_cuda_event_ms": null, "gpu_peak_mb": null, "latency_ms": 32.44100000006256, "cuda_event_ms": null, "tokens_total": 1, "tokens_per_s": 30.82519034549094}
{"scenario": "micro", "backend": "hf_cpu_fp32", "backend_kind": "hf", "model": "models/gpt2-5m", "model_kind": "hf", "params_millions": 5.0, "prompt": "Hello", "gen_tokens_target": 16, "rep": 0, "mode": "kv_decode", "status": "ok", "error": "", "started_at_unix": 1766455928.7197065, "prompt_tokens": 1, "gen_tokens": 16, "prefill_ms": 32.44100000006256, "prefill_cuda_event_ms": null, "kv_decode_ms": 379.4093999999859, "kv_decode_cuda_event_ms": null, "gpu_peak_mb": null, "latency_ms": 379.4093999999859, "cuda_event_ms": null, "tokens_total": 16, "tokens_per_s": 42.17080546765735}
{"scenario": "micro", "backend": "hf_cpu_fp32", "backend_kind": "hf", "model": "models/gpt2-5m", "model_kind": "hf", "params_millions": 5.0, "prompt": "Hello", "gen_tokens_target": 16, "rep": 0, "mode": "e2e_kv", "status": "ok", "error": "", "started_at_unix": 1766455928.7197065, "prompt_tokens": 1, "gen_tokens": 16, "prefill_ms": 32.44100000006256, "prefill_cuda_event_ms": null, "kv_decode_ms": 379.4093999999859, "kv_decode_cuda_event_ms": null, "gpu_peak_mb": null, "latency_ms": 411.85040000004847, "cuda_event_ms": null, "tokens_total": 17, "tokens_per_s": 41.27712392654711}
{"scenario": "micro", "backend": "hf_gpu_fp16", "backend_kind": "hf", "model": "models/gpt2-5m", "model_kind": "hf", "params_millions": 5.0, "prompt": "Hello", "gen_tokens_target": 16, "rep": 0, "mode": "prefill", "status": "ok", "error": "", "started_at_unix": 1766455935.3143432, "prompt_tokens": 1, "gen_tokens": 0, "prefill_ms": 364.363400000002, "prefill_cuda_event_ms": 337.0731506347656, "kv_decode_ms": 214.69509999997172, "kv_decode_cuda_event_ms": 214.58023071289062, "gpu_peak_mb": 31.03662109375, "latency_ms": 364.363400000002, "cuda_event_ms": 337.0731506347656, "tokens_total": 1, "tokens_per_s": 2.744512758416445}
{"scenario": "micro", "backend": "hf_gpu_fp16", "backend_kind": "hf", "model": "models/gpt2-5m", "model_kind": "hf", "params_millions": 5.0, "prompt": "Hello", "gen_tokens_target": 16, "rep": 0, "mode": "kv_decode", "status": "ok", "error": "", "started_at_unix": 1766455935.3143432, "prompt_tokens": 1, "gen_tokens": 16, "prefill_ms": 364.363400000002, "prefill_cuda_event_ms": 337.0731506347656, "kv_decode_ms": 214.69509999997172, "kv_decode_cuda_event_ms": 214.58023071289062, "gpu_peak_mb": 31.03662109375, "latency_ms": 214.69509999997172, "cuda_event_ms": 214.58023071289062, "tokens_total": 16, "tokens_per_s": 74.52429049383106}
{"scenario": "micro", "backend": "hf_gpu_fp16", "backend_kind": "hf", "model": "models/gpt2-5m", "model_kind": "hf", "params_millions": 5.0, "prompt": "Hello", "gen_tokens_target": 16, "rep": 0, "mode": "e2e_kv", "status": "ok", "error": "", "started_at_unix": 1766455935.3143432, "prompt_tokens": 1, "gen_tokens": 16, "prefill_ms": 364.363400000002, "prefill_cuda_event_ms": 337.0731506347656, "kv_decode_ms": 214.69509999997172, "kv_decode_cuda_event_ms": 214.58023071289062, "gpu_peak_mb": 31.03662109375, "latency_ms": 579.0584999999737, "cuda_event_ms": 551.6533813476562, "tokens_total": 17, "tokens_per_s": 29.3580009619076}
{"scenario": "micro", "backend": "ollama", "backend_kind": "ollama", "model": "gemma3:270m", "model_kind": "ollama", "params_millions": 270.0, "prompt": "Hello", "gen_tokens_target": 16, "rep": 0, "mode": "prefill", "status": "ok", "error": "", "started_at_unix": 1766455936.284639, "prompt_tokens": 10, "prefill_ms": 9.5497, "prefill_cuda_event_ms": null, "kv_decode_ms": 81.632, "kv_decode_cuda_event_ms": null, "gen_tokens": 0, "ollama_wall_ms": 257.85769999993136, "ollama_total_duration_ms": 221.5186, "ollama_load_ms": 116.0348, "ollama_done_reason": "stop", "latency_ms": 9.5497, "cuda_event_ms": null, "tokens_total": 10, "tokens_per_s": 1047.1533137166614}
{"scenario": "micro", "backend": "ollama", "backend_kind": "ollama", "model": "gemma3:270m", "model_kind": "ollama", "params_millions": 270.0, "prompt": "Hello", "gen_tokens_target": 16, "rep": 0, "mode": "kv_decode", "status": "ok", "error": "", "started_at_unix": 1766455936.284639, "prompt_tokens": 10, "prefill_ms": 9.5497, "prefill_cuda_event_ms": null, "kv_decode_ms": 81.632, "kv_decode_cuda_event_ms": null, "gen_tokens": 11, "ollama_wall_ms": 257.85769999993136, "ollama_total_duration_ms": 221.5186, "ollama_load_ms": 116.0348, "ollama_done_reason": "stop", "latency_ms": 81.632, "cuda_event_ms": null, "tokens_total": 11, "tokens_per_s": 134.75107800862406}
{"scenario": "micro", "backend": "ollama", "backend_kind": "ollama", "model": "gemma3:270m", "model_kind": "ollama", "params_millions": 270.0, "prompt": "Hello", "gen_tokens_target": 16, "rep": 0, "mode": "e2e_kv", "status": "ok", "error": "", "started_at_unix": 1766455936.284639, "prompt_tokens": 10, "prefill_ms": 9.5497, "prefill_cuda_event_ms": null, "kv_decode_ms": 81.632, "kv_decode_cuda_event_ms": null, "gen_tokens": 11, "ollama_wall_ms": 257.85769999993136, "ollama_total_duration_ms": 221.5186, "ollama_load_ms": 116.0348, "ollama_done_reason": "stop", "latency_ms": 91.1817, "cuda_event_ms": null, "tokens_total": 21, "tokens_per_s": 230.30937128831772}
