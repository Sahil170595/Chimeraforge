{
  "collector": {
    "config": {
      "base_url": "http://localhost:11434",
      "id": "chimera_a",
      "label": "Chimera Agent A",
      "model": "gemma3:latest",
      "options": {
        "num_ctx": 512,
        "num_gpu": 80,
        "temperature": 1.0
      },
      "prompt": "You are DataCollector-9000, a systems analyst tasked with scanning benchmark artifacts.\nProduce a concise data inventory with bullet points that highlight:\n1. Directory coverage (reports/, csv_data/, artifacts/).\n2. File counts per type (md, csv, json) and the latest modified timestamp you observe.\n3. Any gaps or missing telemetry that could impact model evaluation.\nKeep the response under 250 words but include concrete metrics so a second agent can reason over them."
    },
    "execution_time_s": 5.28314,
    "result": {
      "agent_type": "Chimera Agent A",
      "aggregate_metrics": {
        "average_tokens_per_second": 92.05626742082669,
        "average_ttft_ms": 783.1856,
        "eval_duration_ms": 4258.2652,
        "load_duration_ms": 436.0649,
        "prompt_eval_duration_ms": 34.3998,
        "stddev_throughput": 0.0,
        "stddev_ttft": 0.0,
        "total_duration_ms": 5283.14,
        "total_tokens_generated": 392
      },
      "configuration": {
        "num_ctx": 512,
        "num_gpu": 80,
        "temperature": 1.0
      },
      "individual_runs": [
        {
          "eval_duration_ms": 4258.2652,
          "load_duration_ms": 436.0649,
          "prompt_eval_duration_ms": 34.3998,
          "throughput_tokens_per_sec": 92.05626742082669,
          "tokens_generated": 392,
          "total_duration_ms": 5283.14,
          "ttft_ms": 783.1856
        }
      ],
      "model": "gemma3:latest",
      "prompt": "You are DataCollector-9000, a systems analyst tasked with scanning benchmark artifacts.\nProduce a concise data inventory with bullet points that highlight:\n1. Directory coverage (reports/, csv_data/, artifacts/).\n2. File counts per type (md, csv, json) and the latest modified timestamp you observe.\n3. Any gaps or missing telemetry that could impact model evaluation.\nKeep the response under 250 words but include concrete metrics so a second agent can reason over them.",
      "runs": 1,
      "system_info": {
        "arch": "x86_64",
        "hostname": "SahilKadadekar",
        "os": "windows",
        "rust_version": "1.90.0"
      },
      "timestamp": "2025-11-14T00:24:39.778169300Z"
    }
  },
  "insight": {
    "config": {
      "base_url": "http://localhost:11435",
      "id": "chimera_b",
      "label": "Chimera Agent B",
      "model": "gemma3:latest",
      "options": {
        "num_ctx": 512,
        "num_gpu": 80,
        "temperature": 1.0
      },
      "prompt": "You are InsightAgent, a Chimera-optimised LLM operations specialist.\nGiven the repository context described previously, produce:\n1. Executive summary of model performance.\n2. Three optimisation recommendations that balance throughput, TTFT, and quality.\n3. A risk/mitigation table with at least two rows.\nAim for 300-400 words, with numbered sections and bolded metric callouts."
    },
    "execution_time_s": 2.1039149,
    "result": {
      "agent_type": "Chimera Agent B",
      "aggregate_metrics": {
        "average_tokens_per_second": 48.370584291421416,
        "average_ttft_ms": 623.3172000000001,
        "eval_duration_ms": 1426.4868,
        "load_duration_ms": 297.807,
        "prompt_eval_duration_ms": 12.8109,
        "stddev_throughput": 0.0,
        "stddev_ttft": 0.0,
        "total_duration_ms": 2103.9148999999998,
        "total_tokens_generated": 69
      },
      "configuration": {
        "num_ctx": 512,
        "num_gpu": 80,
        "temperature": 1.0
      },
      "individual_runs": [
        {
          "eval_duration_ms": 1426.4868,
          "load_duration_ms": 297.807,
          "prompt_eval_duration_ms": 12.8109,
          "throughput_tokens_per_sec": 48.370584291421416,
          "tokens_generated": 69,
          "total_duration_ms": 2103.9148999999998,
          "ttft_ms": 623.3172000000001
        }
      ],
      "model": "gemma3:latest",
      "prompt": "You are InsightAgent, a Chimera-optimised LLM operations specialist.\nGiven the repository context described previously, produce:\n1. Executive summary of model performance.\n2. Three optimisation recommendations that balance throughput, TTFT, and quality.\n3. A risk/mitigation table with at least two rows.\nAim for 300-400 words, with numbered sections and bolded metric callouts.",
      "runs": 1,
      "system_info": {
        "arch": "x86_64",
        "hostname": "SahilKadadekar",
        "os": "windows",
        "rust_version": "1.90.0"
      },
      "timestamp": "2025-11-14T00:24:36.599118500Z"
    }
  },
  "run_number": 1,
  "scenario": "chimera_homo",
  "summary": {
    "collector_throughput": 92.05626742082669,
    "collector_ttft_ms": 783.1856,
    "concurrency_speedup": 1.398209566869808,
    "concurrent_wall_time_s": 5.2832244,
    "efficiency_percent": 69.9104783434904,
    "insight_throughput": 48.370584291421416,
    "insight_ttft_ms": 623.3172000000001,
    "resource_contention_detected": true,
    "run_number": 1,
    "scenario": "chimera_homo",
    "sequential_estimated_s": 7.387054900000001,
    "throughput_delta": -43.68568312940527,
    "ttft_delta_ms": 159.86839999999995
  }
}