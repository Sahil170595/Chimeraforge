{
  "path": "scripts/tr120/results/tr120_root_cause_triton/20251221_191009/prefill/runs/single_long/transformers-gpu-compile/fp32/run_1766344244882.json",
  "spec": {
    "mode": "prefill",
    "scenario": "single_long",
    "prompt_set": "long",
    "prompts": [
      "Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.",
      "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles."
    ],
    "backend": "transformers-gpu-compile",
    "model": "models/tiny-gpt2",
    "quantization": "fp32"
  },
  "status": "ok",
  "error": null,
  "latencies_ms": [
    0.3299999998489511,
    0.3607139997257036,
    0.26986700049747014,
    0.2569999996921979,
    0.3231410000807955,
    0.21740700049122097,
    0.220704000639671,
    0.21298199953889707,
    0.23587900068378076,
    0.2120850003848318,
    0.2091209998980048,
    0.20188500002404908,
    0.2185909997933777,
    0.22895799975231057,
    0.21592200027953368,
    0.22530299975187518,
    0.215672999729577,
    0.21312799981387798,
    0.2045439996436471,
    0.19817700012936257,
    0.21993300015310524,
    0.20256500010873424,
    0.20791799943253864,
    0.20276600025681546,
    0.19792300008703023,
    0.2010669995797798,
    0.20625700017262716,
    0.22452400025940733,
    0.20376499924168456,
    0.20048999977007043,
    0.20345499979157466,
    0.20809600027860142,
    0.202698000066448,
    0.20435399983398383,
    0.2515719997973065,
    0.2686950001589139,
    0.20926000070176087,
    0.20174200017208932,
    0.19852900004480034,
    0.20744999983435264,
    0.2037009999185102,
    0.1993590003621648,
    0.23530700036644703,
    0.23075899935065536,
    0.230923999879451,
    0.20508800025709206,
    0.21644400021614274,
    0.20802899962291121,
    0.23411599977407604,
    0.23492899981647497,
    0.20936700002494035,
    0.2016769994952483,
    0.20027200025651837,
    0.20500099981290987,
    0.2041930001723813,
    0.19888399947376456,
    0.19981599962193286,
    0.22212499970919453,
    0.23074899945640936,
    0.23517199952038936
  ],
  "cuda_event_ms": [
    0.19968000054359436,
    0.23472000658512115,
    0.21462400257587433,
    0.2022400051355362,
    0.26713600754737854,
    0.16995200514793396,
    0.16924799978733063,
    0.1656000018119812,
    0.1754560023546219,
    0.16636799275875092,
    0.16335999965667725,
    0.1563200056552887,
    0.16147199273109436,
    0.17961600422859192,
    0.16735999286174774,
    0.16038399934768677,
    0.16988800466060638,
    0.16422399878501892,
    0.15750400722026825,
    0.1518079936504364,
    0.1701440066099167,
    0.15561600029468536,
    0.16044799983501434,
    0.15680000185966492,
    0.15324799716472626,
    0.15622399747371674,
    0.16060799360275269,
    0.17577600479125977,
    0.15667200088500977,
    0.15756799280643463,
    0.15769599378108978,
    0.1621440052986145,
    0.1582079976797104,
    0.1600639969110489,
    0.20070399343967438,
    0.21462400257587433,
    0.16313600540161133,
    0.15782399475574493,
    0.15404799580574036,
    0.15961599349975586,
    0.15772800147533417,
    0.15318399667739868,
    0.18585599958896637,
    0.18051199615001678,
    0.18134400248527527,
    0.15731200575828552,
    0.16364799439907074,
    0.16275200247764587,
    0.1690559983253479,
    0.18806399405002594,
    0.16326400637626648,
    0.15721599757671356,
    0.15590399503707886,
    0.16019199788570404,
    0.15904000401496887,
    0.15503999590873718,
    0.15513600409030914,
    0.1746560037136078,
    0.17078399658203125,
    0.1761920005083084
  ],
  "ttft_ms": [
    0.3299999998489511,
    0.3607139997257036,
    0.26986700049747014,
    0.2569999996921979,
    0.3231410000807955,
    0.21740700049122097,
    0.220704000639671,
    0.21298199953889707,
    0.23587900068378076,
    0.2120850003848318,
    0.2091209998980048,
    0.20188500002404908,
    0.2185909997933777,
    0.22895799975231057,
    0.21592200027953368,
    0.22530299975187518,
    0.215672999729577,
    0.21312799981387798,
    0.2045439996436471,
    0.19817700012936257,
    0.21993300015310524,
    0.20256500010873424,
    0.20791799943253864,
    0.20276600025681546,
    0.19792300008703023,
    0.2010669995797798,
    0.20625700017262716,
    0.22452400025940733,
    0.20376499924168456,
    0.20048999977007043,
    0.20345499979157466,
    0.20809600027860142,
    0.202698000066448,
    0.20435399983398383,
    0.2515719997973065,
    0.2686950001589139,
    0.20926000070176087,
    0.20174200017208932,
    0.19852900004480034,
    0.20744999983435264,
    0.2037009999185102,
    0.1993590003621648,
    0.23530700036644703,
    0.23075899935065536,
    0.230923999879451,
    0.20508800025709206,
    0.21644400021614274,
    0.20802899962291121,
    0.23411599977407604,
    0.23492899981647497,
    0.20936700002494035,
    0.2016769994952483,
    0.20027200025651837,
    0.20500099981290987,
    0.2041930001723813,
    0.19888399947376456,
    0.19981599962193286,
    0.22212499970919453,
    0.23074899945640936,
    0.23517199952038936
  ],
  "tokens": [
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25,
    27,
    25
  ],
  "tokens_per_s": [
    81818.18185563195,
    69306.9856423944,
    100049.28335153416,
    97276.2647079449,
    83554.85683726035,
    114991.69733961494,
    122335.79781855036,
    117380.8117781063,
    114465.4671324311,
    117877.26597655223,
    129111.85396573652,
    123832.87513694397,
    123518.35174147904,
    109190.33196937993,
    125045.15503304743,
    110961.6828339274,
    125189.52318488697,
    117300.40173901217,
    132000.93890331135,
    126149.8558545186,
    122764.66006103717,
    123417.17466778727,
    129858.88703089632,
    123294.83231082125,
    136416.6872376006,
    124336.66415796116,
    130904.64797511019,
    111346.67105127228,
    132505.58290423296,
    124694.49862173152,
    132707.47844810697,
    120136.85974996972,
    133203.0902680289,
    122336.72950032724,
    107325.13960915408,
    93042.29697320116,
    129026.09151034377,
    123920.65102296289,
    136000.28204396908,
    120510.96659417848,
    132547.21386149919,
    125401.91290377581,
    114743.7176027594,
    108338.13662890196,
    116921.58465163768,
    121898.89203005911,
    124743.58251112334,
    120175.55266485372,
    115327.444625977,
    106415.12976060784,
    128960.15129788213,
    123960.59075932961,
    134816.64918419477,
    121950.6247423952,
    132227.84315430204,
    125701.41422210203,
    135124.3146248852,
    112549.24043997719,
    117010.25817492462,
    106305.17260126669
  ],
  "started_at": 1766344244.8635635,
  "degraded_count": 0,
  "degraded_reasons": [],
  "compile": {
    "enabled": true,
    "backend": "inductor",
    "mode": "reduce-overhead",
    "dynamic": false,
    "fullgraph": false,
    "disable_cudagraphs": false,
    "compile_wrapper_ms": 6940.886827999748,
    "dynamo_counters_after_compile": {
      "frames": {
        "total": 1,
        "ok": 1
      },
      "inline_call": {},
      "stats": {
        "calls_captured": 110,
        "unique_graphs": 1
      },
      "inductor": {
        "pattern_matcher_count": 54,
        "pattern_matcher_nodes": 63,
        "benchmarking.InductorBenchmarker.benchmark_gpu": 12,
        "fxgraph_cache_miss": 1,
        "async_compile_cache_miss": 30,
        "extern_calls": 13,
        "async_compile_cache_hit": 15,
        "triton_bundler_save_kernel": 112
      },
      "aot_autograd": {
        "total": 1,
        "autograd_cache_miss": 1,
        "autograd_cache_saved": 1,
        "ok": 1
      },
      "graph_break": {},
      "aten_mm_info": {
        "aten.addmm_8_6_2": 2,
        "aten.bmm_8_8_1": 2,
        "aten.bmm_8_1_8": 2,
        "aten.mm_8_2_2": 2,
        "aten.mm_8_8_2": 2,
        "aten.mm_8_2_8": 2,
        "aten.mm_8_50257_2": 1
      }
    }
  }
}