{
  "path": "scripts/tr120/results/tr120_root_cause_triton/20251221_181901/e2e_kv/runs/single_medium/transformers-gpu-compile/fp32/run_1766341268300.json",
  "spec": {
    "mode": "e2e_kv",
    "scenario": "single_medium",
    "prompt_set": "medium",
    "prompts": [
      "Explain how backpressure works in an inference service and when to enable queueing.",
      "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences."
    ],
    "backend": "transformers-gpu-compile",
    "model": "models/tiny-gpt2",
    "quantization": "fp32"
  },
  "status": "ok",
  "error": null,
  "latencies_ms": [
    105.64702000010584,
    108.5986570001296,
    103.08024199957799,
    107.86845300026471,
    106.67980000016541,
    119.97291800025778,
    111.66938199994547,
    107.55318200017427,
    111.69811899981141,
    103.14863799976592,
    102.83484099954876,
    115.52361599979122,
    116.04545199998029,
    115.53541499961284,
    118.43569100028617,
    113.24970299983761,
    113.76461899953938,
    104.04105200041158,
    104.78844599992954,
    100.75167200011492,
    105.00236799998675,
    100.46487200042975,
    102.61885099998835,
    101.85190000038347,
    98.69011499995395,
    103.94079700017755,
    99.22891500036712,
    103.32519899975523,
    103.94128099960653,
    104.1769899998144,
    101.2895430003482,
    102.91828400022496,
    98.23600099980467,
    100.76316499998939,
    105.51593699983641,
    102.57404200001474,
    100.58520099937596,
    99.57182899961481,
    100.16042099960032,
    98.00520499993581,
    102.65762400013045,
    101.12264100007451,
    101.64131999999881,
    99.84606300031373,
    101.42878999977256,
    103.5223660005613,
    104.4499210001959,
    100.24340200016013,
    99.74157699980424,
    103.6362130002999,
    100.78653599975951,
    103.51915700039171,
    102.67273400040722,
    125.49962200000664,
    101.08155000034458,
    101.73672700011593,
    106.0237279998546,
    108.3690840005147,
    99.18100300001242,
    99.596785999438
  ],
  "ttft_ms": [
    105.64702000010584,
    108.5986570001296,
    103.08024199957799,
    107.86845300026471,
    106.67980000016541,
    119.97291800025778,
    111.66938199994547,
    107.55318200017427,
    111.69811899981141,
    103.14863799976592,
    102.83484099954876,
    115.52361599979122,
    116.04545199998029,
    115.53541499961284,
    118.43569100028617,
    113.24970299983761,
    113.76461899953938,
    104.04105200041158,
    104.78844599992954,
    100.75167200011492,
    105.00236799998675,
    100.46487200042975,
    102.61885099998835,
    101.85190000038347,
    98.69011499995395,
    103.94079700017755,
    99.22891500036712,
    103.32519899975523,
    103.94128099960653,
    104.1769899998144,
    101.2895430003482,
    102.91828400022496,
    98.23600099980467,
    100.76316499998939,
    105.51593699983641,
    102.57404200001474,
    100.58520099937596,
    99.57182899961481,
    100.16042099960032,
    98.00520499993581,
    102.65762400013045,
    101.12264100007451,
    101.64131999999881,
    99.84606300031373,
    101.42878999977256,
    103.5223660005613,
    104.4499210001959,
    100.24340200016013,
    99.74157699980424,
    103.6362130002999,
    100.78653599975951,
    103.51915700039171,
    102.67273400040722,
    125.49962200000664,
    101.08155000034458,
    101.73672700011593,
    106.0237279998546,
    108.3690840005147,
    99.18100300001242,
    99.596785999438
  ],
  "tokens": [
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83
  ],
  "tokens_per_s": [
    766.7040679417067,
    764.28201133188,
    785.795594080305,
    769.4557369780423,
    759.2815134624775,
    691.8227995406569,
    725.3554962813312,
    771.7112451388515,
    725.1688813142571,
    804.6640421969348,
    787.670785627562,
    718.4678152746708,
    698.0023654870487,
    718.3944420875464,
    683.9154592326757,
    732.893754256636,
    711.9964072514316,
    797.7620218572151,
    772.985983588825,
    823.8076684216746,
    771.4111742699957,
    826.1594161951947,
    789.3286585328186,
    814.9087056764529,
    820.750892832963,
    798.5314948071663,
    816.29432307811,
    803.2890408485603,
    779.2861433014917,
    796.7210417592971,
    799.6876834533803,
    806.4650592096792,
    824.5449649376612,
    823.7137053010268,
    767.6565484143459,
    809.1715835863041,
    805.287449795945,
    833.5691011593358,
    808.702671091241,
    846.8937950801119,
    789.0305351300267,
    820.7855251717451,
    796.9199927746014,
    831.2796469475136,
    798.5898283927239,
    801.759109713064,
    775.4912519258687,
    827.9846687552306,
    812.0986496950914,
    800.8783570638558,
    803.6787770957152,
    801.7839635197756,
    788.9144161650428,
    661.356573647653,
    801.3331809783673,
    815.8312386037878,
    763.9799272113039,
    765.9010940759247,
    816.6886555885087,
    833.3602251027293
  ],
  "started_at": 1766341261.99923,
  "degraded_count": 0,
  "degraded_reasons": [],
  "compile": {
    "enabled": true,
    "backend": "inductor",
    "mode": "reduce-overhead",
    "dynamic": false,
    "fullgraph": false,
    "disable_cudagraphs": true,
    "compile_wrapper_ms": 6221.791003999897,
    "dynamo_counters_after_compile": {
      "frames": {
        "total": 1,
        "ok": 1
      },
      "inline_call": {},
      "stats": {
        "calls_captured": 110,
        "unique_graphs": 1
      },
      "inductor": {
        "pattern_matcher_count": 54,
        "pattern_matcher_nodes": 63,
        "benchmarking.InductorBenchmarker.benchmark_gpu": 12,
        "fxgraph_cache_miss": 1,
        "async_compile_cache_miss": 30,
        "extern_calls": 13,
        "async_compile_cache_hit": 15,
        "triton_bundler_save_kernel": 112
      },
      "aot_autograd": {
        "total": 1,
        "autograd_cache_miss": 1,
        "autograd_cache_saved": 1,
        "ok": 1
      },
      "graph_break": {},
      "aten_mm_info": {
        "aten.addmm_8_6_2": 2,
        "aten.bmm_8_8_1": 2,
        "aten.bmm_8_1_8": 2,
        "aten.mm_8_2_2": 2,
        "aten.mm_8_8_2": 2,
        "aten.mm_8_2_8": 2,
        "aten.mm_8_50257_2": 1
      }
    }
  }
}