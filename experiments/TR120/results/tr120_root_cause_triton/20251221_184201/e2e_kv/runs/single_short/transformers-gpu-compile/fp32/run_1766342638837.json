{
  "path": "scripts/tr120/results/tr120_root_cause_triton/20251221_184201/e2e_kv/runs/single_short/transformers-gpu-compile/fp32/run_1766342638837.json",
  "spec": {
    "mode": "e2e_kv",
    "scenario": "single_short",
    "prompt_set": "short",
    "prompts": [
      "Summarize RLHF in one sentence.",
      "List two ways to improve throughput on local LLMs."
    ],
    "backend": "transformers-gpu-compile",
    "model": "models/tiny-gpt2",
    "quantization": "fp32"
  },
  "status": "ok",
  "error": null,
  "latencies_ms": [
    95.69882200048596,
    99.93147199929808,
    105.45255099987116,
    97.3370680003427,
    97.12318099991535,
    99.60450300059165,
    101.00631500063173,
    105.70443800042995,
    108.5473990005994,
    97.29420199892047,
    100.90195100019628,
    99.78887099987332,
    101.58919799960131,
    99.96571100055007,
    101.85760900003515,
    99.01133399944229,
    97.60096599984536,
    100.47237399976439,
    102.99962499902904,
    104.58168199966167,
    103.37872099989909,
    100.68853099983244,
    103.70088000036048,
    98.41300700009015,
    100.67657699983101,
    103.22949300007167,
    103.11005899984593,
    102.0705339997221,
    101.46758399969258,
    102.49225100051262,
    104.4618169999012,
    112.6960429992323,
    102.78090700012399,
    99.99666000021534,
    102.89681700032816,
    100.63727599936101,
    100.12364300018817,
    103.48132099989016,
    100.64276400044037,
    101.73856199980946,
    104.16630600047938,
    99.6390069994959,
    103.93749500053673,
    104.03173699978652,
    106.16715700052737,
    93.61662100036483,
    97.56484499939688,
    97.76608399988618,
    107.14683700007299,
    149.93038000011438,
    133.1574219993854,
    121.02679300005548,
    108.00099399875762,
    112.61819700030173,
    104.20981300103449,
    104.0007110004808,
    102.4790129995381,
    93.67875000043568,
    98.69336000065232,
    107.04559200075892
  ],
  "ttft_ms": [
    95.69882200048596,
    99.93147199929808,
    105.45255099987116,
    97.3370680003427,
    97.12318099991535,
    99.60450300059165,
    101.00631500063173,
    105.70443800042995,
    108.5473990005994,
    97.29420199892047,
    100.90195100019628,
    99.78887099987332,
    101.58919799960131,
    99.96571100055007,
    101.85760900003515,
    99.01133399944229,
    97.60096599984536,
    100.47237399976439,
    102.99962499902904,
    104.58168199966167,
    103.37872099989909,
    100.68853099983244,
    103.70088000036048,
    98.41300700009015,
    100.67657699983101,
    103.22949300007167,
    103.11005899984593,
    102.0705339997221,
    101.46758399969258,
    102.49225100051262,
    104.4618169999012,
    112.6960429992323,
    102.78090700012399,
    99.99666000021534,
    102.89681700032816,
    100.63727599936101,
    100.12364300018817,
    103.48132099989016,
    100.64276400044037,
    101.73856199980946,
    104.16630600047938,
    99.6390069994959,
    103.93749500053673,
    104.03173699978652,
    106.16715700052737,
    93.61662100036483,
    97.56484499939688,
    97.76608399988618,
    107.14683700007299,
    149.93038000011438,
    133.1574219993854,
    121.02679300005548,
    108.00099399875762,
    112.61819700030173,
    104.20981300103449,
    104.0007110004808,
    102.4790129995381,
    93.67875000043568,
    98.69336000065232,
    107.04559200075892
  ],
  "tokens": [
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75
  ],
  "tokens_per_s": [
    762.8098076236436,
    750.514312453306,
    692.2544718722754,
    770.5183805180566,
    751.6228283345006,
    752.9780054176316,
    722.7270888908622,
    709.5255546384433,
    672.5172659328014,
    770.8578564715723,
    723.4746134874835,
    751.5868177333643,
    718.5803356798475,
    750.2572557062822,
    716.6867622032519,
    757.4890365624451,
    747.9434168726943,
    746.4738516099547,
    708.7404444500469,
    717.1427975335358,
    706.141450522214,
    744.8713299841946,
    703.9477389174156,
    762.0943845352809,
    725.0941795540241,
    726.5365528817227,
    707.9813619358813,
    734.7860059221812,
    719.441590333137,
    731.7626383249684,
    698.8199334123112,
    665.5069513000639,
    710.2486456936202,
    750.0250508350828,
    709.4485731251258,
    745.2506961781855,
    729.0985207146608,
    724.7684826141677,
    725.3377898055402,
    737.1836059579892,
    700.8024264550962,
    752.7172566099483,
    702.3451931338449,
    720.933843488107,
    687.5949404921654,
    801.1397890520715,
    748.2203246512744,
    767.1372006685602,
    681.3080259191437,
    500.23217442617556,
    548.2232901770727,
    619.697491281667,
    675.9197049690093,
    665.9669751221381,
    700.5098454526094,
    721.1489159882116,
    712.3409746376951,
    800.6084624277244,
    739.6647555571875,
    700.636042999961
  ],
  "started_at": 1766342632.6124086,
  "degraded_count": 0,
  "degraded_reasons": [],
  "compile": {
    "enabled": true,
    "backend": "inductor",
    "mode": "reduce-overhead",
    "dynamic": true,
    "fullgraph": false,
    "disable_cudagraphs": true,
    "compile_wrapper_ms": 11661.708976000227,
    "dynamo_counters_after_compile": {
      "frames": {
        "total": 4,
        "ok": 4
      },
      "inline_call": {},
      "stats": {
        "calls_captured": 250,
        "unique_graphs": 1
      },
      "inductor": {
        "pattern_matcher_count": 54,
        "pattern_matcher_nodes": 63,
        "benchmarking.InductorBenchmarker.benchmark_gpu": 10,
        "fxgraph_cache_miss": 1,
        "async_compile_cache_miss": 30,
        "extern_calls": 13,
        "async_compile_cache_hit": 15,
        "triton_bundler_save_kernel": 105
      },
      "aot_autograd": {
        "total": 2,
        "autograd_cache_miss": 2,
        "autograd_cache_saved": 1,
        "ok": 1
      },
      "graph_break": {},
      "aten_mm_info": {
        "aten.addmm_s70_6_2": 2,
        "aten.bmm_s70_s70_1": 2,
        "aten.bmm_s70_1_s70": 2,
        "aten.mm_s70_2_2": 2,
        "aten.mm_s70_8_2": 2,
        "aten.mm_s70_2_8": 2,
        "aten.mm_s70_50257_2": 1
      }
    }
  }
}