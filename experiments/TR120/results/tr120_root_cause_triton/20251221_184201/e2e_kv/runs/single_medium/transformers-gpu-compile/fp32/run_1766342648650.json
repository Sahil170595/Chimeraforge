{
  "path": "scripts/tr120/results/tr120_root_cause_triton/20251221_184201/e2e_kv/runs/single_medium/transformers-gpu-compile/fp32/run_1766342648650.json",
  "spec": {
    "mode": "e2e_kv",
    "scenario": "single_medium",
    "prompt_set": "medium",
    "prompts": [
      "Explain how backpressure works in an inference service and when to enable queueing.",
      "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences."
    ],
    "backend": "transformers-gpu-compile",
    "model": "models/tiny-gpt2",
    "quantization": "fp32"
  },
  "status": "ok",
  "error": null,
  "latencies_ms": [
    96.6404330010846,
    98.67638899959275,
    99.54301699963253,
    98.78024800036656,
    94.29860300042492,
    95.98681800071063,
    96.65565500108642,
    93.95123800004512,
    95.00956299962127,
    95.42917399994622,
    95.13693999906536,
    92.01208299964492,
    96.18865399988863,
    93.17486500003724,
    94.75709500020457,
    96.34263400039345,
    109.21405899989622,
    111.7272530000264,
    104.12429699954373,
    101.58767000029911,
    105.99807900052838,
    100.69345500050986,
    97.32585599977028,
    97.7491559997361,
    100.74690300007205,
    104.36553800082038,
    101.86242300005688,
    99.97508000014932,
    98.04058000008808,
    100.23692799950368,
    115.05956500059256,
    101.446018000388,
    99.71880800003419,
    98.07032699973206,
    99.23171300033573,
    100.18937499989988,
    102.99106799902802,
    103.01067299951683,
    94.25804300008167,
    95.83750600086205,
    94.48523800074327,
    95.87980000014795,
    96.70637100043677,
    100.02641899973241,
    98.26678100125719,
    100.3860299997541,
    101.95225999996183,
    95.76576499966905,
    95.79333400051837,
    98.37463999974716,
    97.77013299935788,
    102.8081039994504,
    98.94329899998411,
    99.27069899913477,
    99.50993699931132,
    96.434199000214,
    95.72191099960037,
    100.2837180003553,
    95.3768779991151,
    101.25140699983604
  ],
  "ttft_ms": [
    96.6404330010846,
    98.67638899959275,
    99.54301699963253,
    98.78024800036656,
    94.29860300042492,
    95.98681800071063,
    96.65565500108642,
    93.95123800004512,
    95.00956299962127,
    95.42917399994622,
    95.13693999906536,
    92.01208299964492,
    96.18865399988863,
    93.17486500003724,
    94.75709500020457,
    96.34263400039345,
    109.21405899989622,
    111.7272530000264,
    104.12429699954373,
    101.58767000029911,
    105.99807900052838,
    100.69345500050986,
    97.32585599977028,
    97.7491559997361,
    100.74690300007205,
    104.36553800082038,
    101.86242300005688,
    99.97508000014932,
    98.04058000008808,
    100.23692799950368,
    115.05956500059256,
    101.446018000388,
    99.71880800003419,
    98.07032699973206,
    99.23171300033573,
    100.18937499989988,
    102.99106799902802,
    103.01067299951683,
    94.25804300008167,
    95.83750600086205,
    94.48523800074327,
    95.87980000014795,
    96.70637100043677,
    100.02641899973241,
    98.26678100125719,
    100.3860299997541,
    101.95225999996183,
    95.76576499966905,
    95.79333400051837,
    98.37463999974716,
    97.77013299935788,
    102.8081039994504,
    98.94329899998411,
    99.27069899913477,
    99.50993699931132,
    96.434199000214,
    95.72191099960037,
    100.2837180003553,
    95.3768779991151,
    101.25140699983604
  ],
  "tokens": [
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83,
    81,
    83
  ],
  "tokens_per_s": [
    838.158496238225,
    841.1333333280219,
    813.7185554693306,
    840.2489534111314,
    858.9734887126059,
    864.7020677296076,
    838.0264972503633,
    883.4370016493039,
    852.5457590024163,
    869.7549870865149,
    851.4043020597021,
    902.0554398308785,
    842.0951602056286,
    890.7981782422419,
    854.8172566901204,
    861.5085196825846,
    741.6627560749937,
    742.8805217289321,
    777.9164165723486,
    817.0282869934473,
    764.1647920769982,
    824.2839616495405,
    832.2557163041154,
    849.1121908021802,
    803.9949376899663,
    795.2816762114288,
    795.190194915693,
    830.2068875551391,
    826.1885027600533,
    828.0381457860617,
    703.9831933971144,
    818.1691271478251,
    812.2840778438931,
    846.3314290797334,
    816.2713063285116,
    828.4311584944305,
    786.475968972032,
    805.7417506668393,
    859.343111971143,
    866.0492479766056,
    857.2767737470568,
    865.6672208314152,
    837.5870086122264,
    829.7807802178946,
    824.2866935771888,
    826.8082720295175,
    794.4894993012448,
    866.6980313923962,
    845.5703191159594,
    843.7133797919192,
    828.4738653319821,
    807.3293521728959,
    818.6506900281646,
    836.0976686657905,
    813.9890592088364,
    860.690510840618,
    846.2012422666548,
    827.6518028550352,
    849.2624386463092,
    819.7416950475998
  ],
  "started_at": 1766342643.0162947,
  "degraded_count": 0,
  "degraded_reasons": [],
  "compile": {
    "enabled": true,
    "backend": "inductor",
    "mode": "reduce-overhead",
    "dynamic": true,
    "fullgraph": false,
    "disable_cudagraphs": true,
    "compile_wrapper_ms": 11661.708976000227,
    "dynamo_counters_after_compile": {
      "frames": {
        "total": 4,
        "ok": 4
      },
      "inline_call": {},
      "stats": {
        "calls_captured": 250,
        "unique_graphs": 1
      },
      "inductor": {
        "pattern_matcher_count": 54,
        "pattern_matcher_nodes": 63,
        "benchmarking.InductorBenchmarker.benchmark_gpu": 10,
        "fxgraph_cache_miss": 1,
        "async_compile_cache_miss": 30,
        "extern_calls": 13,
        "async_compile_cache_hit": 15,
        "triton_bundler_save_kernel": 105
      },
      "aot_autograd": {
        "total": 2,
        "autograd_cache_miss": 2,
        "autograd_cache_saved": 1,
        "ok": 1
      },
      "graph_break": {},
      "aten_mm_info": {
        "aten.addmm_s70_6_2": 2,
        "aten.bmm_s70_s70_1": 2,
        "aten.bmm_s70_1_s70": 2,
        "aten.mm_s70_2_2": 2,
        "aten.mm_s70_8_2": 2,
        "aten.mm_s70_2_8": 2,
        "aten.mm_s70_50257_2": 1
      }
    }
  }
}