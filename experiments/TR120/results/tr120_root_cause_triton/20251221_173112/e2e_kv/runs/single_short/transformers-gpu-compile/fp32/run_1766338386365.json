{
  "path": "scripts/tr120/results/tr120_root_cause_triton/20251221_173112/e2e_kv/runs/single_short/transformers-gpu-compile/fp32/run_1766338386365.json",
  "spec": {
    "mode": "e2e_kv",
    "scenario": "single_short",
    "prompt_set": "short",
    "prompts": [
      "Summarize RLHF in one sentence.",
      "List two ways to improve throughput on local LLMs."
    ],
    "backend": "transformers-gpu-compile",
    "model": "models/tiny-gpt2",
    "quantization": "fp32"
  },
  "status": "ok",
  "error": null,
  "latencies_ms": [
    109.72703599998113,
    111.2675520000721,
    113.17407599995022,
    107.52232599998024,
    104.43164100001923,
    102.67716799990012,
    114.95687499996166,
    107.23828699997284,
    103.8352030001306,
    103.82374800008165,
    103.79717400007848,
    106.29656300000079,
    108.07788099998561,
    110.5637889999116,
    116.61719000005633,
    100.88104899989503,
    110.51722799993513,
    151.12177299999985,
    104.66782100002092,
    108.39532400007101,
    103.818441000044,
    105.42075900002601,
    103.32389200004855,
    104.04187000006004,
    129.02183200003492,
    103.0576299999666,
    104.82265799998913,
    105.93680900001345,
    100.84295399985876,
    103.22044899999128,
    99.99764600001981,
    104.32097199998225,
    108.59731999994438,
    98.06559800006198,
    105.35792299992863,
    103.53981399998702,
    112.90452699995512,
    111.67899300005502,
    104.61732299995674,
    103.84407599985934,
    104.15854499990473,
    101.04270400006499,
    106.86528700011877,
    106.21912599992811,
    110.14921399987543,
    97.97040299997661,
    101.28946499992253,
    100.81412099998488,
    102.57241099998282,
    103.46551399993587,
    102.66475599996738,
    102.46007899991127,
    103.9623990001246,
    101.49431100001038,
    102.04833300008431,
    105.5868509999982,
    101.30182099987906,
    103.34027700002935,
    108.89475299995865,
    102.52981600001476
  ],
  "ttft_ms": [
    109.72703599998113,
    111.2675520000721,
    113.17407599995022,
    107.52232599998024,
    104.43164100001923,
    102.67716799990012,
    114.95687499996166,
    107.23828699997284,
    103.8352030001306,
    103.82374800008165,
    103.79717400007848,
    106.29656300000079,
    108.07788099998561,
    110.5637889999116,
    116.61719000005633,
    100.88104899989503,
    110.51722799993513,
    151.12177299999985,
    104.66782100002092,
    108.39532400007101,
    103.818441000044,
    105.42075900002601,
    103.32389200004855,
    104.04187000006004,
    129.02183200003492,
    103.0576299999666,
    104.82265799998913,
    105.93680900001345,
    100.84295399985876,
    103.22044899999128,
    99.99764600001981,
    104.32097199998225,
    108.59731999994438,
    98.06559800006198,
    105.35792299992863,
    103.53981399998702,
    112.90452699995512,
    111.67899300005502,
    104.61732299995674,
    103.84407599985934,
    104.15854499990473,
    101.04270400006499,
    106.86528700011877,
    106.21912599992811,
    110.14921399987543,
    97.97040299997661,
    101.28946499992253,
    100.81412099998488,
    102.57241099998282,
    103.46551399993587,
    102.66475599996738,
    102.46007899991127,
    103.9623990001246,
    101.49431100001038,
    102.04833300008431,
    105.5868509999982,
    101.30182099987906,
    103.34027700002935,
    108.89475299995865,
    102.52981600001476
  ],
  "tokens": [
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75
  ],
  "tokens_per_s": [
    665.2872679438143,
    674.0509578205819,
    645.0240424320505,
    697.5295530717386,
    699.0218606254264,
    730.444766455508,
    635.0207414739166,
    699.3770797552836,
    703.0371000469675,
    722.378082516738,
    703.2946773670814,
    705.5731425671726,
    675.4388532100265,
    678.3414414285311,
    625.97975478542,
    743.4498425970772,
    660.5305011816154,
    496.28851297291277,
    697.4445374188635,
    691.9117654923091,
    703.150608859259,
    711.4348322988407,
    706.5161656895939,
    720.8636292288548,
    565.7957174254063,
    727.7481541155595,
    696.4143191256185,
    707.9692196504661,
    723.8978739169247,
    726.6002107780633,
    730.017184604381,
    718.9350191255193,
    672.2081171067333,
    764.7941941877782,
    692.876225360379,
    724.3590373844926,
    646.5639770142168,
    671.5676599981794,
    697.7811886854549,
    722.2366733765496,
    700.8546442355428,
    742.2604209003727,
    683.1030173522939,
    706.0875270245658,
    662.7373664244445,
    765.5373225321723,
    720.7067388504405,
    743.943400548136,
    711.6923477601811,
    724.879209511746,
    711.0521939975506,
    731.9924084780858,
    702.1769476473172,
    738.9576741891703,
    715.3473050847356,
    710.3157191419723,
    720.6188327067404,
    725.7576830375508,
    670.3720609938637,
    731.4945342337219
  ],
  "started_at": 1766338379.978489,
  "degraded_count": 0,
  "degraded_reasons": [],
  "compile": {
    "enabled": true,
    "backend": "inductor",
    "mode": "reduce-overhead",
    "dynamic": false,
    "fullgraph": false,
    "compile_wrapper_ms": 6510.590301999969,
    "dynamo_counters_after_compile": {
      "frames": {
        "total": 1,
        "ok": 1
      },
      "inline_call": {},
      "stats": {
        "calls_captured": 110,
        "unique_graphs": 1
      },
      "inductor": {
        "pattern_matcher_count": 54,
        "pattern_matcher_nodes": 63,
        "benchmarking.InductorBenchmarker.benchmark_gpu": 12,
        "fxgraph_cache_miss": 1,
        "async_compile_cache_miss": 30,
        "extern_calls": 13,
        "async_compile_cache_hit": 15,
        "triton_bundler_save_kernel": 112
      },
      "aot_autograd": {
        "total": 1,
        "autograd_cache_miss": 1,
        "autograd_cache_saved": 1,
        "ok": 1
      },
      "graph_break": {},
      "aten_mm_info": {
        "aten.addmm_8_6_2": 2,
        "aten.bmm_8_8_1": 2,
        "aten.bmm_8_1_8": 2,
        "aten.mm_8_2_2": 2,
        "aten.mm_8_8_2": 2,
        "aten.mm_8_2_8": 2,
        "aten.mm_8_50257_2": 1
      }
    }
  }
}