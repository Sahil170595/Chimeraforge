{
  "path": "scripts/tr120/results/tr120_root_cause_triton/20251221_173112/kv_decode/runs/single_short/transformers-gpu-compile/fp32/run_1766338329829.json",
  "spec": {
    "mode": "kv_decode",
    "scenario": "single_short",
    "prompt_set": "short",
    "prompts": [
      "Summarize RLHF in one sentence.",
      "List two ways to improve throughput on local LLMs."
    ],
    "backend": "transformers-gpu-compile",
    "model": "models/tiny-gpt2",
    "quantization": "fp32"
  },
  "status": "ok",
  "error": null,
  "latencies_ms": [
    109.40780199996425,
    102.65537400005087,
    103.02078400002301,
    104.93102300006285,
    112.61291400001028,
    112.2975690000203,
    110.83210800006782,
    101.50369600000886,
    101.44650099994124,
    100.2305049998995,
    101.5695160000405,
    103.71175099999164,
    104.08101500001976,
    101.57827100010763,
    100.13438299995414,
    99.49913000002653,
    103.52068700001382,
    103.60852899998463,
    102.2781289999557,
    99.45741900003213,
    101.21633599999313,
    99.12484300002689,
    100.93439400009174,
    102.7316830000018,
    104.5828139999685,
    108.12106999992466,
    100.87413300004755,
    100.14651699998467,
    101.25059000006331,
    114.48651599994264,
    97.85306500009483,
    104.03639900005146,
    103.9675410000882,
    103.05344400001104,
    105.18986399995356,
    104.05521100005899,
    104.66323200000716,
    95.05803000001833,
    103.78214699994714,
    101.59265300001152,
    101.6264869999759,
    107.27729600000657,
    104.54569000000902,
    105.55177699995966,
    96.46937900004104,
    100.04056499997205,
    107.32893600004445,
    107.7846089999639,
    108.73170400009258,
    99.98804800000016,
    101.00812600001063,
    102.5155420001056,
    105.54432799995084,
    103.92506699997739,
    96.74357599999439,
    100.0823209999453,
    98.46355999991374,
    100.85422600002403,
    110.35731900005885,
    101.73803500003942
  ],
  "ttft_ms": [
    109.40780199996425,
    102.65537400005087,
    103.02078400002301,
    104.93102300006285,
    112.61291400001028,
    112.2975690000203,
    110.83210800006782,
    101.50369600000886,
    101.44650099994124,
    100.2305049998995,
    101.5695160000405,
    103.71175099999164,
    104.08101500001976,
    101.57827100010763,
    100.13438299995414,
    99.49913000002653,
    103.52068700001382,
    103.60852899998463,
    102.2781289999557,
    99.45741900003213,
    101.21633599999313,
    99.12484300002689,
    100.93439400009174,
    102.7316830000018,
    104.5828139999685,
    108.12106999992466,
    100.87413300004755,
    100.14651699998467,
    101.25059000006331,
    114.48651599994264,
    97.85306500009483,
    104.03639900005146,
    103.9675410000882,
    103.05344400001104,
    105.18986399995356,
    104.05521100005899,
    104.66323200000716,
    95.05803000001833,
    103.78214699994714,
    101.59265300001152,
    101.6264869999759,
    107.27729600000657,
    104.54569000000902,
    105.55177699995966,
    96.46937900004104,
    100.04056499997205,
    107.32893600004445,
    107.7846089999639,
    108.73170400009258,
    99.98804800000016,
    101.00812600001063,
    102.5155420001056,
    105.54432799995084,
    103.92506699997739,
    96.74357599999439,
    100.0823209999453,
    98.46355999991374,
    100.85422600002403,
    110.35731900005885,
    101.73803500003942
  ],
  "tokens": [
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64
  ],
  "tokens_per_s": [
    584.967423072999,
    623.445198299782,
    621.2338667504773,
    609.9244834386268,
    568.3184789978365,
    569.9143852347189,
    577.4499931009237,
    630.5189123359056,
    630.8743955598535,
    638.5281606639035,
    630.1103177450849,
    617.0949712343123,
    614.9056098269973,
    630.0560087297822,
    639.1411030118327,
    643.2217045514161,
    618.233918791434,
    617.7097640292673,
    625.7447278882831,
    643.4914624114599,
    632.3089980258161,
    645.6504551536353,
    634.0752390106175,
    622.9821037780417,
    611.955230044004,
    591.9290291896352,
    634.4540279713714,
    639.0636630928442,
    632.0950821122127,
    559.0177973450783,
    654.041853466092,
    615.1693120401865,
    615.5767404361877,
    621.0369834897817,
    608.423640513769,
    615.058096417331,
    611.4850342094884,
    673.2729470617859,
    616.6763923281776,
    629.966814627754,
    629.7570829149607,
    596.5847610476319,
    612.1725343244134,
    606.337494441467,
    663.4229499909269,
    639.7404892707061,
    596.2977216132423,
    593.7767979472973,
    588.6047734517755,
    640.0765019435113,
    633.612388769526,
    624.2955824194353,
    606.3802879111591,
    615.828325614781,
    661.5426330736803,
    639.4735789554179,
    649.9866549620598,
    634.5792589790412,
    579.93434943781,
    629.066602278835
  ],
  "started_at": 1766338323.590975,
  "degraded_count": 0,
  "degraded_reasons": [],
  "compile": {
    "enabled": true,
    "backend": "inductor",
    "mode": "reduce-overhead",
    "dynamic": false,
    "fullgraph": false,
    "compile_wrapper_ms": 6510.590301999969,
    "dynamo_counters_after_compile": {
      "frames": {
        "total": 1,
        "ok": 1
      },
      "inline_call": {},
      "stats": {
        "calls_captured": 110,
        "unique_graphs": 1
      },
      "inductor": {
        "pattern_matcher_count": 54,
        "pattern_matcher_nodes": 63,
        "benchmarking.InductorBenchmarker.benchmark_gpu": 12,
        "fxgraph_cache_miss": 1,
        "async_compile_cache_miss": 30,
        "extern_calls": 13,
        "async_compile_cache_hit": 15,
        "triton_bundler_save_kernel": 112
      },
      "aot_autograd": {
        "total": 1,
        "autograd_cache_miss": 1,
        "autograd_cache_saved": 1,
        "ok": 1
      },
      "graph_break": {},
      "aten_mm_info": {
        "aten.addmm_8_6_2": 2,
        "aten.bmm_8_8_1": 2,
        "aten.bmm_8_1_8": 2,
        "aten.mm_8_2_2": 2,
        "aten.mm_8_8_2": 2,
        "aten.mm_8_2_8": 2,
        "aten.mm_8_50257_2": 1
      }
    }
  }
}