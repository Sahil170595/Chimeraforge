{
  "path": "scripts/tr120/results/tr120_root_cause_triton/20251221_182322/e2e_kv/runs/single_short/transformers-gpu-compile/fp32/run_1766341514622.json",
  "spec": {
    "mode": "e2e_kv",
    "scenario": "single_short",
    "prompt_set": "short",
    "prompts": [
      "Summarize RLHF in one sentence.",
      "List two ways to improve throughput on local LLMs."
    ],
    "backend": "transformers-gpu-compile",
    "model": "models/tiny-gpt2",
    "quantization": "fp32"
  },
  "status": "ok",
  "error": null,
  "latencies_ms": [
    96.23294199991506,
    98.9459500005978,
    98.02613099964219,
    101.78218700002617,
    105.12449300040316,
    105.65014599978895,
    95.86624500116159,
    98.20312000010745,
    99.75989700069476,
    104.59014399930311,
    104.19470699980593,
    107.3694599999726,
    100.38024200002837,
    100.03712599973369,
    100.50692900040303,
    99.85449000032531,
    102.77203300029214,
    101.88698600086354,
    101.48802799994883,
    103.26607599927229,
    104.1722630006916,
    101.20191100122611,
    105.11489800046547,
    105.9466219994647,
    103.38596600013261,
    101.99223400104529,
    103.17577599926153,
    106.24583400021947,
    111.34870000023511,
    100.92435899969132,
    106.44643400064524,
    100.77263500079425,
    109.63821399946028,
    106.19227200004389,
    107.60577299970464,
    96.5377830007128,
    109.5568020009523,
    105.0108330000512,
    109.9069160009094,
    136.80282000041188,
    119.51954399955866,
    102.91373299969564,
    103.23642399998789,
    103.53981699972792,
    102.91487199901894,
    101.26960499928828,
    105.02892700060329,
    102.88462900007289,
    106.25151800013555,
    98.40918999998394,
    98.42882600059966,
    98.06706000017584,
    104.82171900002868,
    98.16512699944724,
    98.12048500043602,
    99.76330400058941,
    103.34135000084643,
    98.84995799984608,
    113.28196700014814,
    104.87265900064813
  ],
  "ttft_ms": [
    96.23294199991506,
    98.9459500005978,
    98.02613099964219,
    101.78218700002617,
    105.12449300040316,
    105.65014599978895,
    95.86624500116159,
    98.20312000010745,
    99.75989700069476,
    104.59014399930311,
    104.19470699980593,
    107.3694599999726,
    100.38024200002837,
    100.03712599973369,
    100.50692900040303,
    99.85449000032531,
    102.77203300029214,
    101.88698600086354,
    101.48802799994883,
    103.26607599927229,
    104.1722630006916,
    101.20191100122611,
    105.11489800046547,
    105.9466219994647,
    103.38596600013261,
    101.99223400104529,
    103.17577599926153,
    106.24583400021947,
    111.34870000023511,
    100.92435899969132,
    106.44643400064524,
    100.77263500079425,
    109.63821399946028,
    106.19227200004389,
    107.60577299970464,
    96.5377830007128,
    109.5568020009523,
    105.0108330000512,
    109.9069160009094,
    136.80282000041188,
    119.51954399955866,
    102.91373299969564,
    103.23642399998789,
    103.53981699972792,
    102.91487199901894,
    101.26960499928828,
    105.02892700060329,
    102.88462900007289,
    106.25151800013555,
    98.40918999998394,
    98.42882600059966,
    98.06706000017584,
    104.82171900002868,
    98.16512699944724,
    98.12048500043602,
    99.76330400058941,
    103.34135000084643,
    98.84995799984608,
    113.28196700014814,
    104.87265900064813
  ],
  "tokens": [
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75
  ],
  "tokens_per_s": [
    758.575997812313,
    757.989589261075,
    744.6993904132202,
    736.8676407000443,
    694.4147640238325,
    709.8901690126374,
    761.4776191465044,
    763.7231892420316,
    731.7569704336363,
    717.0847761764219,
    700.6114043790724,
    698.5226525309816,
    727.2347480491168,
    749.7216583391216,
    726.318083002091,
    751.0929152986076,
    710.3099731401877,
    736.1097127690512,
    719.2966642335075,
    726.2791703301336,
    700.7623516781559,
    741.0927250088325,
    694.4781509437106,
    707.9036460490354,
    706.0919660982455,
    735.3501051779231,
    707.5304187731284,
    705.9100312568027,
    655.5981345075952,
    743.1308035380179,
    685.7909396904503,
    744.2496665826876,
    665.8262419374996,
    706.2660830909523,
    678.402263791185,
    776.8978908439012,
    666.3210194777815,
    714.2120280101333,
    664.1984204105588,
    548.2343127120786,
    610.7787693723928,
    728.7657129318378,
    707.1147679428393,
    724.3590163984652,
    709.324110131487,
    740.597339157461,
    695.0466132019104,
    728.9718661467581,
    687.0490076189487,
    762.1239439122733,
    741.6526536601713,
    764.7827925081624,
    696.4205576516068,
    764.0187742070799,
    743.9832772909307,
    751.7794318395559,
    706.3968101771661,
    758.7256637996425,
    644.409714389092,
    715.1530314448925
  ],
  "started_at": 1766341508.3887048,
  "degraded_count": 0,
  "degraded_reasons": [],
  "compile": {
    "enabled": true,
    "backend": "inductor",
    "mode": "reduce-overhead",
    "dynamic": false,
    "fullgraph": false,
    "disable_cudagraphs": true,
    "compile_wrapper_ms": 6266.81523499974,
    "dynamo_counters_after_compile": {
      "frames": {
        "total": 1,
        "ok": 1
      },
      "inline_call": {},
      "stats": {
        "calls_captured": 110,
        "unique_graphs": 1
      },
      "inductor": {
        "pattern_matcher_count": 54,
        "pattern_matcher_nodes": 63,
        "benchmarking.InductorBenchmarker.benchmark_gpu": 12,
        "fxgraph_cache_miss": 1,
        "async_compile_cache_miss": 30,
        "extern_calls": 13,
        "async_compile_cache_hit": 15,
        "triton_bundler_save_kernel": 112
      },
      "aot_autograd": {
        "total": 1,
        "autograd_cache_miss": 1,
        "autograd_cache_saved": 1,
        "ok": 1
      },
      "graph_break": {},
      "aten_mm_info": {
        "aten.addmm_8_6_2": 2,
        "aten.bmm_8_8_1": 2,
        "aten.bmm_8_1_8": 2,
        "aten.mm_8_2_2": 2,
        "aten.mm_8_8_2": 2,
        "aten.mm_8_2_8": 2,
        "aten.mm_8_50257_2": 1
      }
    }
  }
}