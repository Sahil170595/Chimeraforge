{
  "path": "scripts/tr120/results/tr120_root_cause_triton/20251221_182322/kv_decode/runs/single_short/transformers-gpu-compile/fp32/run_1766341459992.json",
  "spec": {
    "mode": "kv_decode",
    "scenario": "single_short",
    "prompt_set": "short",
    "prompts": [
      "Summarize RLHF in one sentence.",
      "List two ways to improve throughput on local LLMs."
    ],
    "backend": "transformers-gpu-compile",
    "model": "models/tiny-gpt2",
    "quantization": "fp32"
  },
  "status": "ok",
  "error": null,
  "latencies_ms": [
    106.41546799979551,
    106.44800499994744,
    105.75426800005516,
    110.40235699965706,
    107.00391200043669,
    97.55291500005114,
    107.11087199979374,
    114.16848799945001,
    111.86690799968346,
    101.89724000065326,
    102.03568299948529,
    103.7531920001129,
    100.74920300030499,
    100.97424499963381,
    102.04165499999363,
    109.0406149996852,
    108.12188599993533,
    97.53965599975345,
    99.81934799998271,
    98.38506500000221,
    99.24727399993571,
    105.55919899979926,
    103.93237000062072,
    106.57153400006791,
    106.6000589999021,
    103.64280999965558,
    101.58171700004459,
    99.63599000002432,
    100.87056599968491,
    96.2104599993836,
    98.92765099993994,
    99.08124100002169,
    105.15479400055483,
    101.56983499928174,
    107.68401699988317,
    102.59389600014401,
    104.56250399965938,
    107.2336670004006,
    109.72712999955547,
    103.52753799998027,
    103.20172100000491,
    99.93617899999663,
    97.78398499929608,
    101.19970600044326,
    104.10069100089459,
    109.18396600027336,
    98.05402599977242,
    103.16398900067725,
    100.95756800001254,
    99.75465699972119,
    114.64562599940109,
    105.15026200027933,
    100.90851200038742,
    103.85124799995538,
    102.3958469995705,
    105.90390600009414,
    108.5656889999882,
    103.70269200029725,
    103.53107199989608,
    101.55640699940705
  ],
  "ttft_ms": [
    106.41546799979551,
    106.44800499994744,
    105.75426800005516,
    110.40235699965706,
    107.00391200043669,
    97.55291500005114,
    107.11087199979374,
    114.16848799945001,
    111.86690799968346,
    101.89724000065326,
    102.03568299948529,
    103.7531920001129,
    100.74920300030499,
    100.97424499963381,
    102.04165499999363,
    109.0406149996852,
    108.12188599993533,
    97.53965599975345,
    99.81934799998271,
    98.38506500000221,
    99.24727399993571,
    105.55919899979926,
    103.93237000062072,
    106.57153400006791,
    106.6000589999021,
    103.64280999965558,
    101.58171700004459,
    99.63599000002432,
    100.87056599968491,
    96.2104599993836,
    98.92765099993994,
    99.08124100002169,
    105.15479400055483,
    101.56983499928174,
    107.68401699988317,
    102.59389600014401,
    104.56250399965938,
    107.2336670004006,
    109.72712999955547,
    103.52753799998027,
    103.20172100000491,
    99.93617899999663,
    97.78398499929608,
    101.19970600044326,
    104.10069100089459,
    109.18396600027336,
    98.05402599977242,
    103.16398900067725,
    100.95756800001254,
    99.75465699972119,
    114.64562599940109,
    105.15026200027933,
    100.90851200038742,
    103.85124799995538,
    102.3958469995705,
    105.90390600009414,
    108.5656889999882,
    103.70269200029725,
    103.53107199989608,
    101.55640699940705
  ],
  "tokens": [
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64
  ],
  "tokens_per_s": [
    601.4163279357375,
    601.2324984393235,
    605.1765211023599,
    579.697768592013,
    598.1089738077876,
    656.0542040180599,
    597.5117073094433,
    560.5749985960076,
    572.1084201252894,
    628.083743971767,
    627.2315538900527,
    616.8484917546475,
    635.2407571879875,
    633.8249917118181,
    627.1948450856074,
    586.9372618650837,
    591.9245618786032,
    656.1433843908756,
    641.1582652294131,
    650.5052367450137,
    644.8539835969848,
    606.2948620908132,
    615.7850532958862,
    600.5355989335691,
    600.3749022320783,
    617.5054497288589,
    630.0346350709144,
    642.3381751913579,
    634.4764636316199,
    665.208335979373,
    646.937427029768,
    645.934582107081,
    608.6265548640827,
    630.1083387646793,
    594.3314688944919,
    623.8187893742739,
    612.0740949375934,
    596.8274870219715,
    583.265050313986,
    618.1930067728665,
    620.1446970055563,
    640.4087152461789,
    654.503904708534,
    632.4129044378813,
    614.7893869354817,
    586.1666538092211,
    652.7013995340542,
    620.3715135480061,
    633.929692125627,
    641.5740570405537,
    558.241969042363,
    608.6527868074165,
    634.2378728144786,
    616.2660654788424,
    625.0253489310797,
    604.3214307878608,
    589.5048480741182,
    617.1488778692125,
    618.1719049529811,
    630.1916530029827
  ],
  "started_at": 1766341453.7306333,
  "degraded_count": 0,
  "degraded_reasons": [],
  "compile": {
    "enabled": true,
    "backend": "inductor",
    "mode": "reduce-overhead",
    "dynamic": false,
    "fullgraph": false,
    "disable_cudagraphs": true,
    "compile_wrapper_ms": 6266.81523499974,
    "dynamo_counters_after_compile": {
      "frames": {
        "total": 1,
        "ok": 1
      },
      "inline_call": {},
      "stats": {
        "calls_captured": 110,
        "unique_graphs": 1
      },
      "inductor": {
        "pattern_matcher_count": 54,
        "pattern_matcher_nodes": 63,
        "benchmarking.InductorBenchmarker.benchmark_gpu": 12,
        "fxgraph_cache_miss": 1,
        "async_compile_cache_miss": 30,
        "extern_calls": 13,
        "async_compile_cache_hit": 15,
        "triton_bundler_save_kernel": 112
      },
      "aot_autograd": {
        "total": 1,
        "autograd_cache_miss": 1,
        "autograd_cache_saved": 1,
        "ok": 1
      },
      "graph_break": {},
      "aten_mm_info": {
        "aten.addmm_8_6_2": 2,
        "aten.bmm_8_8_1": 2,
        "aten.bmm_8_1_8": 2,
        "aten.mm_8_2_2": 2,
        "aten.mm_8_8_2": 2,
        "aten.mm_8_2_8": 2,
        "aten.mm_8_50257_2": 1
      }
    }
  }
}