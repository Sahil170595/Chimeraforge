{
  "path": "scripts/tr120/results/tr120_root_cause/20251221_113136/e2e_kv/runs/single_short/transformers-gpu-compile/fp32/run_1766334822225.json",
  "spec": {
    "mode": "e2e_kv",
    "scenario": "single_short",
    "prompt_set": "short",
    "prompts": [
      "Summarize RLHF in one sentence.",
      "List two ways to improve throughput on local LLMs."
    ],
    "backend": "transformers-gpu-compile",
    "model": "models/tiny-gpt2",
    "quantization": "fp32"
  },
  "status": "ok",
  "error": null,
  "latencies_ms": [
    104.20620000013514,
    102.04819999944448,
    102.28850000021339,
    103.42079999963971,
    110.08129999981975,
    189.26220000003013,
    164.3368000004557,
    102.39529999989827,
    103.2599999998638,
    112.12189999969269,
    104.18619999973089,
    106.14929999974265,
    104.63800000025003,
    104.72310000022844,
    103.2869000005121,
    104.68560000026628,
    102.2186000000147,
    101.4086000000134,
    100.96150000026682,
    101.91819999954532,
    113.29699999987497,
    110.43370000015784,
    102.81459999987419,
    102.37189999998009,
    101.44960000025094,
    101.6672999999173,
    101.12759999992704,
    100.51899999962188,
    101.06460000042716,
    100.15519999933531,
    100.9636000003411,
    99.438199999895,
    101.11640000013722,
    111.59580000003189,
    101.7375000001266,
    137.73120000041672,
    104.80520000010074,
    153.59049999960916,
    255.6162000000768,
    247.40149999979621,
    248.23590000005424,
    289.77460000032806,
    259.7612000004119,
    260.94870000042647,
    248.9189000002625,
    255.03410000010263,
    239.36170000024504,
    234.90340000034848,
    218.14879999965342,
    99.05960000014602,
    104.10030000002735,
    131.80839999995442,
    105.786199999784,
    106.47189999963302,
    112.80150000038702,
    109.71980000022086,
    108.07830000021568,
    129.37599999941085,
    107.35559999966426,
    106.57100000025821
  ],
  "ttft_ms": [
    104.20620000013514,
    102.04819999944448,
    102.28850000021339,
    103.42079999963971,
    110.08129999981975,
    189.26220000003013,
    164.3368000004557,
    102.39529999989827,
    103.2599999998638,
    112.12189999969269,
    104.18619999973089,
    106.14929999974265,
    104.63800000025003,
    104.72310000022844,
    103.2869000005121,
    104.68560000026628,
    102.2186000000147,
    101.4086000000134,
    100.96150000026682,
    101.91819999954532,
    113.29699999987497,
    110.43370000015784,
    102.81459999987419,
    102.37189999998009,
    101.44960000025094,
    101.6672999999173,
    101.12759999992704,
    100.51899999962188,
    101.06460000042716,
    100.15519999933531,
    100.9636000003411,
    99.438199999895,
    101.11640000013722,
    111.59580000003189,
    101.7375000001266,
    137.73120000041672,
    104.80520000010074,
    153.59049999960916,
    255.6162000000768,
    247.40149999979621,
    248.23590000005424,
    289.77460000032806,
    259.7612000004119,
    260.94870000042647,
    248.9189000002625,
    255.03410000010263,
    239.36170000024504,
    234.90340000034848,
    218.14879999965342,
    99.05960000014602,
    104.10030000002735,
    131.80839999995442,
    105.786199999784,
    106.47189999963302,
    112.80150000038702,
    109.71980000022086,
    108.07830000021568,
    129.37599999941085,
    107.35559999966426,
    106.57100000025821
  ],
  "tokens": [
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75,
    73,
    75
  ],
  "tokens_per_s": [
    700.5341332848269,
    734.94681925216,
    713.6677143554526,
    725.1926111600498,
    663.1462382813387,
    396.2756429967952,
    444.2096961836763,
    732.4554935634205,
    706.9533217131153,
    668.9148150379682,
    700.6686106239459,
    706.5519979894528,
    697.6433035782944,
    716.1743684042623,
    706.7692030609696,
    716.4309131323623,
    714.1557407359277,
    739.5822445038201,
    723.0478944925251,
    735.8842679750485,
    644.3242098209181,
    679.1405159828278,
    710.0158926853708,
    732.6229170310855,
    719.5691259484456,
    737.7003225231811,
    721.8603032214021,
    746.1275977703929,
    722.3102847059351,
    748.837803733583,
    723.0328554028716,
    754.2373051813005,
    721.9402589481126,
    672.068303645644,
    717.5328664446164,
    544.5389279972372,
    696.5303248305412,
    488.31145155586347,
    285.58440349233763,
    303.1509509847829,
    294.0751116175543,
    258.8218567117859,
    281.0273435751153,
    287.4128133226087,
    293.26820904287706,
    294.0783212910345,
    304.97778048837915,
    319.2801807035945,
    334.633974608689,
    757.1199560657367,
    701.2467783472365,
    569.0077415401897,
    690.0711056843809,
    704.4112108477308,
    647.1545147870333,
    683.5593940186642,
    675.4362346544526,
    579.7056641134486,
    679.9831587753996,
    703.7561813234208
  ],
  "started_at": 1766334814.070246,
  "degraded_count": 0,
  "degraded_reasons": [],
  "compile": {
    "enabled": true,
    "backend": "aot_eager",
    "mode": "reduce-overhead",
    "dynamic": false,
    "fullgraph": false,
    "compile_wrapper_ms": 0.6936999998288229,
    "fallback_from": "inductor",
    "fallback_error": "compile_smoke_failed: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"
  }
}