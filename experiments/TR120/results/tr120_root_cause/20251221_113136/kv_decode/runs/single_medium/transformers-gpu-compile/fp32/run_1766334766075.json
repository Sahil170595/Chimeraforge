{
  "path": "scripts/tr120/results/tr120_root_cause/20251221_113136/kv_decode/runs/single_medium/transformers-gpu-compile/fp32/run_1766334766075.json",
  "spec": {
    "mode": "kv_decode",
    "scenario": "single_medium",
    "prompt_set": "medium",
    "prompts": [
      "Explain how backpressure works in an inference service and when to enable queueing.",
      "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences."
    ],
    "backend": "transformers-gpu-compile",
    "model": "models/tiny-gpt2",
    "quantization": "fp32"
  },
  "status": "ok",
  "error": null,
  "latencies_ms": [
    105.19819999990432,
    107.94819999955507,
    144.2615000000842,
    192.77329999977155,
    112.89340000030279,
    104.58740000012767,
    107.05520000010438,
    104.2499999998654,
    102.02919999983351,
    102.28420000021288,
    102.668999999878,
    104.06979999970645,
    98.70599999976548,
    104.22440000002098,
    104.26050000023679,
    178.1804999995984,
    108.75779999969382,
    101.32859999976063,
    100.28439999996408,
    103.12059999978374,
    101.99939999984053,
    100.43939999968643,
    104.30980000001,
    172.09420000017417,
    104.27149999986796,
    105.57110000036118,
    123.80629999961457,
    139.2031999998835,
    105.61740000002828,
    103.4153000000515,
    100.26849999985643,
    102.32960000030289,
    107.65300000002753,
    107.20199999968827,
    113.54769999979908,
    240.67120000017894,
    103.80080000004455,
    183.20360000006986,
    157.3684999998477,
    99.8104999998759,
    103.09529999994993,
    106.66760000003705,
    98.30239999973855,
    106.32269999996424,
    106.55540000016117,
    115.5561000000489,
    104.72600000002785,
    106.87500000040018,
    108.81080000035581,
    105.32650000004651,
    108.06390000016108,
    110.64809999970748,
    106.08940000020084,
    108.59510000000228,
    108.78069999989748,
    109.26789999984976,
    109.78690000001734,
    109.66170000028796,
    110.2298000000701,
    130.69250000035026
  ],
  "ttft_ms": [
    105.19819999990432,
    107.94819999955507,
    144.2615000000842,
    192.77329999977155,
    112.89340000030279,
    104.58740000012767,
    107.05520000010438,
    104.2499999998654,
    102.02919999983351,
    102.28420000021288,
    102.668999999878,
    104.06979999970645,
    98.70599999976548,
    104.22440000002098,
    104.26050000023679,
    178.1804999995984,
    108.75779999969382,
    101.32859999976063,
    100.28439999996408,
    103.12059999978374,
    101.99939999984053,
    100.43939999968643,
    104.30980000001,
    172.09420000017417,
    104.27149999986796,
    105.57110000036118,
    123.80629999961457,
    139.2031999998835,
    105.61740000002828,
    103.4153000000515,
    100.26849999985643,
    102.32960000030289,
    107.65300000002753,
    107.20199999968827,
    113.54769999979908,
    240.67120000017894,
    103.80080000004455,
    183.20360000006986,
    157.3684999998477,
    99.8104999998759,
    103.09529999994993,
    106.66760000003705,
    98.30239999973855,
    106.32269999996424,
    106.55540000016117,
    115.5561000000489,
    104.72600000002785,
    106.87500000040018,
    108.81080000035581,
    105.32650000004651,
    108.06390000016108,
    110.64809999970748,
    106.08940000020084,
    108.59510000000228,
    108.78069999989748,
    109.26789999984976,
    109.78690000001734,
    109.66170000028796,
    110.2298000000701,
    130.69250000035026
  ],
  "tokens": [
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64
  ],
  "tokens_per_s": [
    608.3754284774665,
    592.8769539488735,
    443.63880869090264,
    331.99618411925223,
    566.9064799167032,
    611.9283967277308,
    597.822431791614,
    613.9088729024713,
    627.271408578176,
    625.7075872897946,
    623.3624560488175,
    614.9718746474051,
    648.3901687856063,
    614.0596635719382,
    613.8470465790463,
    359.1863307160113,
    588.463540087977,
    631.6084501330442,
    638.1850018549537,
    620.6325409291085,
    627.454671302969,
    637.2001425755212,
    613.5569237022204,
    371.8893489724536,
    613.7822895046206,
    606.2265146406644,
    516.9365371568268,
    459.75954575795356,
    605.9607602533565,
    618.8639398615884,
    638.2862015497553,
    625.4299831115392,
    594.5027077738997,
    597.0037872445114,
    563.6397742984952,
    265.92296876382557,
    616.5655756022355,
    349.3381134430524,
    406.6887591866348,
    641.2151026202612,
    620.784846642195,
    599.9947500457287,
    651.0522632221615,
    601.9410718503342,
    600.6265285466827,
    553.8435443907584,
    611.1185378987356,
    598.8304093544829,
    588.176908907854,
    607.6343560259929,
    592.242182633651,
    578.4102935357155,
    603.2647936540205,
    589.345191449694,
    588.3396595173622,
    585.7163906333699,
    582.9475101308981,
    583.613057246349,
    580.6052446793816,
    489.69910285462805
  ],
  "started_at": 1766334758.8747313,
  "degraded_count": 0,
  "degraded_reasons": [],
  "compile": {
    "enabled": true,
    "backend": "aot_eager",
    "mode": "reduce-overhead",
    "dynamic": false,
    "fullgraph": false,
    "compile_wrapper_ms": 0.6936999998288229,
    "fallback_from": "inductor",
    "fallback_error": "compile_smoke_failed: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"
  }
}