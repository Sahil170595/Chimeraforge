{
  "path": "scripts/tr120/results/tr120_root_cause/20251221_113136/kv_decode/runs/single_short/transformers-gpu-compile/fp32/run_1766334751199.json",
  "spec": {
    "mode": "kv_decode",
    "scenario": "single_short",
    "prompt_set": "short",
    "prompts": [
      "Summarize RLHF in one sentence.",
      "List two ways to improve throughput on local LLMs."
    ],
    "backend": "transformers-gpu-compile",
    "model": "models/tiny-gpt2",
    "quantization": "fp32"
  },
  "status": "ok",
  "error": null,
  "latencies_ms": [
    106.49419999981546,
    104.92910000039046,
    107.0185999997193,
    104.38359999989189,
    128.8707999997314,
    151.15900000000693,
    102.70780000018931,
    108.70629999999437,
    104.51710000006642,
    101.43550000020696,
    105.07640000014362,
    104.57399999995687,
    131.98629999988043,
    107.7354999997624,
    127.43399999999383,
    102.61040000023058,
    103.15189999982977,
    104.71509999979389,
    104.08940000024813,
    104.27350000009028,
    107.3938000004091,
    118.00589999984368,
    105.92070000029707,
    111.69969999991736,
    132.02309999996942,
    102.10360000019136,
    101.34940000034476,
    104.43100000020422,
    111.13519999980781,
    102.65669999989768,
    110.87809999980891,
    186.5339999999378,
    108.57560000022204,
    103.12699999985853,
    106.81500000009692,
    104.22119999975621,
    106.5550000002986,
    103.23130000006131,
    103.53369999984352,
    112.6246000003448,
    101.97260000040842,
    102.8785000003154,
    107.92439999977432,
    107.27819999965504,
    133.56070000008913,
    108.10179999998581,
    107.99469999983557,
    117.04329999975016,
    115.98360000016328,
    107.82990000006976,
    108.12780000014754,
    110.38529999996172,
    107.98160000013013,
    104.81260000005932,
    108.04290000032779,
    176.41880000019228,
    127.37140000035652,
    107.23920000009457,
    103.93870000007155,
    106.68799999984913
  ],
  "ttft_ms": [
    106.49419999981546,
    104.92910000039046,
    107.0185999997193,
    104.38359999989189,
    128.8707999997314,
    151.15900000000693,
    102.70780000018931,
    108.70629999999437,
    104.51710000006642,
    101.43550000020696,
    105.07640000014362,
    104.57399999995687,
    131.98629999988043,
    107.7354999997624,
    127.43399999999383,
    102.61040000023058,
    103.15189999982977,
    104.71509999979389,
    104.08940000024813,
    104.27350000009028,
    107.3938000004091,
    118.00589999984368,
    105.92070000029707,
    111.69969999991736,
    132.02309999996942,
    102.10360000019136,
    101.34940000034476,
    104.43100000020422,
    111.13519999980781,
    102.65669999989768,
    110.87809999980891,
    186.5339999999378,
    108.57560000022204,
    103.12699999985853,
    106.81500000009692,
    104.22119999975621,
    106.5550000002986,
    103.23130000006131,
    103.53369999984352,
    112.6246000003448,
    101.97260000040842,
    102.8785000003154,
    107.92439999977432,
    107.27819999965504,
    133.56070000008913,
    108.10179999998581,
    107.99469999983557,
    117.04329999975016,
    115.98360000016328,
    107.82990000006976,
    108.12780000014754,
    110.38529999996172,
    107.98160000013013,
    104.81260000005932,
    108.04290000032779,
    176.41880000019228,
    127.37140000035652,
    107.23920000009457,
    103.93870000007155,
    106.68799999984913
  ],
  "tokens": [
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64,
    64
  ],
  "tokens_per_s": [
    600.9716961121911,
    609.9356613157059,
    598.0268850477195,
    613.1231342860975,
    496.6214223868665,
    423.39523283428093,
    623.1269679603889,
    588.742326801697,
    612.3399902978491,
    630.942815876783,
    609.0806308544309,
    612.0068085759979,
    484.89881146799314,
    594.0474588240752,
    502.2207574117041,
    623.718453488693,
    620.444218672711,
    611.1821504264998,
    614.856075641203,
    613.7705169572766,
    595.9375680882528,
    542.3457640684472,
    604.2256140661882,
    572.9648333885171,
    484.7636512096355,
    626.8143336756006,
    631.4788247368242,
    612.8448449203287,
    575.8751502684179,
    623.4371453598624,
    577.2104680735898,
    343.10098963203137,
    589.4510368800092,
    620.594024844006,
    599.1667836908855,
    614.078517615895,
    600.6287832557895,
    619.9670061305243,
    618.1562138713938,
    568.2595099099492,
    627.6195762365936,
    622.0930515103136,
    593.0076979824195,
    596.5797338154983,
    479.1828734048061,
    592.034545215791,
    592.6216749534694,
    546.8061819868084,
    551.8021513378607,
    593.5273982444443,
    591.8921868373598,
    579.7873448731144,
    592.693570014918,
    610.6136094321082,
    592.3572951096817,
    362.77312848704474,
    502.4675869137095,
    596.7966937457903,
    615.7475512004281,
    599.8800239960493
  ],
  "started_at": 1766334744.2240236,
  "degraded_count": 0,
  "degraded_reasons": [],
  "compile": {
    "enabled": true,
    "backend": "aot_eager",
    "mode": "reduce-overhead",
    "dynamic": false,
    "fullgraph": false,
    "compile_wrapper_ms": 0.6936999998288229,
    "fallback_from": "inductor",
    "fallback_error": "compile_smoke_failed: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"
  }
}